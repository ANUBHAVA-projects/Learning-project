{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No          0      Graduate            No   \n",
       "1    LP001003    Male     Yes          1      Graduate            No   \n",
       "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
       "4    LP001008    Male      No          0      Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "609  LP002978  Female      No          0      Graduate            No   \n",
       "610  LP002979    Male     Yes         3+      Graduate            No   \n",
       "611  LP002983    Male     Yes          1      Graduate            No   \n",
       "612  LP002984    Male     Yes          2      Graduate            No   \n",
       "613  LP002990  Female      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "0               1.0         Urban           Y  \n",
       "1               1.0         Rural           N  \n",
       "2               1.0         Urban           Y  \n",
       "3               1.0         Urban           Y  \n",
       "4               1.0         Urban           Y  \n",
       "..              ...           ...         ...  \n",
       "609             1.0         Rural           Y  \n",
       "610             1.0         Rural           Y  \n",
       "611             1.0         Urban           Y  \n",
       "612             1.0         Urban           Y  \n",
       "613             0.0     Semiurban           N  \n",
       "\n",
       "[614 rows x 13 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.read_csv(\"Loan.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0    LP001002    Male      No          0      Graduate            No   \n",
       "1    LP001003    Male     Yes          1      Graduate            No   \n",
       "2    LP001005    Male     Yes          0      Graduate           Yes   \n",
       "3    LP001006    Male     Yes          0  Not Graduate            No   \n",
       "4    LP001008    Male      No          0      Graduate            No   \n",
       "..        ...     ...     ...        ...           ...           ...   \n",
       "609  LP002978  Female      No          0      Graduate            No   \n",
       "610  LP002979    Male     Yes         3+      Graduate            No   \n",
       "611  LP002983    Male     Yes          1      Graduate            No   \n",
       "612  LP002984    Male     Yes          2      Graduate            No   \n",
       "613  LP002990  Female      No          0      Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0               5849                0.0         NaN             360.0   \n",
       "1               4583             1508.0       128.0             360.0   \n",
       "2               3000                0.0        66.0             360.0   \n",
       "3               2583             2358.0       120.0             360.0   \n",
       "4               6000                0.0       141.0             360.0   \n",
       "..               ...                ...         ...               ...   \n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "0               1.0         Urban           Y  \n",
       "1               1.0         Rural           N  \n",
       "2               1.0         Urban           Y  \n",
       "3               1.0         Urban           Y  \n",
       "4               1.0         Urban           Y  \n",
       "..              ...           ...         ...  \n",
       "609             1.0         Rural           Y  \n",
       "610             1.0         Rural           Y  \n",
       "611             1.0         Urban           Y  \n",
       "612             1.0         Urban           Y  \n",
       "613             0.0     Semiurban           N  \n",
       "\n",
       "[614 rows x 13 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan=pd.DataFrame(data)\n",
    "df_loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"Gender\",\"Married\",\"Dependents\",\"Self_Employed\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      489\n",
       "Female    112\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing of null value from the data usling simple imputer\n",
    "for column in columns:\n",
    "    df_loan[column]=imp.fit_transform(df_loan[column].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      6.539513\n",
       "CoapplicantIncome    7.491531\n",
       "LoanAmount           2.745407\n",
       "Loan_Amount_Term    -2.402112\n",
       "Credit_History      -2.021971\n",
       "dtype: float64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing of skewness from the data\n",
    "column=[\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\"]\n",
    "for col in column:\n",
    "    if df_loan.skew().loc[col]>0.55:\n",
    "       df_loan[col]=np.log1p(df_loan[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ApplicantIncome      0.482128\n",
       "CoapplicantIncome   -0.173073\n",
       "LoanAmount          -0.137460\n",
       "Loan_Amount_Term    -2.402112\n",
       "Credit_History      -2.021971\n",
       "dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column:\n",
    "   df_loan[col]=sc.fit_transform(df_loan[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the no of male are 502\n",
      "the no of femae are 112\n"
     ]
    }
   ],
   "source": [
    "male=len(df_loan[df_loan[\"Gender\"]== \"Male\"])\n",
    "female=len(df_loan[df_loan[\"Gender\"]== \"Female\"])\n",
    "print(\"the no of male are\", male)\n",
    "print(\"the no of femae are\",female)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.140000e+02</td>\n",
       "      <td>6.140000e+02</td>\n",
       "      <td>6.140000e+02</td>\n",
       "      <td>6.140000e+02</td>\n",
       "      <td>6.140000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.350555e-16</td>\n",
       "      <td>1.374217e-17</td>\n",
       "      <td>-1.470932e-15</td>\n",
       "      <td>1.795524e-16</td>\n",
       "      <td>8.317632e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000815e+00</td>\n",
       "      <td>1.000815e+00</td>\n",
       "      <td>1.000815e+00</td>\n",
       "      <td>1.000815e+00</td>\n",
       "      <td>1.000815e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.157770e+00</td>\n",
       "      <td>-1.107783e+00</td>\n",
       "      <td>-5.220737e+00</td>\n",
       "      <td>-5.132498e+00</td>\n",
       "      <td>-2.428760e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.841435e-01</td>\n",
       "      <td>-1.107783e+00</td>\n",
       "      <td>-5.018784e-01</td>\n",
       "      <td>2.732313e-01</td>\n",
       "      <td>4.117327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.477208e-01</td>\n",
       "      <td>7.206820e-01</td>\n",
       "      <td>-5.608695e-02</td>\n",
       "      <td>2.732313e-01</td>\n",
       "      <td>4.117327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.017959e-01</td>\n",
       "      <td>8.907879e-01</td>\n",
       "      <td>5.028287e-01</td>\n",
       "      <td>2.732313e-01</td>\n",
       "      <td>4.117327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.593738e+00</td>\n",
       "      <td>1.638995e+00</td>\n",
       "      <td>3.442243e+00</td>\n",
       "      <td>2.137276e+00</td>\n",
       "      <td>4.117327e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ApplicantIncome  CoapplicantIncome    LoanAmount  Loan_Amount_Term  \\\n",
       "count     6.140000e+02       6.140000e+02  6.140000e+02      6.140000e+02   \n",
       "mean      9.350555e-16       1.374217e-17 -1.470932e-15      1.795524e-16   \n",
       "std       1.000815e+00       1.000815e+00  1.000815e+00      1.000815e+00   \n",
       "min      -5.157770e+00      -1.107783e+00 -5.220737e+00     -5.132498e+00   \n",
       "25%      -5.841435e-01      -1.107783e+00 -5.018784e-01      2.732313e-01   \n",
       "50%      -1.477208e-01       7.206820e-01 -5.608695e-02      2.732313e-01   \n",
       "75%       5.017959e-01       8.907879e-01  5.028287e-01      2.732313e-01   \n",
       "max       4.593738e+00       1.638995e+00  3.442243e+00      2.137276e+00   \n",
       "\n",
       "       Credit_History  \n",
       "count    6.140000e+02  \n",
       "mean     8.317632e-17  \n",
       "std      1.000815e+00  \n",
       "min     -2.428760e+00  \n",
       "25%      4.117327e-01  \n",
       "50%      4.117327e-01  \n",
       "75%      4.117327e-01  \n",
       "max      4.117327e-01  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan.describe()\n",
    "\n",
    "# from below table it is oberve that outlier may be presnet in independent variable applicant income and co applicant income.\n",
    "# difference between mean and 50 percent also shows the skewness in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Check for the outliers\n",
    "features=[\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\"]\n",
    "for col in features:\n",
    "    z=np.abs(zscore(df_loan[col]))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 14,  94, 130, 133, 155, 171, 369, 555, 561, 568], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "# No Outlier found\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "categories=[male, female]\n",
    "labels = ['Male', 'Female']\n",
    "plt.pie(categories, labels=labels, autopct=\"%1.1f%%\", startangle=60)\n",
    "plt.title('Sex distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=\"Dependents\",hue=\"Loan_Status\",data=df_loan)\n",
    "plt.xlabel(\"no of dependent\")\n",
    "plt.legend([\"yes\",\"no\"])\n",
    "plt.title(\"Loan status basis on dependent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(y=\"Education\",hue=\"Loan_Status\",data=df_loan)\n",
    "plt.ylabel(\"Education\")\n",
    "plt.legend([\"yes\",\"no\"])\n",
    "plt.title(\"Loan status basis on education\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the no of person having less salary 614\n",
      "the no of person having more salary 0\n"
     ]
    }
   ],
   "source": [
    "less_income=len(df_loan[df_loan[\"ApplicantIncome\"]<= 5000])\n",
    "more_income=len(df_loan[df_loan[\"ApplicantIncome\"]> 5000])\n",
    "print(\"the no of person having less salary\", less_income)\n",
    "print(\"the no of person having more salary\",more_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(y=\"Credit_History\",hue=\"Loan_Status\",data=df_loan)\n",
    "plt.ylabel(\"Credit history\")\n",
    "plt.legend([\"yes\",\"no\"])\n",
    "plt.title(\"Loan status basis on Credit History\")\n",
    "plt.show()\n",
    "# Person with a credit history are likely have less chance to get loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAGECAYAAADA9NJLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZRcdZ338feHEAkKskYGDBg2HUEwSmTUccdB9HFUHDcUcUGBOTqDz7iiDwi4b6MzbjOMsrixibuMgqiAC0IiEcImiyhhDYEICkQSvs8f9zYWTXfoJF1d3Tfv1zl1uup3l9+3qu+pT93fvVU3VYUkSZra1hl0AZIkac0Z6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5NYUkqyQ7jvM53J/nCeK5TUv8Z6JqUklyd5NmDrmMkq1pbkmOTvL+fNY2nqvpgVb1h0HVMVkkOT/KVQdchDWegS5rSkqzbxb4G0Z+mNgNdU0qS9ZJ8Ksl17e1TSdZrp22S5HtJFie5tb0/q2fZnyZ5X5KfJ7k9yWlJNh+ln83b5ZcmuSXJ2UnWSfJlYBvgu0n+lOQd7fwnJ7khyR+TnJVk57b9AOBVwDva+b/btt9nqLx3L360vlfysjwvyVVJbk7ysaF5k2yf5MdJlrTTvppk454+35nk2va1uCzJHm37vXugSWYk+Uq7jqVJzkuyxSiv2aPb13hpkouSvGDY8/tsku+3/f0qyfajrGd2+/oc0P6Pr0/y1p7phyf5elvXbcBrk2yV5Dvt63VFkjeOMP+Jbd+/TvLYnulbJTml3W5+l+RfV9LXQcC7gZe3/8/fJHlpkvnDnsNbk3xrlOf3uiSXtLVcleTAnmnPSLKo/d/cABzTbnfvSnJl+384KcmmPcuMuO1pLVRV3rxNuhtwNfDsEdqPBM4BHgbMBH4BvK+dthnwT8CDgQ2Bk4Fv9Sz7U+BK4JHA+u3jD4/S/4eA/wKmt7enAhmtNuD1bZ/rAZ8CFvRMOxZ4/7D5C9hhpHlW1vcIdRbwE2BTmg8avwXe0E7bAfiHtqaZwFnAp9ppjwKuAbZqH88Gtm/vHw58pb1/IPDd9jWdBuwGPHSEOqYDV9CE3YOAZwG3A4/qeX63ALsD6wJfBU4Y5TnNbp/X8cBDgF2AxUOveVvf3cCLaHZK1gfOBD4HzADmtPPvMWz+l7R1vg34XXt/HWA+cFhb93bAVcBzVtLXva9PO8967XN7dE/b+cA/jfL8/g+wPRDg6cAdwOPbac8AlgMfade7PvAWmm1+Vtv238DxY9n2vK1dN/fQNdW8Cjiyqm6qqsXAEcCrAapqSVWdUlV3VNXtwAdo3jB7HVNVv62qO4GTaN78R3I3sCXwiKq6u6rOrqpRL3xQVUdX1e1VtYzmDf+xSTZazee4Sn0DH6mqW6rqDzRv6Pu0NV1RVadX1bL2tfp3/vp6rKAJgJ2STK+qq6vqylFq2Yzmw8eKqppfVbeNMN8TgQ1oPiD9pap+DHxvqJbWN6rq3KpaThPoo732Q46oqj9X1YXAMcPW9cuq+lZV3QNsDjwFeGdV3VVVC4Av0G4XrflV9fWqurt9HWa0NT8BmFlVR7Z1XwX8D/CKkfpqt5v7aP/nJwL7ArR7yLPb538/VfX9qrqyGmcCp9F8aBtyD/De9v92J82HqvdU1aKe7eslaYfjx3nb0xRmoGuq2Qr4fc/j37dtJHlwkv9O8vt2ePQsYOMk03rmv6Hn/h00ITSSj9HscZ7WDou+a7SCkkxL8uF2SPQ2mj14aIJmdYy579Y1Pfd7X4+HJTmhHVa/DfjKUE1VdQXNnt/hwE3tfFuNsO4vAz8ETmiHvz+aZPoI820FXNMGbG8tD+95PNbXfqXPa4RpWwG3tB/iRuv73vnbGhe1yz0C2Ko9TLA0yVKaUYYtRlp2JY4DXpkkNB8kTmoD9n6SPDfJOe3hgaXA87jvtrK4qu7qefwI4Js99V1C84Fsiz5se5rCDHRNNdfRvMEN2aZtA3grzVDy31XVQ4Gnte1Z1U7aPZ63VtV2wD8C/zZ0jJlmOLjXK4EXAs8GNqLZO+vtd6S96ztohrGH/M0Y+x7J1j33e1+PD7V979q+Hvv21ERVfa2qnkLzehbNMO99tCMER1TVTsCTgecD+41Qw3XA1rnvsf5tgGtXUvcDGe15wX1f0+uATZNsuJK+711XW+OsdrlrgN9V1cY9tw2r6nmj9DXSY6rqHOAvNHvar6T5IHQ/ac73OAX4OLBFVW0MnMp9t9Hh678GeO6wGmdU1bU88LantYiBrslsentS1tBtXZrjqv8vycw0J7QdRrPnCc1xxDuBpe1JQ+9d3Y6TPD/JDu0e1200e0Qr2sk30hxrHbIhsAxYQhPSHxy2uuHzAyyg2aOblmQveg4NPEDfI3l7mhMCtwYOphn+HarrTzSvx8OBt/f08agkz2oD5i6a1+1+fSR5ZpJd2lGO22iG4Eeq5VfAn2lO/pue5Bk0H0ZOWEndD+TQdtRlZ+B1Pc/rPqrqGppzKT7Ubie7AvvTDOsP2S3Ji9tt6C00/69zgHOB29qT0NZv/x+PSfKEldR1IzA79z9R8UvAZ4DlVfWzUZZ9EM2hjsXA8iTPBfZcSV/QnE/xgSSPAGi3/Re20x5o29NaxEDXZHYqTdAM3Q4H3g/MAy4ALgR+3bZBc/x4feBmmjfrH6xB3zsCP6IJxF8Cn6uqn7bTPkTzoWJpkrfRvJH/nmaP8OK2715fpDlWvbTnzOeDaQJvKc15Ab1nRK+s75F8m+bErgXA99v+oDm/4PHAH9v2b/Qssx7wYZrX6gaakwzfPcK6/wb4Ok2YX0Jz8tn9voNdVX8BXgA8t13n54D9qurSldT9QM6kOfRwBvDxqjptJfPuQ7N3eh3wTZpj0Kf3TP828HLgVpoh8Re3ow8raP4Pc2hOlLuZ5vj7yo5Bn9z+XZLk1z3tXwYewyh759CMvgD/SnP+xq00e9jfWUlfAP/RznNakttptq+/a6c90LantcjQWbuSNCkkmU17Fnp7At2aru9wmpP69l3TdT1AP+sDN9GcsX55P/uSRuIeuiSNj38GzjPMNSj+CpEkraEkV9OciPaiAZeitZhD7pIkdYBD7pIkdYCBLklSB0zpY+ibb755zZ49e9BlSJI0YebPn39zVc0c3j6lA3327NnMmzdv0GVIkjRhkvx+pHaH3CVJ6gADXZKkDjDQJUnqgCl9DF2SJIC7776bRYsWcddddz3wzFPEjBkzmDVrFtOnj3TF4vsz0CVJU96iRYvYcMMNmT17Ns2FCqe2qmLJkiUsWrSIbbfddkzLOOQuSZry7rrrLjbbbLNOhDlAEjbbbLNVGnEw0CVJndCVMB+yqs/HQJckqQM8hi5J6pzd3v6lcV3f/I/tN67r6wcDXZKkcXDooYey+eabc/DBBwPwnve8hy222IJly5Zx0kknsWzZMvbee2+OOOII/vznP/Oyl72MRYsWsWLFCg499FBe/vKXr1H/DrlLkjQO9t9/f4477jgA7rnnHk444QS22GILLr/8cs4991wWLFjA/PnzOeuss/jBD37AVlttxW9+8xsWLlzIXnvttcb9G+iSJI2D2bNns9lmm3H++edz2mmn8bjHPY7zzjvv3vuPf/zjufTSS7n88svZZZdd+NGPfsQ73/lOzj77bDbaaKM17t8hd0mSxskb3vAGjj32WG644QZe//rXc8YZZ3DIIYdw4IEH3m/e+fPnc+qpp3LIIYew5557cthhh61R3wa6JE1S431i12Q2FU46G4u9996bww47jLvvvpuvfe1rrLvuuhx66KG86lWvYoMNNuDaa69l+vTpLF++nE033ZR9992XDTbYgGOPPXaN+zbQJUkaJw960IN45jOfycYbb8y0adPYc889ueSSS3jSk54EwAYbbMBXvvIVrrjiCt7+9rezzjrrMH36dD7/+c+vcd8GuiSpcwa1x3/PPfdwzjnncPLJJ9/bdvDBB9975vuQ7bffnuc85znj2rcnxUmSNA4uvvhidthhB/bYYw923HHHCe+/b3voSY4Gng/cVFWPadtOBB7VzrIxsLSq5iSZDVwCXNZOO6eqDupXbZIkjbeddtqJq666amD993PI/VjgM8C9Z3VU1b3fmk/yCeCPPfNfWVVz+liPJEmd1bdAr6qz2j3v+0nzi/MvA57Vr/4lSVqbDOoY+lOBG6vq8p62bZOcn+TMJE8dbcEkBySZl2Te4sWL+1+pJElTwKACfR/g+J7H1wPbVNXjgH8DvpbkoSMtWFVHVdXcqpo7c+bMCShVkqTJb8IDPcm6wIuBE4faqmpZVS1p788HrgQeOdG1SZI0VQ3ie+jPBi6tqkVDDUlmArdU1Yok2wE7AoM7VVCSNKX94chdxnV92xx24biurx/6toee5Hjgl8CjkixKsn876RXcd7gd4GnABUl+A3wdOKiqbulXbZIkjberr76aRz/60bzxjW9k5513Zs899+TOO+9kwYIFPPGJT2TXXXdl77335tZbb+1L/30L9Krap6q2rKrpVTWrqr7Ytr+2qv5r2LynVNXOVfXYqnp8VX23X3VJktQvl19+OW9605u46KKL2HjjjTnllFPYb7/9+MhHPsIFF1zALrvswhFHHNGXvv2lOEmSxsm2227LnDnNT6rstttuXHnllSxdupSnP/3pALzmNa/hrLPO6kvfBrokSeNkvfXWu/f+tGnTWLp06YT1baBLktQnG220EZtssglnn302AF/+8pfv3Vsfb15tTZKkPjruuOM46KCDuOOOO9huu+045phj+tKPgS5J6pxBfM1s9uzZLFy48N7Hb3vb2+69f8455/S9f4fcJUnqAANdkqQOMNAlSeoAA12S1AlVNegSxtWqPh8DXZI05c2YMYMlS5Z0JtSriiVLljBjxowxL+NZ7pKkKW/WrFksWrSIxYsXD7qUcTNjxgxmzZo15vkNdEnSlDd9+nS23XbbQZcxUA65S5LUAQa6JEkdYKBLktQBBrokSR1goEuS1AEGuiRJHWCgS5LUAQa6JEkdYKBLktQBBrokSR1goEuS1AEGuiRJHWCgS5LUAQa6JEkdYKBLktQBBrokSR1goEuS1AEGuiRJHWCgS5LUAQa6JEkdYKBLktQBBrokSR3Qt0BPcnSSm5Is7Gk7PMm1SRa0t+f1TDskyRVJLkvynH7VJUlSF/VzD/1YYK8R2j9ZVXPa26kASXYCXgHs3C7zuSTT+libJEmd0rdAr6qzgFvGOPsLgROqallV/Q64Ati9X7VJktQ1gziG/uYkF7RD8pu0bQ8HrumZZ1HbJkmSxmCiA/3zwPbAHOB64BNte0aYt0ZaQZIDksxLMm/x4sX9qVKSpClmQgO9qm6sqhVVdQ/wP/x1WH0RsHXPrLOA60ZZx1FVNbeq5s6cObO/BUuSNEVMaKAn2bLn4d7A0Bnw3wFekWS9JNsCOwLnTmRtkiRNZev2a8VJjgeeAWyeZBHwXuAZSebQDKdfDRwIUFUXJTkJuBhYDrypqlb0qzZJkrqmb4FeVfuM0PzFlcz/AeAD/apHkqQu85fiJEnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDlh30AUMym5v/9KgS5hQ8z+236BLkCT1kXvokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHVA3wI9ydFJbkqysKftY0kuTXJBkm8m2bhtn53kziQL2tt/9asuSZK6qJ976McCew1rOx14TFXtCvwWOKRn2pVVNae9HdTHuiRJ6py+BXpVnQXcMqzttKpa3j48B5jVr/4lSVqbDPIY+uuB/+15vG2S85OcmeSpgypKkqSpaCBXW0vyHmA58NW26Xpgm6pakmQ34FtJdq6q20ZY9gDgAIBtttlmokqWJGlSm/A99CSvAZ4PvKqqCqCqllXVkvb+fOBK4JEjLV9VR1XV3KqaO3PmzIkqW5KkSW1CAz3JXsA7gRdU1R097TOTTGvvbwfsCFw1kbVJkjSV9W3IPcnxwDOAzZMsAt5Lc1b7esDpSQDOac9ofxpwZJLlwArgoKq6ZcQVS5Kk++lboFfVPiM0f3GUeU8BTulXLZIkdZ2/FCdJUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSB6w76AKkrtjt7V8adAkTav7H9ht0CZJ6uIcuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIH9C3Qkxyd5KYkC3vaNk1yepLL27+b9Ew7JMkVSS5L8px+1SVJUhf1cw/9WGCvYW3vAs6oqh2BM9rHJNkJeAWwc7vM55JM62NtkiR1ypgCPckZY2nrVVVnAbcMa34hcFx7/zjgRT3tJ1TVsqr6HXAFsPtYapMkSbDuyiYmmQE8GNi8HR5PO+mhwFar0d8WVXU9QFVdn+RhbfvDgXN65lvUto1U0wHAAQDbbLPNapQgSVL3rDTQgQOBt9CE93z+Gui3AZ8dxzoyQluNNGNVHQUcBTB37twR55EkaW2z0kCvqv8A/iPJv1TVp8ehvxuTbNnunW8J3NS2LwK27plvFnDdOPQnSdJa4YH20AGoqk8neTIwu3eZqvrSKvb3HeA1wIfbv9/uaf9akn+nGQ3YETh3FdctSdJaa0yBnuTLwPbAAmBF21zAqIGe5HjgGTTH3xcB76UJ8pOS7A/8AXgpQFVdlOQk4GJgOfCmqlox4oolSdL9jCnQgbnATlU15mPWVbXPKJP2GGX+DwAfGOv6JUnSX431e+gLgb/pZyGSJGn1jXUPfXPg4iTnAsuGGqvqBX2pSpIkrZKxBvrh/SxCkiStmbGe5X5mvwuRJEmrb6xnud/OX3/o5UHAdODPVfXQfhUmSZLGbqx76Bv2Pk7yIvytdUmSJo3VutpaVX0LeNY41yJJklbTWIfcX9zzcB2a76X7O+qSJE0SYz3L/R977i8Hrqa55KkkSZoExnoM/XX9LkSSJK2+MR1DTzIryTeT3JTkxiSnJJnV7+IkSdLYjPWkuGNoroi2FfBw4LttmyRJmgTGGugzq+qYqlre3o4FZvaxLkmStArGGug3J9k3ybT2ti+wpJ+FSZKksRtroL8eeBlwA3A98BLAE+UkSZokxvq1tfcBr6mqWwGSbAp8nCboJUnSgI11D33XoTAHqKpbgMf1pyRJkrSqxhro6yTZZOhBu4c+1r17SZLUZ2MN5U8Av0jydZqffH0Z8IG+VSVJklbJWH8p7ktJ5tFckCXAi6vq4r5WJkmSxmzMw+ZtgBvikiRNQqt1+VRJkjS5GOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHjPlqa+MlyaOAE3uatgMOAzYG3ggsbtvfXVWnTnB5kiRNSRMe6FV1GTAHIMk04Frgm8DrgE9W1ccnuiZJkqa6QQ+57wFcWVW/H3AdkiRNaYMO9FcAx/c8fnOSC5IcnWSTQRUlSdJUM7BAT/Ig4AXAyW3T54HtaYbjrwc+McpyBySZl2Te4sWLR5pFkqS1ziD30J8L/LqqbgSoqhurakVV3QP8D7D7SAtV1VFVNbeq5s6cOXMCy5UkafIaZKDvQ89we5Ite6btDSyc8IokSZqiJvwsd4AkDwb+ATiwp/mjSeYABVw9bJokSVqJgQR6Vd0BbDas7dWDqEWSpC4Y9FnukiRpHBjokiR1gIEuSVIHGOiSJHWAgS5JUgcM5Cx3Tbw/HLnLoEuYMNscduGgS1gruE1Jk4t76JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdYCBLklSBxjokiR1gIEuSVIHGOiSJHWAgS5JUgcY6JIkdcC6gy5AkqQ/HLnLoEuYUNscduG4r9M9dEmSOsBAlySpAwx0SZI6YCDH0JNcDdwOrACWV9XcJJsCJwKzgauBl1XVrYOoT5KkqWaQe+jPrKo5VTW3ffwu4Iyq2hE4o30sSZLGYDINub8QOK69fxzwogHWIknSlDKoQC/gtCTzkxzQtm1RVdcDtH8fNtKCSQ5IMi/JvMWLF09QuZIkTW6D+h7631fVdUkeBpye5NKxLlhVRwFHAcydO7f6VaAkSVPJQPbQq+q69u9NwDeB3YEbk2wJ0P69aRC1SZI0FU14oCd5SJINh+4DewILge8Ar2lnew3w7YmuTZKkqWoQQ+5bAN9MMtT/16rqB0nOA05Ksj/wB+ClA6hNkqQpacIDvaquAh47QvsSYI+JrkeSpC6YTF9bkyRJq8lAlySpAwx0SZI6wECXJKkDDHRJkjrAQJckqQMMdEmSOsBAlySpAwx0SZI6wECXJKkDDHRJkjrAQJckqQMMdEmSOsBAlySpAwx0SZI6wECXJKkDDHRJkjrAQJckqQMMdEmSOsBAlySpAwx0SZI6wECXJKkDDHRJkjrAQJckqQMMdEmSOsBAlySpAwx0SZI6wECXJKkDDHRJkjrAQJckqQMMdEmSOsBAlySpAwx0SZI6wECXJKkDJjzQk2yd5CdJLklyUZKD2/bDk1ybZEF7e95E1yZJ0lS17gD6XA68tap+nWRDYH6S09tpn6yqjw+gJkmSprQJD/Squh64vr1/e5JLgIdPdB2SJHXJQI+hJ5kNPA74Vdv05iQXJDk6ySYDK0ySpClmYIGeZAPgFOAtVXUb8Hlge2AOzR78J0ZZ7oAk85LMW7x48YTVK0nSZDaQQE8ynSbMv1pV3wCoqhurakVV3QP8D7D7SMtW1VFVNbeq5s6cOXPiipYkaRIbxFnuAb4IXFJV/97TvmXPbHsDCye6NkmSpqpBnOX+98CrgQuTLGjb3g3sk2QOUMDVwIEDqE2SpClpEGe5/wzICJNOnehaJEnqCn8pTpKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeqASRfoSfZKclmSK5K8a9D1SJI0FUyqQE8yDfgs8FxgJ2CfJDsNtipJkia/SRXowO7AFVV1VVX9BTgBeOGAa5IkadKbbIH+cOCanseL2jZJkrQS6w66gGEyQlvdZ4bkAOCA9uGfklzW96o64BGwOXDzoOuYEO8daTPSeHOb0nhaq7YnWNNt6hEjNU62QF8EbN3zeBZwXe8MVXUUcNREFtUFSeZV1dxB16HucJvSeHJ7WnOTbcj9PGDHJNsmeRDwCuA7A65JkqRJb1LtoVfV8iRvBn4ITAOOrqqLBlyWJEmT3qQKdICqOhU4ddB1dJCHKTTe3KY0ntye1lCq6oHnkiRJk9pkO4YuSZJWg4E+hSSZnWThsLbDk7xthHmPTfKSiatOU12SFUkWJFmY5LtJNh7Hdf9pvNaliZfkPUkuSnJBu4383Tis8xerscxPk3gm/CgM9A5KMunOjdCUcGdVzamqxwC3AG8a64Juc92V5EnA84HHV9WuwLO57w+ArZaqevIq1jFtTfvsOgO9I9pPrh9MciZwcNv87CRnJ/ltkue3881u237d3p7ctj+jXcfXk1ya5KtJ/DWNtdcvaX+lsXevKMnmSa5u7782yclJvguclmSDJGe029WFSfzZ5m7YEri5qpYBVNXNVXVdkt2SnJlkfpIfJtkS7t1ePpnkrCSXJHlCkm8kuTzJ+4dWOjRq0773fK+n/TNJXtvevzrJYUl+Bry0nWXfJL9oR5J2b+fbvW07v/37qLb9tW3fP2j7/2j/X67B8VN1t2xcVU+HZsgdmA08Hdge+EmSHYCbgH+oqruS7AgcDwwNYT0O2Jnmx3x+Dvw98LOJfAIavHZPaA/gi2OY/UnArlV1S7uXvndV3ZZkc+CcJN8pz7yd6k4DDkvyW+BHwInAL4BPAy+sqsVJXg58AHh9u8xfquppSQ4Gvg3sRjPqc2WST1bVklXo/66qegpAkoOAh1TVk5M8DTgaeAxwKfC09qvPzwY+CPxTu/wcmve2ZcBlST5dVWs8wjAZGehTy2hvjEPtJw5rP6mq7gEuT3IV8LfA74DPJJkDrAAe2TP/uVW1CCDJApoPBAb62mP9nv/7fOD0MSxzelXd0t4P8MH2jfYemj38LYAb+lCrJkhV/SnJbsBTgWfSvM+8nyZIT28H8qYB1/csNvSDYBcCF1XV9QDt+9DWwKoE+vD3tePbus5K8tD2XI8NgePanZQCpvfMf0ZV/bHt/2Kan0010DVwS4BNhrVtShPSAH8eNm34B4AC/i9wI/BYmkMud/VMX9ZzfwVuH2ubO6tqTpKNgO/RHEP/T2A5fz08N2PYMr3b3KuAmcBuVXV3OzQ/fH5NQVW1Avgp8NMkF9JsGxdV1ZNGWWToveQe7vu+cg/3f1/p3b5g5dsYjPy+9j7gJ1W1d5LZba3Da4GOv695DH0Kqao/Adcn2QMgyabAXoy+F/3SJOsk2R7YDrgM2Ai4vt1zfzXNJ2vpXu3ezL8Cb0syHbiaZsgUYGXfnNgIuKkN82cyygUkNLUkeVS75ztkDnAJMLM9YY4k05PsvJpd/A3IdU4AAAPuSURBVB7YKcl67YfJPR5g/pe3fT4F+GO7vW4EXNtOf+1q1jHldfaTSoftB3w2ySfax0dU1ZWjnL92GXAmzbDnQe1x888BpyR5KfAT7v/pV6Kqzk/yG5rrKXwcOCnJq4Efr2SxrwLfTTIPWEBzXFNT3wbAp9uh7eXAFTRXvDwK+M82hNcFPgWs8k91V9U1SU4CLgAuB85/gEVubb/y9lD+esz+ozRD7v/GyrfRTvOX4iRJ6gCH3CVJ6gADXZKkDjDQJUnqAANdkqQOMNAlSeoAA12SpA4w0KUpJve9zOnJSR48wf2/ZU36TLJ3kkryt+NZl7S2M9Clqaf3Mqd/AQ7qnZg+XmayXfdbgDX5ELEPza8bvmIlfUhaRQa6NLWdDezQXoLyJ0m+BlyYZEaSY9rLmJ7f/hTr0OUkv91eTvKyJO8dWlGSfZOc2+79//dQsCb5U5Ijk/wKeA+wFc3V+36SZP8kn+xZxxuT/PtoxSbZgOYqfvvTE+gj1D8tyceSnJfkgiQHDi0fL9EqjciffpWmqPZypc8FftA27Q48pqp+l+StAFW1Szu0fVqSR/bOB9wBnJfk+zQ/Afxy4O/b32L/HM3FVr4EPARYWFWHtf2+HnhmVd2c5CHABUneUVV3A68DDlxJ2S8CflBVv01yS5LHV9WvR6j/AJrf6X5CkvWAnyc5jeYqWV6iVRqBgS5NPUOXOYVmD/2LwJNpLn87dOW9p9Bcr5qqujTJ7/nrpXJPH7oedZJvtPMup7kAy3ntdQHWB25q518BnDJSIVX15yQ/Bp6f5BJgelVduJLa96H5zW+AE9rHQ4HeW/+ewK5Jhi4GsxGwI7AIL9EqjchAl6aeO6tqTm9DG8K9F9oZ8Wo9rZEuPxnguKo6ZIT572ovnzmaLwDvprkYyzGjzZRkM+BZwGOSFM2V/irJO9pZhtf/L1X1w2HreC1eolUakcfQpW46i2bInHaofRuaq+8B/EOSTZOsTzME/nPgDOAlSR7WLrNpktEuf3o7sOHQg6r6FbA18Erg+JXU9BLgS1X1iKqaXVVbA7+jGSEY7ofAP7eXbyXJI9vhfS/RKo3CQJe66XPAtCQXAicCr62qZe20nwFfprnE6SlVNa+qLgb+H82x9guA04EtR1n3UcD/JvlJT9tJwM+r6taV1LQP8M1hbafQfBAY7gvAxcCvkywE/ptmRPGrwNz2Eq2vwku0Svfy8qnSWqQdsp5bVW8e5/V+D/hkVZ0xnuuVNHbuoUtabUk2TvJbmuP6hrk0QO6hSxpX7clvI4X7HkNn10safwa6JEkd4JC7JEkdYKBLktQBBrokSR1goEuS1AEGuiRJHfD/Af2eSEknIwRNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=\"Property_Area\",hue=\"Loan_Status\",data=df_loan)\n",
    "plt.xlabel(\"Property_Area\")\n",
    "plt.legend([\"yes\",\"no\"])\n",
    "plt.title(\"Loan status basis on property area\")\n",
    "plt.show()\n",
    "\n",
    "# Person having property in urban and rural are having moderate chance to not to pay loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data categorical to numerical\n",
    "le=LabelEncoder()\n",
    "features=[\"Gender\",\"Married\",\"Education\",\"Self_Employed\",\"Property_Area\",\"Loan_Status\",\"Dependents\"]\n",
    "for col in features:\n",
    "    data=df_loan[col] = data=df_loan[col].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516186</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-0.138624</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>-0.008123</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.519479</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-1.343509</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.751605</td>\n",
       "      <td>0.897526</td>\n",
       "      <td>-0.138624</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555727</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.187592</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572062</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-1.196800</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032679</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-2.344602</td>\n",
       "      <td>-2.522836</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.015921</td>\n",
       "      <td>0.308483</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918972</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.759593</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>-2.428760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender  Married  Dependents  Education  Self_Employed  \\\n",
       "0    LP001002       1        0           0          0              0   \n",
       "1    LP001003       1        1           1          0              0   \n",
       "2    LP001005       1        1           0          0              1   \n",
       "3    LP001006       1        1           0          1              0   \n",
       "4    LP001008       1        0           0          0              0   \n",
       "..        ...     ...      ...         ...        ...            ...   \n",
       "609  LP002978       0        0           0          0              0   \n",
       "610  LP002979       1        1           3          0              0   \n",
       "611  LP002983       1        1           1          0              0   \n",
       "612  LP002984       1        1           2          0              0   \n",
       "613  LP002990       0        0           0          0              1   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0           0.516186          -1.107783   -0.138624          0.273231   \n",
       "1           0.137806           0.782158   -0.008123          0.273231   \n",
       "2          -0.519479          -1.107783   -1.343509          0.273231   \n",
       "3          -0.751605           0.897526   -0.138624          0.273231   \n",
       "4           0.555727          -1.107783    0.187592          0.273231   \n",
       "..               ...                ...         ...               ...   \n",
       "609        -0.572062          -1.107783   -1.196800          0.273231   \n",
       "610        -0.032679          -1.107783   -2.344602         -2.522836   \n",
       "611         1.015921           0.308483    1.372928          0.273231   \n",
       "612         0.918972          -1.107783    0.759593          0.273231   \n",
       "613         0.137806          -1.107783    0.069392          0.273231   \n",
       "\n",
       "     Credit_History  Property_Area  Loan_Status  \n",
       "0          0.411733              2            1  \n",
       "1          0.411733              0            0  \n",
       "2          0.411733              2            1  \n",
       "3          0.411733              2            1  \n",
       "4          0.411733              2            1  \n",
       "..              ...            ...          ...  \n",
       "609        0.411733              0            1  \n",
       "610        0.411733              0            1  \n",
       "611        0.411733              2            1  \n",
       "612        0.411733              2            1  \n",
       "613       -2.428760              1            0  \n",
       "\n",
       "[614 rows x 13 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan1=df_loan.drop(\"Loan_ID\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516186</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-0.138624</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>0.782158</td>\n",
       "      <td>-0.008123</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.519479</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-1.343509</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.751605</td>\n",
       "      <td>0.897526</td>\n",
       "      <td>-0.138624</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555727</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.187592</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.572062</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-1.196800</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.032679</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>-2.344602</td>\n",
       "      <td>-2.522836</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.015921</td>\n",
       "      <td>0.308483</td>\n",
       "      <td>1.372928</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918972</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.759593</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>0.411733</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.137806</td>\n",
       "      <td>-1.107783</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>0.273231</td>\n",
       "      <td>-2.428760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         1        0           0          0              0         0.516186   \n",
       "1         1        1           1          0              0         0.137806   \n",
       "2         1        1           0          0              1        -0.519479   \n",
       "3         1        1           0          1              0        -0.751605   \n",
       "4         1        0           0          0              0         0.555727   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "609       0        0           0          0              0        -0.572062   \n",
       "610       1        1           3          0              0        -0.032679   \n",
       "611       1        1           1          0              0         1.015921   \n",
       "612       1        1           2          0              0         0.918972   \n",
       "613       0        0           0          0              1         0.137806   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0            -1.107783   -0.138624          0.273231        0.411733   \n",
       "1             0.782158   -0.008123          0.273231        0.411733   \n",
       "2            -1.107783   -1.343509          0.273231        0.411733   \n",
       "3             0.897526   -0.138624          0.273231        0.411733   \n",
       "4            -1.107783    0.187592          0.273231        0.411733   \n",
       "..                 ...         ...               ...             ...   \n",
       "609          -1.107783   -1.196800          0.273231        0.411733   \n",
       "610          -1.107783   -2.344602         -2.522836        0.411733   \n",
       "611           0.308483    1.372928          0.273231        0.411733   \n",
       "612          -1.107783    0.759593          0.273231        0.411733   \n",
       "613          -1.107783    0.069392          0.273231       -2.428760   \n",
       "\n",
       "     Property_Area  Loan_Status  \n",
       "0                2            1  \n",
       "1                0            0  \n",
       "2                2            1  \n",
       "3                2            1  \n",
       "4                2            1  \n",
       "..             ...          ...  \n",
       "609              0            1  \n",
       "610              0            1  \n",
       "611              2            1  \n",
       "612              2            1  \n",
       "613              1            0  \n",
       "\n",
       "[614 rows x 12 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loan1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df_loan1.values\n",
    "x = array[:, 0:11]\n",
    "y = array[:, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 11)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "lregr=LogisticRegression()\n",
    "def maxraccuracy_score(regr,x,y):\n",
    "    maxraccuracy_score=0\n",
    "    for r_state in range(42,101):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred=regr.predict(x_test)\n",
    "        acc_scr=accuracy_score(y_test,y_pred)\n",
    "        Class_rprt=classification_report(y_test,y_pred)\n",
    "        conf_rprt=confusion_matrix(y_test,y_pred)\n",
    "        print(\"classification report is\",Class_rprt)\n",
    "        print(\"confusion matrix is\",conf_rprt)\n",
    "        print(\"accuracy score correspond to random state\",r_state,\"is:\", acc_scr)\n",
    "        if acc_scr>maxraccuracy_score:\n",
    "            maxraccuracy_score=acc_scr\n",
    "            final_r_state=r_state\n",
    "            \n",
    "    print(\"max Accuracyscore corresponsds to \",final_r_state,\"is:\",maxraccuracy_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.58        43\n",
      "         1.0       0.76      0.99      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.70      0.72       123\n",
      "weighted avg       0.83      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[18 25]\n",
      " [ 1 79]]\n",
      "accuracy score correspond to random state 42 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.42      0.57        38\n",
      "         1.0       0.79      0.98      0.87        85\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.70      0.72       123\n",
      "weighted avg       0.82      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[16 22]\n",
      " [ 2 83]]\n",
      "accuracy score correspond to random state 43 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.44      0.58        32\n",
      "         1.0       0.83      0.98      0.90        91\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.85      0.71      0.74       123\n",
      "weighted avg       0.84      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[14 18]\n",
      " [ 2 89]]\n",
      "accuracy score correspond to random state 44 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.38      0.55        45\n",
      "         1.0       0.74      1.00      0.85        78\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.87      0.69      0.70       123\n",
      "weighted avg       0.83      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[17 28]\n",
      " [ 0 78]]\n",
      "accuracy score correspond to random state 45 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.44      0.59        34\n",
      "         1.0       0.82      0.98      0.89        89\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.85      0.71      0.74       123\n",
      "weighted avg       0.84      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 19]\n",
      " [ 2 87]]\n",
      "accuracy score correspond to random state 46 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57        37\n",
      "         1.0       0.79      0.99      0.88        86\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.87      0.70      0.72       123\n",
      "weighted avg       0.84      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[15 22]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 47 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.24      0.38        37\n",
      "         1.0       0.75      0.99      0.85        86\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.62      0.62       123\n",
      "weighted avg       0.80      0.76      0.71       123\n",
      "\n",
      "confusion matrix is [[ 9 28]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 48 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.40      0.56        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.84      0.82      0.79       123\n",
      "\n",
      "confusion matrix is [[14 21]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 49 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.44      0.59        43\n",
      "         1.0       0.76      0.97      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.83      0.71      0.73       123\n",
      "weighted avg       0.81      0.79      0.77       123\n",
      "\n",
      "confusion matrix is [[19 24]\n",
      " [ 2 78]]\n",
      "accuracy score correspond to random state 50 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.44      0.62        36\n",
      "         1.0       0.81      1.00      0.90        87\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.91      0.72      0.76       123\n",
      "weighted avg       0.87      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[16 20]\n",
      " [ 0 87]]\n",
      "accuracy score correspond to random state 51 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.49      0.63        39\n",
      "         1.0       0.80      0.98      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.85      0.73      0.76       123\n",
      "weighted avg       0.84      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[19 20]\n",
      " [ 2 82]]\n",
      "accuracy score correspond to random state 52 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.43      0.59        46\n",
      "         1.0       0.74      0.97      0.84        77\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.83      0.70      0.72       123\n",
      "weighted avg       0.80      0.77      0.75       123\n",
      "\n",
      "confusion matrix is [[20 26]\n",
      " [ 2 75]]\n",
      "accuracy score correspond to random state 53 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        35\n",
      "         1.0       0.82      0.99      0.90        88\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.88      0.72      0.76       123\n",
      "weighted avg       0.86      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[16 19]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 54 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.33      0.48        46\n",
      "         1.0       0.71      0.99      0.83        77\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.82      0.66      0.65       123\n",
      "weighted avg       0.80      0.74      0.70       123\n",
      "\n",
      "confusion matrix is [[15 31]\n",
      " [ 1 76]]\n",
      "accuracy score correspond to random state 55 is: 0.7398373983739838\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.40      0.55        30\n",
      "         1.0       0.83      0.98      0.90        93\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.85      0.69      0.72       123\n",
      "weighted avg       0.84      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[12 18]\n",
      " [ 2 91]]\n",
      "accuracy score correspond to random state 56 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 57 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57        39\n",
      "         1.0       0.78      0.99      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.70      0.72       123\n",
      "weighted avg       0.83      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 58 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.37      0.53        35\n",
      "         1.0       0.80      0.99      0.88        88\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.86      0.68      0.71       123\n",
      "weighted avg       0.84      0.81      0.78       123\n",
      "\n",
      "confusion matrix is [[13 22]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 59 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.47      0.61        38\n",
      "         1.0       0.80      0.96      0.88        85\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.83      0.72      0.74       123\n",
      "weighted avg       0.82      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[18 20]\n",
      " [ 3 82]]\n",
      "accuracy score correspond to random state 60 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.37      0.49        30\n",
      "         1.0       0.82      0.96      0.89        93\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.78      0.66      0.69       123\n",
      "weighted avg       0.80      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[11 19]\n",
      " [ 4 89]]\n",
      "accuracy score correspond to random state 61 is: 0.8130081300813008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62        42\n",
      "         1.0       0.78      1.00      0.88        81\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.73      0.75       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 62 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.73        35\n",
      "         1.0       0.85      1.00      0.92        88\n",
      "\n",
      "    accuracy                           0.88       123\n",
      "   macro avg       0.93      0.79      0.82       123\n",
      "weighted avg       0.90      0.88      0.87       123\n",
      "\n",
      "confusion matrix is [[20 15]\n",
      " [ 0 88]]\n",
      "accuracy score correspond to random state 63 is: 0.8780487804878049\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.41      0.58        39\n",
      "         1.0       0.79      1.00      0.88        84\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.71      0.73       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 0 84]]\n",
      "accuracy score correspond to random state 64 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        44\n",
      "         1.0       0.74      1.00      0.85        79\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.87      0.68      0.69       123\n",
      "weighted avg       0.83      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[16 28]\n",
      " [ 0 79]]\n",
      "accuracy score correspond to random state 65 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.43      0.59        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.88      0.71      0.74       123\n",
      "weighted avg       0.85      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 20]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 66 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61        30\n",
      "         1.0       0.85      0.98      0.91        93\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.86      0.72      0.76       123\n",
      "weighted avg       0.86      0.85      0.84       123\n",
      "\n",
      "confusion matrix is [[14 16]\n",
      " [ 2 91]]\n",
      "accuracy score correspond to random state 67 is: 0.8536585365853658\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.37      0.51        35\n",
      "         1.0       0.79      0.97      0.87        88\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.80      0.67      0.69       123\n",
      "weighted avg       0.80      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[13 22]\n",
      " [ 3 85]]\n",
      "accuracy score correspond to random state 68 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.53      0.68        40\n",
      "         1.0       0.81      0.99      0.89        83\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.88      0.76      0.78       123\n",
      "weighted avg       0.86      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[21 19]\n",
      " [ 1 82]]\n",
      "accuracy score correspond to random state 69 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.44      0.60        41\n",
      "         1.0       0.78      0.99      0.87        82\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.71      0.74       123\n",
      "weighted avg       0.84      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[18 23]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 70 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.25      0.38        36\n",
      "         1.0       0.76      0.98      0.85        87\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.79      0.61      0.62       123\n",
      "weighted avg       0.78      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[ 9 27]\n",
      " [ 2 85]]\n",
      "accuracy score correspond to random state 71 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.47      0.63        34\n",
      "         1.0       0.83      0.99      0.90        89\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.89      0.73      0.77       123\n",
      "weighted avg       0.86      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[16 18]\n",
      " [ 1 88]]\n",
      "accuracy score correspond to random state 72 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60        37\n",
      "         1.0       0.80      1.00      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.90      0.72      0.75       123\n",
      "weighted avg       0.86      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[16 21]\n",
      " [ 0 86]]\n",
      "accuracy score correspond to random state 73 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.47      0.62        47\n",
      "         1.0       0.75      0.97      0.85        76\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.72      0.73       123\n",
      "weighted avg       0.81      0.78      0.76       123\n",
      "\n",
      "confusion matrix is [[22 25]\n",
      " [ 2 74]]\n",
      "accuracy score correspond to random state 74 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.36      0.51        42\n",
      "         1.0       0.75      0.98      0.84        81\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.81      0.67      0.68       123\n",
      "weighted avg       0.79      0.76      0.73       123\n",
      "\n",
      "confusion matrix is [[15 27]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 75 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.44      0.58        39\n",
      "         1.0       0.79      0.96      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.82      0.70      0.72       123\n",
      "weighted avg       0.81      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 22]\n",
      " [ 3 81]]\n",
      "accuracy score correspond to random state 76 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.47      0.62        40\n",
      "         1.0       0.79      0.98      0.88        83\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.85      0.73      0.75       123\n",
      "weighted avg       0.83      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[19 21]\n",
      " [ 2 81]]\n",
      "accuracy score correspond to random state 77 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.41      0.55        34\n",
      "         1.0       0.81      0.97      0.88        89\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.82      0.69      0.72       123\n",
      "weighted avg       0.81      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[14 20]\n",
      " [ 3 86]]\n",
      "accuracy score correspond to random state 78 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 79 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 80 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.45      0.59        33\n",
      "         1.0       0.83      0.97      0.89        90\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.83      0.71      0.74       123\n",
      "weighted avg       0.83      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 18]\n",
      " [ 3 87]]\n",
      "accuracy score correspond to random state 81 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.50      0.64        38\n",
      "         1.0       0.81      0.98      0.89        85\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.74      0.77       123\n",
      "weighted avg       0.84      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[19 19]\n",
      " [ 2 83]]\n",
      "accuracy score correspond to random state 82 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.31      0.46        29\n",
      "         1.0       0.82      0.99      0.90        94\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.65      0.68       123\n",
      "weighted avg       0.84      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[ 9 20]\n",
      " [ 1 93]]\n",
      "accuracy score correspond to random state 83 is: 0.8292682926829268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.41      0.56        41\n",
      "         1.0       0.77      0.96      0.85        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.81      0.69      0.71       123\n",
      "weighted avg       0.79      0.78      0.76       123\n",
      "\n",
      "confusion matrix is [[17 24]\n",
      " [ 3 79]]\n",
      "accuracy score correspond to random state 84 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.45      0.60        42\n",
      "         1.0       0.77      0.98      0.86        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.71      0.73       123\n",
      "weighted avg       0.82      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 85 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.36      0.52        45\n",
      "         1.0       0.73      0.99      0.84        78\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.67      0.68       123\n",
      "weighted avg       0.80      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[16 29]\n",
      " [ 1 77]]\n",
      "accuracy score correspond to random state 86 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.46      0.62        39\n",
      "         1.0       0.80      0.99      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.72      0.75       123\n",
      "weighted avg       0.85      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 87 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 88 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.46      0.62        39\n",
      "         1.0       0.80      0.99      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.72      0.75       123\n",
      "weighted avg       0.85      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 89 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.37      0.53        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.85      0.68      0.69       123\n",
      "weighted avg       0.82      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[15 26]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 90 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.41      0.51        32\n",
      "         1.0       0.82      0.93      0.87        91\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.75      0.67      0.69       123\n",
      "weighted avg       0.78      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[13 19]\n",
      " [ 6 85]]\n",
      "accuracy score correspond to random state 91 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.37      0.52        46\n",
      "         1.0       0.72      0.97      0.83        77\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.81      0.67      0.68       123\n",
      "weighted avg       0.79      0.75      0.71       123\n",
      "\n",
      "confusion matrix is [[17 29]\n",
      " [ 2 75]]\n",
      "accuracy score correspond to random state 92 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.39      0.54        41\n",
      "         1.0       0.76      0.98      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.68      0.70       123\n",
      "weighted avg       0.80      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 2 80]]\n",
      "accuracy score correspond to random state 93 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.60        33\n",
      "         1.0       0.83      1.00      0.90        90\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.91      0.71      0.75       123\n",
      "weighted avg       0.87      0.85      0.82       123\n",
      "\n",
      "confusion matrix is [[14 19]\n",
      " [ 0 90]]\n",
      "accuracy score correspond to random state 94 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.45      0.60        47\n",
      "         1.0       0.74      0.97      0.84        76\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.83      0.71      0.72       123\n",
      "weighted avg       0.81      0.77      0.75       123\n",
      "\n",
      "confusion matrix is [[21 26]\n",
      " [ 2 74]]\n",
      "accuracy score correspond to random state 95 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.39      0.54        44\n",
      "         1.0       0.74      0.97      0.84        79\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.82      0.68      0.69       123\n",
      "weighted avg       0.80      0.76      0.73       123\n",
      "\n",
      "confusion matrix is [[17 27]\n",
      " [ 2 77]]\n",
      "accuracy score correspond to random state 96 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.39      0.55        33\n",
      "         1.0       0.82      0.99      0.89        90\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.85      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[13 20]\n",
      " [ 1 89]]\n",
      "accuracy score correspond to random state 97 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        37\n",
      "         1.0       0.81      0.99      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.88      0.72      0.75       123\n",
      "weighted avg       0.85      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[17 20]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 98 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.32      0.46        41\n",
      "         1.0       0.74      0.96      0.84        82\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.78      0.64      0.65       123\n",
      "weighted avg       0.76      0.75      0.71       123\n",
      "\n",
      "confusion matrix is [[13 28]\n",
      " [ 3 79]]\n",
      "accuracy score correspond to random state 99 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.38      0.52        48\n",
      "         1.0       0.71      0.96      0.81        75\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.78      0.67      0.67       123\n",
      "weighted avg       0.76      0.73      0.70       123\n",
      "\n",
      "confusion matrix is [[18 30]\n",
      " [ 3 72]]\n",
      "accuracy score correspond to random state 100 is: 0.7317073170731707\n",
      "max Accuracyscore corresponsds to  63 is: 0.8780487804878049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxraccuracy_score(lregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=42,test_size=0.20)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_neighbors\":[5,10,15,20,25,30]}\n",
    "gkcv=GridSearchCV(estimator=KNeighborsClassifier(),param_grid=parameters)\n",
    "gkcv.fit(x_train,y_train)\n",
    "print(gkcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.59        43\n",
      "         1.0       0.76      1.00      0.86        80\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.71      0.73       123\n",
      "weighted avg       0.85      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[18 25]\n",
      " [ 0 80]]\n",
      "accuracy score correspond to random state 42 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.42      0.58        38\n",
      "         1.0       0.79      0.99      0.88        85\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.87      0.70      0.73       123\n",
      "weighted avg       0.84      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[16 22]\n",
      " [ 1 84]]\n",
      "accuracy score correspond to random state 43 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61        32\n",
      "         1.0       0.84      0.98      0.90        91\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.86      0.72      0.76       123\n",
      "weighted avg       0.85      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[15 17]\n",
      " [ 2 89]]\n",
      "accuracy score correspond to random state 44 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.57        45\n",
      "         1.0       0.74      1.00      0.85        78\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.87      0.70      0.71       123\n",
      "weighted avg       0.84      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[18 27]\n",
      " [ 0 78]]\n",
      "accuracy score correspond to random state 45 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.41      0.57        34\n",
      "         1.0       0.81      0.99      0.89        89\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.87      0.70      0.73       123\n",
      "weighted avg       0.85      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[14 20]\n",
      " [ 1 88]]\n",
      "accuracy score correspond to random state 46 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.41      0.56        37\n",
      "         1.0       0.79      0.98      0.88        86\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.69      0.72       123\n",
      "weighted avg       0.82      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[15 22]\n",
      " [ 2 84]]\n",
      "accuracy score correspond to random state 47 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.24      0.38        37\n",
      "         1.0       0.75      0.99      0.85        86\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.62      0.62       123\n",
      "weighted avg       0.80      0.76      0.71       123\n",
      "\n",
      "confusion matrix is [[ 9 28]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 48 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.40      0.56        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.84      0.82      0.79       123\n",
      "\n",
      "confusion matrix is [[14 21]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 49 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.42      0.57        43\n",
      "         1.0       0.76      0.97      0.85        80\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.70      0.71       123\n",
      "weighted avg       0.81      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[18 25]\n",
      " [ 2 78]]\n",
      "accuracy score correspond to random state 50 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.44      0.62        36\n",
      "         1.0       0.81      1.00      0.90        87\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.91      0.72      0.76       123\n",
      "weighted avg       0.87      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[16 20]\n",
      " [ 0 87]]\n",
      "accuracy score correspond to random state 51 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.49      0.63        39\n",
      "         1.0       0.80      0.98      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.85      0.73      0.76       123\n",
      "weighted avg       0.84      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[19 20]\n",
      " [ 2 82]]\n",
      "accuracy score correspond to random state 52 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.41      0.58        46\n",
      "         1.0       0.74      0.99      0.84        77\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.84      0.70      0.71       123\n",
      "weighted avg       0.82      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[19 27]\n",
      " [ 1 76]]\n",
      "accuracy score correspond to random state 53 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        35\n",
      "         1.0       0.82      0.99      0.90        88\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.88      0.72      0.76       123\n",
      "weighted avg       0.86      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[16 19]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 54 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.30      0.46        46\n",
      "         1.0       0.70      0.99      0.82        77\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.82      0.65      0.64       123\n",
      "weighted avg       0.79      0.73      0.69       123\n",
      "\n",
      "confusion matrix is [[14 32]\n",
      " [ 1 76]]\n",
      "accuracy score correspond to random state 55 is: 0.7317073170731707\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.43      0.59        30\n",
      "         1.0       0.84      0.99      0.91        93\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.89      0.71      0.75       123\n",
      "weighted avg       0.86      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[13 17]\n",
      " [ 1 92]]\n",
      "accuracy score correspond to random state 56 is: 0.8536585365853658\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 57 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57        39\n",
      "         1.0       0.78      0.99      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.70      0.72       123\n",
      "weighted avg       0.83      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 58 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.40      0.56        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.84      0.82      0.79       123\n",
      "\n",
      "confusion matrix is [[14 21]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 59 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.47      0.62        38\n",
      "         1.0       0.81      0.98      0.88        85\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.85      0.73      0.75       123\n",
      "weighted avg       0.83      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[18 20]\n",
      " [ 2 83]]\n",
      "accuracy score correspond to random state 60 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.40      0.52        30\n",
      "         1.0       0.83      0.96      0.89        93\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.79      0.68      0.71       123\n",
      "weighted avg       0.81      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[12 18]\n",
      " [ 4 89]]\n",
      "accuracy score correspond to random state 61 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62        42\n",
      "         1.0       0.78      1.00      0.88        81\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.73      0.75       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 62 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.73        35\n",
      "         1.0       0.85      1.00      0.92        88\n",
      "\n",
      "    accuracy                           0.88       123\n",
      "   macro avg       0.93      0.79      0.82       123\n",
      "weighted avg       0.90      0.88      0.87       123\n",
      "\n",
      "confusion matrix is [[20 15]\n",
      " [ 0 88]]\n",
      "accuracy score correspond to random state 63 is: 0.8780487804878049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.41      0.58        39\n",
      "         1.0       0.79      1.00      0.88        84\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.71      0.73       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 0 84]]\n",
      "accuracy score correspond to random state 64 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        44\n",
      "         1.0       0.74      1.00      0.85        79\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.87      0.68      0.69       123\n",
      "weighted avg       0.83      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[16 28]\n",
      " [ 0 79]]\n",
      "accuracy score correspond to random state 65 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60        35\n",
      "         1.0       0.81      1.00      0.90        88\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.91      0.71      0.75       123\n",
      "weighted avg       0.87      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[15 20]\n",
      " [ 0 88]]\n",
      "accuracy score correspond to random state 66 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61        30\n",
      "         1.0       0.85      0.98      0.91        93\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.86      0.72      0.76       123\n",
      "weighted avg       0.86      0.85      0.84       123\n",
      "\n",
      "confusion matrix is [[14 16]\n",
      " [ 2 91]]\n",
      "accuracy score correspond to random state 67 is: 0.8536585365853658\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.40      0.54        35\n",
      "         1.0       0.80      0.97      0.88        88\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.81      0.68      0.71       123\n",
      "weighted avg       0.81      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[14 21]\n",
      " [ 3 85]]\n",
      "accuracy score correspond to random state 68 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.55      0.70        40\n",
      "         1.0       0.82      0.99      0.90        83\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.89      0.77      0.80       123\n",
      "weighted avg       0.86      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[22 18]\n",
      " [ 1 82]]\n",
      "accuracy score correspond to random state 69 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.44      0.60        41\n",
      "         1.0       0.78      0.99      0.87        82\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.71      0.74       123\n",
      "weighted avg       0.84      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[18 23]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 70 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.25      0.38        36\n",
      "         1.0       0.76      0.98      0.85        87\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.79      0.61      0.62       123\n",
      "weighted avg       0.78      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[ 9 27]\n",
      " [ 2 85]]\n",
      "accuracy score correspond to random state 71 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.47      0.63        34\n",
      "         1.0       0.83      0.99      0.90        89\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.89      0.73      0.77       123\n",
      "weighted avg       0.86      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[16 18]\n",
      " [ 1 88]]\n",
      "accuracy score correspond to random state 72 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60        37\n",
      "         1.0       0.80      1.00      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.90      0.72      0.75       123\n",
      "weighted avg       0.86      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[16 21]\n",
      " [ 0 86]]\n",
      "accuracy score correspond to random state 73 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.45      0.61        47\n",
      "         1.0       0.74      0.99      0.85        76\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.85      0.72      0.73       123\n",
      "weighted avg       0.82      0.78      0.76       123\n",
      "\n",
      "confusion matrix is [[21 26]\n",
      " [ 1 75]]\n",
      "accuracy score correspond to random state 74 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.33      0.48        42\n",
      "         1.0       0.74      0.98      0.84        81\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.81      0.65      0.66       123\n",
      "weighted avg       0.78      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[14 28]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 75 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.44      0.59        39\n",
      "         1.0       0.79      0.98      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.71      0.73       123\n",
      "weighted avg       0.82      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[17 22]\n",
      " [ 2 82]]\n",
      "accuracy score correspond to random state 76 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.47      0.63        40\n",
      "         1.0       0.80      0.99      0.88        83\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.73      0.76       123\n",
      "weighted avg       0.85      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[19 21]\n",
      " [ 1 82]]\n",
      "accuracy score correspond to random state 77 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.41      0.55        34\n",
      "         1.0       0.81      0.97      0.88        89\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.82      0.69      0.72       123\n",
      "weighted avg       0.81      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[14 20]\n",
      " [ 3 86]]\n",
      "accuracy score correspond to random state 78 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 79 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 80 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.45      0.60        33\n",
      "         1.0       0.83      0.98      0.90        90\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.86      0.72      0.75       123\n",
      "weighted avg       0.84      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[15 18]\n",
      " [ 2 88]]\n",
      "accuracy score correspond to random state 81 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.50      0.64        38\n",
      "         1.0       0.81      0.98      0.89        85\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.74      0.77       123\n",
      "weighted avg       0.84      0.83      0.81       123\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is [[19 19]\n",
      " [ 2 83]]\n",
      "accuracy score correspond to random state 82 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.31      0.46        29\n",
      "         1.0       0.82      0.99      0.90        94\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.65      0.68       123\n",
      "weighted avg       0.84      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[ 9 20]\n",
      " [ 1 93]]\n",
      "accuracy score correspond to random state 83 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.44      0.58        41\n",
      "         1.0       0.77      0.96      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.82      0.70      0.72       123\n",
      "weighted avg       0.80      0.79      0.77       123\n",
      "\n",
      "confusion matrix is [[18 23]\n",
      " [ 3 79]]\n",
      "accuracy score correspond to random state 84 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.45      0.60        42\n",
      "         1.0       0.77      0.98      0.86        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.71      0.73       123\n",
      "weighted avg       0.82      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 85 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.36      0.52        45\n",
      "         1.0       0.73      0.99      0.84        78\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.67      0.68       123\n",
      "weighted avg       0.80      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[16 29]\n",
      " [ 1 77]]\n",
      "accuracy score correspond to random state 86 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.46      0.63        39\n",
      "         1.0       0.80      1.00      0.89        84\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.90      0.73      0.76       123\n",
      "weighted avg       0.86      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 0 84]]\n",
      "accuracy score correspond to random state 87 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 88 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.46      0.62        39\n",
      "         1.0       0.80      0.99      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.72      0.75       123\n",
      "weighted avg       0.85      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 89 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.37      0.53        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.85      0.68      0.69       123\n",
      "weighted avg       0.82      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[15 26]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 90 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.41      0.52        32\n",
      "         1.0       0.82      0.95      0.88        91\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.77      0.68      0.70       123\n",
      "weighted avg       0.79      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[13 19]\n",
      " [ 5 86]]\n",
      "accuracy score correspond to random state 91 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.37      0.52        46\n",
      "         1.0       0.72      0.97      0.83        77\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.81      0.67      0.68       123\n",
      "weighted avg       0.79      0.75      0.71       123\n",
      "\n",
      "confusion matrix is [[17 29]\n",
      " [ 2 75]]\n",
      "accuracy score correspond to random state 92 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.39      0.54        41\n",
      "         1.0       0.76      0.98      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.68      0.70       123\n",
      "weighted avg       0.80      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 2 80]]\n",
      "accuracy score correspond to random state 93 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.60        33\n",
      "         1.0       0.83      1.00      0.90        90\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.91      0.71      0.75       123\n",
      "weighted avg       0.87      0.85      0.82       123\n",
      "\n",
      "confusion matrix is [[14 19]\n",
      " [ 0 90]]\n",
      "accuracy score correspond to random state 94 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.45      0.60        47\n",
      "         1.0       0.74      0.97      0.84        76\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.83      0.71      0.72       123\n",
      "weighted avg       0.81      0.77      0.75       123\n",
      "\n",
      "confusion matrix is [[21 26]\n",
      " [ 2 74]]\n",
      "accuracy score correspond to random state 95 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.36      0.52        44\n",
      "         1.0       0.74      0.99      0.84        79\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.84      0.68      0.68       123\n",
      "weighted avg       0.81      0.76      0.73       123\n",
      "\n",
      "confusion matrix is [[16 28]\n",
      " [ 1 78]]\n",
      "accuracy score correspond to random state 96 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.39      0.55        33\n",
      "         1.0       0.82      0.99      0.89        90\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.85      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[13 20]\n",
      " [ 1 89]]\n",
      "accuracy score correspond to random state 97 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        37\n",
      "         1.0       0.81      0.99      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.88      0.72      0.75       123\n",
      "weighted avg       0.85      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[17 20]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 98 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.29      0.44        41\n",
      "         1.0       0.73      0.98      0.84        82\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.80      0.63      0.64       123\n",
      "weighted avg       0.78      0.75      0.70       123\n",
      "\n",
      "confusion matrix is [[12 29]\n",
      " [ 2 80]]\n",
      "accuracy score correspond to random state 99 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.38      0.53        48\n",
      "         1.0       0.71      0.97      0.82        75\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.80      0.67      0.67       123\n",
      "weighted avg       0.78      0.74      0.71       123\n",
      "\n",
      "confusion matrix is [[18 30]\n",
      " [ 2 73]]\n",
      "accuracy score correspond to random state 100 is: 0.7398373983739838\n",
      "max Accuracyscore corresponsds to  63 is: 0.8780487804878049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kregr=KNeighborsClassifier(n_neighbors=15)\n",
    "maxraccuracy_score(Kregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    }
   ],
   "source": [
    "parameters={\"criterion\":[\"ginni\",\"entropy\"]}\n",
    "gscv=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=parameters)\n",
    "gscv.fit(x_train,y_train)\n",
    "print(gscv.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.42      0.58        43\n",
      "         1.0       0.76      0.99      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.70      0.72       123\n",
      "weighted avg       0.83      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[18 25]\n",
      " [ 1 79]]\n",
      "accuracy score correspond to random state 42 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.42      0.58        38\n",
      "         1.0       0.79      0.99      0.88        85\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.87      0.70      0.73       123\n",
      "weighted avg       0.84      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[16 22]\n",
      " [ 1 84]]\n",
      "accuracy score correspond to random state 43 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.44      0.58        32\n",
      "         1.0       0.83      0.98      0.90        91\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.85      0.71      0.74       123\n",
      "weighted avg       0.84      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[14 18]\n",
      " [ 2 89]]\n",
      "accuracy score correspond to random state 44 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.38      0.55        45\n",
      "         1.0       0.74      1.00      0.85        78\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.87      0.69      0.70       123\n",
      "weighted avg       0.83      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[17 28]\n",
      " [ 0 78]]\n",
      "accuracy score correspond to random state 45 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.44      0.59        34\n",
      "         1.0       0.82      0.98      0.89        89\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.85      0.71      0.74       123\n",
      "weighted avg       0.84      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 19]\n",
      " [ 2 87]]\n",
      "accuracy score correspond to random state 46 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57        37\n",
      "         1.0       0.79      0.99      0.88        86\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.87      0.70      0.72       123\n",
      "weighted avg       0.84      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[15 22]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 47 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.24      0.38        37\n",
      "         1.0       0.75      0.99      0.85        86\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.62      0.62       123\n",
      "weighted avg       0.80      0.76      0.71       123\n",
      "\n",
      "confusion matrix is [[ 9 28]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 48 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.40      0.56        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.84      0.82      0.79       123\n",
      "\n",
      "confusion matrix is [[14 21]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 49 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.44      0.59        43\n",
      "         1.0       0.76      0.97      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.83      0.71      0.73       123\n",
      "weighted avg       0.81      0.79      0.77       123\n",
      "\n",
      "confusion matrix is [[19 24]\n",
      " [ 2 78]]\n",
      "accuracy score correspond to random state 50 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.44      0.62        36\n",
      "         1.0       0.81      1.00      0.90        87\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.91      0.72      0.76       123\n",
      "weighted avg       0.87      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[16 20]\n",
      " [ 0 87]]\n",
      "accuracy score correspond to random state 51 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.49      0.63        39\n",
      "         1.0       0.80      0.98      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.85      0.73      0.76       123\n",
      "weighted avg       0.84      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[19 20]\n",
      " [ 2 82]]\n",
      "accuracy score correspond to random state 52 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.43      0.59        46\n",
      "         1.0       0.74      0.97      0.84        77\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.83      0.70      0.72       123\n",
      "weighted avg       0.80      0.77      0.75       123\n",
      "\n",
      "confusion matrix is [[20 26]\n",
      " [ 2 75]]\n",
      "accuracy score correspond to random state 53 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        35\n",
      "         1.0       0.82      0.99      0.90        88\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.88      0.72      0.76       123\n",
      "weighted avg       0.86      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[16 19]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 54 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.33      0.48        46\n",
      "         1.0       0.71      0.99      0.83        77\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.82      0.66      0.65       123\n",
      "weighted avg       0.80      0.74      0.70       123\n",
      "\n",
      "confusion matrix is [[15 31]\n",
      " [ 1 76]]\n",
      "accuracy score correspond to random state 55 is: 0.7398373983739838\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.40      0.55        30\n",
      "         1.0       0.83      0.98      0.90        93\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.85      0.69      0.72       123\n",
      "weighted avg       0.84      0.84      0.81       123\n",
      "\n",
      "confusion matrix is [[12 18]\n",
      " [ 2 91]]\n",
      "accuracy score correspond to random state 56 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 57 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.41      0.57        39\n",
      "         1.0       0.78      0.99      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.70      0.72       123\n",
      "weighted avg       0.83      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 58 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.37      0.53        35\n",
      "         1.0       0.80      0.99      0.88        88\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.86      0.68      0.71       123\n",
      "weighted avg       0.84      0.81      0.78       123\n",
      "\n",
      "confusion matrix is [[13 22]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 59 is: 0.8130081300813008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.47      0.61        38\n",
      "         1.0       0.80      0.96      0.88        85\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.83      0.72      0.74       123\n",
      "weighted avg       0.82      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[18 20]\n",
      " [ 3 82]]\n",
      "accuracy score correspond to random state 60 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.37      0.49        30\n",
      "         1.0       0.82      0.96      0.89        93\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.78      0.66      0.69       123\n",
      "weighted avg       0.80      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[11 19]\n",
      " [ 4 89]]\n",
      "accuracy score correspond to random state 61 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.45      0.62        42\n",
      "         1.0       0.78      1.00      0.88        81\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.73      0.75       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 62 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.57      0.73        35\n",
      "         1.0       0.85      1.00      0.92        88\n",
      "\n",
      "    accuracy                           0.88       123\n",
      "   macro avg       0.93      0.79      0.82       123\n",
      "weighted avg       0.90      0.88      0.87       123\n",
      "\n",
      "confusion matrix is [[20 15]\n",
      " [ 0 88]]\n",
      "accuracy score correspond to random state 63 is: 0.8780487804878049\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.41      0.58        39\n",
      "         1.0       0.79      1.00      0.88        84\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.89      0.71      0.73       123\n",
      "weighted avg       0.85      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[16 23]\n",
      " [ 0 84]]\n",
      "accuracy score correspond to random state 64 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.36      0.53        44\n",
      "         1.0       0.74      1.00      0.85        79\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.87      0.68      0.69       123\n",
      "weighted avg       0.83      0.77      0.74       123\n",
      "\n",
      "confusion matrix is [[16 28]\n",
      " [ 0 79]]\n",
      "accuracy score correspond to random state 65 is: 0.7723577235772358\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.43      0.59        35\n",
      "         1.0       0.81      0.99      0.89        88\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.88      0.71      0.74       123\n",
      "weighted avg       0.85      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 20]\n",
      " [ 1 87]]\n",
      "accuracy score correspond to random state 66 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.47      0.61        30\n",
      "         1.0       0.85      0.98      0.91        93\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.86      0.72      0.76       123\n",
      "weighted avg       0.86      0.85      0.84       123\n",
      "\n",
      "confusion matrix is [[14 16]\n",
      " [ 2 91]]\n",
      "accuracy score correspond to random state 67 is: 0.8536585365853658\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.37      0.51        35\n",
      "         1.0       0.79      0.97      0.87        88\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.80      0.67      0.69       123\n",
      "weighted avg       0.80      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[13 22]\n",
      " [ 3 85]]\n",
      "accuracy score correspond to random state 68 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.53      0.68        40\n",
      "         1.0       0.81      0.99      0.89        83\n",
      "\n",
      "    accuracy                           0.84       123\n",
      "   macro avg       0.88      0.76      0.78       123\n",
      "weighted avg       0.86      0.84      0.82       123\n",
      "\n",
      "confusion matrix is [[21 19]\n",
      " [ 1 82]]\n",
      "accuracy score correspond to random state 69 is: 0.8373983739837398\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.44      0.60        41\n",
      "         1.0       0.78      0.99      0.87        82\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.86      0.71      0.74       123\n",
      "weighted avg       0.84      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[18 23]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 70 is: 0.8048780487804879\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.25      0.38        36\n",
      "         1.0       0.76      0.98      0.85        87\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.79      0.61      0.62       123\n",
      "weighted avg       0.78      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[ 9 27]\n",
      " [ 2 85]]\n",
      "accuracy score correspond to random state 71 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.47      0.63        34\n",
      "         1.0       0.83      0.99      0.90        89\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.89      0.73      0.77       123\n",
      "weighted avg       0.86      0.85      0.83       123\n",
      "\n",
      "confusion matrix is [[16 18]\n",
      " [ 1 88]]\n",
      "accuracy score correspond to random state 72 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.43      0.60        37\n",
      "         1.0       0.80      1.00      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.90      0.72      0.75       123\n",
      "weighted avg       0.86      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[16 21]\n",
      " [ 0 86]]\n",
      "accuracy score correspond to random state 73 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.47      0.62        47\n",
      "         1.0       0.75      0.97      0.85        76\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.72      0.73       123\n",
      "weighted avg       0.81      0.78      0.76       123\n",
      "\n",
      "confusion matrix is [[22 25]\n",
      " [ 2 74]]\n",
      "accuracy score correspond to random state 74 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.36      0.51        42\n",
      "         1.0       0.75      0.98      0.84        81\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.81      0.67      0.68       123\n",
      "weighted avg       0.79      0.76      0.73       123\n",
      "\n",
      "confusion matrix is [[15 27]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 75 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.44      0.58        39\n",
      "         1.0       0.79      0.96      0.87        84\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.82      0.70      0.72       123\n",
      "weighted avg       0.81      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 22]\n",
      " [ 3 81]]\n",
      "accuracy score correspond to random state 76 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.47      0.62        40\n",
      "         1.0       0.79      0.98      0.88        83\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.85      0.73      0.75       123\n",
      "weighted avg       0.83      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[19 21]\n",
      " [ 2 81]]\n",
      "accuracy score correspond to random state 77 is: 0.8130081300813008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.41      0.55        34\n",
      "         1.0       0.81      0.97      0.88        89\n",
      "\n",
      "    accuracy                           0.81       123\n",
      "   macro avg       0.82      0.69      0.72       123\n",
      "weighted avg       0.81      0.81      0.79       123\n",
      "\n",
      "confusion matrix is [[14 20]\n",
      " [ 3 86]]\n",
      "accuracy score correspond to random state 78 is: 0.8130081300813008\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 79 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.40      0.58        42\n",
      "         1.0       0.76      1.00      0.87        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.88      0.70      0.72       123\n",
      "weighted avg       0.84      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 0 81]]\n",
      "accuracy score correspond to random state 80 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.45      0.59        33\n",
      "         1.0       0.83      0.97      0.89        90\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.83      0.71      0.74       123\n",
      "weighted avg       0.83      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[15 18]\n",
      " [ 3 87]]\n",
      "accuracy score correspond to random state 81 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.50      0.64        38\n",
      "         1.0       0.81      0.98      0.89        85\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.74      0.77       123\n",
      "weighted avg       0.84      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[19 19]\n",
      " [ 2 83]]\n",
      "accuracy score correspond to random state 82 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.31      0.46        29\n",
      "         1.0       0.82      0.99      0.90        94\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.86      0.65      0.68       123\n",
      "weighted avg       0.84      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[ 9 20]\n",
      " [ 1 93]]\n",
      "accuracy score correspond to random state 83 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.41      0.56        41\n",
      "         1.0       0.77      0.96      0.85        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.81      0.69      0.71       123\n",
      "weighted avg       0.79      0.78      0.76       123\n",
      "\n",
      "confusion matrix is [[17 24]\n",
      " [ 3 79]]\n",
      "accuracy score correspond to random state 84 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.45      0.60        42\n",
      "         1.0       0.77      0.98      0.86        81\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.84      0.71      0.73       123\n",
      "weighted avg       0.82      0.80      0.77       123\n",
      "\n",
      "confusion matrix is [[19 23]\n",
      " [ 2 79]]\n",
      "accuracy score correspond to random state 85 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.36      0.52        45\n",
      "         1.0       0.73      0.99      0.84        78\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.83      0.67      0.68       123\n",
      "weighted avg       0.80      0.76      0.72       123\n",
      "\n",
      "confusion matrix is [[16 29]\n",
      " [ 1 77]]\n",
      "accuracy score correspond to random state 86 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.46      0.63        39\n",
      "         1.0       0.80      1.00      0.89        84\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.90      0.73      0.76       123\n",
      "weighted avg       0.86      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 0 84]]\n",
      "accuracy score correspond to random state 87 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.39      0.55        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.69      0.71       123\n",
      "weighted avg       0.82      0.79      0.76       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 88 is: 0.7886178861788617\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.46      0.62        39\n",
      "         1.0       0.80      0.99      0.88        84\n",
      "\n",
      "    accuracy                           0.82       123\n",
      "   macro avg       0.87      0.72      0.75       123\n",
      "weighted avg       0.85      0.82      0.80       123\n",
      "\n",
      "confusion matrix is [[18 21]\n",
      " [ 1 83]]\n",
      "accuracy score correspond to random state 89 is: 0.8211382113821138\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.37      0.53        41\n",
      "         1.0       0.76      0.99      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.85      0.68      0.69       123\n",
      "weighted avg       0.82      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[15 26]\n",
      " [ 1 81]]\n",
      "accuracy score correspond to random state 90 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.41      0.51        32\n",
      "         1.0       0.82      0.93      0.87        91\n",
      "\n",
      "    accuracy                           0.80       123\n",
      "   macro avg       0.75      0.67      0.69       123\n",
      "weighted avg       0.78      0.80      0.78       123\n",
      "\n",
      "confusion matrix is [[13 19]\n",
      " [ 6 85]]\n",
      "accuracy score correspond to random state 91 is: 0.7967479674796748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.37      0.52        46\n",
      "         1.0       0.72      0.97      0.83        77\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.81      0.67      0.68       123\n",
      "weighted avg       0.79      0.75      0.71       123\n",
      "\n",
      "confusion matrix is [[17 29]\n",
      " [ 2 75]]\n",
      "accuracy score correspond to random state 92 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.39      0.54        41\n",
      "         1.0       0.76      0.98      0.86        82\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.83      0.68      0.70       123\n",
      "weighted avg       0.80      0.78      0.75       123\n",
      "\n",
      "confusion matrix is [[16 25]\n",
      " [ 2 80]]\n",
      "accuracy score correspond to random state 93 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.42      0.60        33\n",
      "         1.0       0.83      1.00      0.90        90\n",
      "\n",
      "    accuracy                           0.85       123\n",
      "   macro avg       0.91      0.71      0.75       123\n",
      "weighted avg       0.87      0.85      0.82       123\n",
      "\n",
      "confusion matrix is [[14 19]\n",
      " [ 0 90]]\n",
      "accuracy score correspond to random state 94 is: 0.8455284552845529\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.45      0.60        47\n",
      "         1.0       0.74      0.97      0.84        76\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.83      0.71      0.72       123\n",
      "weighted avg       0.81      0.77      0.75       123\n",
      "\n",
      "confusion matrix is [[21 26]\n",
      " [ 2 74]]\n",
      "accuracy score correspond to random state 95 is: 0.7723577235772358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.39      0.54        44\n",
      "         1.0       0.74      0.97      0.84        79\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.82      0.68      0.69       123\n",
      "weighted avg       0.80      0.76      0.73       123\n",
      "\n",
      "confusion matrix is [[17 27]\n",
      " [ 2 77]]\n",
      "accuracy score correspond to random state 96 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.39      0.55        33\n",
      "         1.0       0.82      0.99      0.89        90\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.87      0.69      0.72       123\n",
      "weighted avg       0.85      0.83      0.80       123\n",
      "\n",
      "confusion matrix is [[13 20]\n",
      " [ 1 89]]\n",
      "accuracy score correspond to random state 97 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.46      0.62        37\n",
      "         1.0       0.81      0.99      0.89        86\n",
      "\n",
      "    accuracy                           0.83       123\n",
      "   macro avg       0.88      0.72      0.75       123\n",
      "weighted avg       0.85      0.83      0.81       123\n",
      "\n",
      "confusion matrix is [[17 20]\n",
      " [ 1 85]]\n",
      "accuracy score correspond to random state 98 is: 0.8292682926829268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.32      0.46        41\n",
      "         1.0       0.74      0.96      0.84        82\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.78      0.64      0.65       123\n",
      "weighted avg       0.76      0.75      0.71       123\n",
      "\n",
      "confusion matrix is [[13 28]\n",
      " [ 3 79]]\n",
      "accuracy score correspond to random state 99 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.38      0.52        48\n",
      "         1.0       0.71      0.96      0.81        75\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.78      0.67      0.67       123\n",
      "weighted avg       0.76      0.73      0.70       123\n",
      "\n",
      "confusion matrix is [[18 30]\n",
      " [ 3 72]]\n",
      "accuracy score correspond to random state 100 is: 0.7317073170731707\n",
      "max Accuracyscore corresponsds to  63 is: 0.8780487804878049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adregr=AdaBoostClassifier(n_estimators=50,base_estimator=lregr)\n",
    "maxraccuracy_score(adregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.51      0.52        43\n",
      "         1.0       0.74      0.76      0.75        80\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.64      0.64      0.64       123\n",
      "weighted avg       0.67      0.67      0.67       123\n",
      "\n",
      "confusion matrix is [[22 21]\n",
      " [19 61]]\n",
      "accuracy score correspond to random state 42 is: 0.6747967479674797\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.61      0.55        38\n",
      "         1.0       0.81      0.74      0.77        85\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.66      0.67      0.66       123\n",
      "weighted avg       0.72      0.70      0.71       123\n",
      "\n",
      "confusion matrix is [[23 15]\n",
      " [22 63]]\n",
      "accuracy score correspond to random state 43 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.62      0.60        32\n",
      "         1.0       0.86      0.84      0.85        91\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.72      0.73      0.72       123\n",
      "weighted avg       0.79      0.78      0.78       123\n",
      "\n",
      "confusion matrix is [[20 12]\n",
      " [15 76]]\n",
      "accuracy score correspond to random state 44 is: 0.7804878048780488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.47      0.53        45\n",
      "         1.0       0.73      0.83      0.78        78\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.67      0.65      0.66       123\n",
      "weighted avg       0.69      0.70      0.69       123\n",
      "\n",
      "confusion matrix is [[21 24]\n",
      " [13 65]]\n",
      "accuracy score correspond to random state 45 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.53      0.47        34\n",
      "         1.0       0.80      0.73      0.76        89\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.62      0.63      0.62       123\n",
      "weighted avg       0.70      0.67      0.68       123\n",
      "\n",
      "confusion matrix is [[18 16]\n",
      " [24 65]]\n",
      "accuracy score correspond to random state 46 is: 0.6747967479674797\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.51      0.47        37\n",
      "         1.0       0.77      0.71      0.74        86\n",
      "\n",
      "    accuracy                           0.65       123\n",
      "   macro avg       0.60      0.61      0.60       123\n",
      "weighted avg       0.67      0.65      0.66       123\n",
      "\n",
      "confusion matrix is [[19 18]\n",
      " [25 61]]\n",
      "accuracy score correspond to random state 47 is: 0.6504065040650406\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.43      0.42        37\n",
      "         1.0       0.75      0.73      0.74        86\n",
      "\n",
      "    accuracy                           0.64       123\n",
      "   macro avg       0.58      0.58      0.58       123\n",
      "weighted avg       0.65      0.64      0.64       123\n",
      "\n",
      "confusion matrix is [[16 21]\n",
      " [23 63]]\n",
      "accuracy score correspond to random state 48 is: 0.6422764227642277\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.54      0.50        35\n",
      "         1.0       0.80      0.75      0.78        88\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.63      0.65      0.64       123\n",
      "weighted avg       0.71      0.69      0.70       123\n",
      "\n",
      "confusion matrix is [[19 16]\n",
      " [22 66]]\n",
      "accuracy score correspond to random state 49 is: 0.6910569105691057\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.58      0.61        43\n",
      "         1.0       0.79      0.82      0.80        80\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.71      0.70      0.71       123\n",
      "weighted avg       0.74      0.74      0.74       123\n",
      "\n",
      "confusion matrix is [[25 18]\n",
      " [14 66]]\n",
      "accuracy score correspond to random state 50 is: 0.7398373983739838\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.44      0.48        36\n",
      "         1.0       0.78      0.84      0.81        87\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.66      0.64      0.65       123\n",
      "weighted avg       0.71      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[16 20]\n",
      " [14 73]]\n",
      "accuracy score correspond to random state 51 is: 0.7235772357723578\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.62      0.61        39\n",
      "         1.0       0.82      0.81      0.81        84\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.71      0.71      0.71       123\n",
      "weighted avg       0.75      0.75      0.75       123\n",
      "\n",
      "confusion matrix is [[24 15]\n",
      " [16 68]]\n",
      "accuracy score correspond to random state 52 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.57      0.61        46\n",
      "         1.0       0.76      0.83      0.80        77\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.71      0.70      0.70       123\n",
      "weighted avg       0.73      0.73      0.73       123\n",
      "\n",
      "confusion matrix is [[26 20]\n",
      " [13 64]]\n",
      "accuracy score correspond to random state 53 is: 0.7317073170731707\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.69      0.62        35\n",
      "         1.0       0.86      0.78      0.82        88\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.71      0.73      0.72       123\n",
      "weighted avg       0.78      0.76      0.76       123\n",
      "\n",
      "confusion matrix is [[24 11]\n",
      " [19 69]]\n",
      "accuracy score correspond to random state 54 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.41      0.49        46\n",
      "         1.0       0.70      0.83      0.76        77\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.65      0.62      0.62       123\n",
      "weighted avg       0.66      0.67      0.66       123\n",
      "\n",
      "confusion matrix is [[19 27]\n",
      " [13 64]]\n",
      "accuracy score correspond to random state 55 is: 0.6747967479674797\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.53      0.47        30\n",
      "         1.0       0.84      0.76      0.80        93\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.63      0.65      0.63       123\n",
      "weighted avg       0.73      0.71      0.72       123\n",
      "\n",
      "confusion matrix is [[16 14]\n",
      " [22 71]]\n",
      "accuracy score correspond to random state 56 is: 0.7073170731707317\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.55      0.54        42\n",
      "         1.0       0.76      0.75      0.76        81\n",
      "\n",
      "    accuracy                           0.68       123\n",
      "   macro avg       0.65      0.65      0.65       123\n",
      "weighted avg       0.68      0.68      0.68       123\n",
      "\n",
      "confusion matrix is [[23 19]\n",
      " [20 61]]\n",
      "accuracy score correspond to random state 57 is: 0.6829268292682927\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.54      0.55        39\n",
      "         1.0       0.79      0.80      0.79        84\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.67      0.67      0.67       123\n",
      "weighted avg       0.71      0.72      0.71       123\n",
      "\n",
      "confusion matrix is [[21 18]\n",
      " [17 67]]\n",
      "accuracy score correspond to random state 58 is: 0.7154471544715447\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.46      0.46        35\n",
      "         1.0       0.79      0.80      0.79        88\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.63      0.63      0.63       123\n",
      "weighted avg       0.70      0.70      0.70       123\n",
      "\n",
      "confusion matrix is [[16 19]\n",
      " [18 70]]\n",
      "accuracy score correspond to random state 59 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.58      0.54        38\n",
      "         1.0       0.80      0.75      0.78        85\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.66      0.67      0.66       123\n",
      "weighted avg       0.71      0.70      0.70       123\n",
      "\n",
      "confusion matrix is [[22 16]\n",
      " [21 64]]\n",
      "accuracy score correspond to random state 60 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.60      0.53        30\n",
      "         1.0       0.86      0.78      0.82        93\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.67      0.69      0.67       123\n",
      "weighted avg       0.76      0.74      0.75       123\n",
      "\n",
      "confusion matrix is [[18 12]\n",
      " [20 73]]\n",
      "accuracy score correspond to random state 61 is: 0.7398373983739838\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.55      0.52        42\n",
      "         1.0       0.75      0.70      0.73        81\n",
      "\n",
      "    accuracy                           0.65       123\n",
      "   macro avg       0.62      0.63      0.62       123\n",
      "weighted avg       0.66      0.65      0.65       123\n",
      "\n",
      "confusion matrix is [[23 19]\n",
      " [24 57]]\n",
      "accuracy score correspond to random state 62 is: 0.6504065040650406\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.57      0.56        35\n",
      "         1.0       0.83      0.82      0.82        88\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.69      0.69      0.69       123\n",
      "weighted avg       0.75      0.75      0.75       123\n",
      "\n",
      "confusion matrix is [[20 15]\n",
      " [16 72]]\n",
      "accuracy score correspond to random state 63 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.54      0.53        39\n",
      "         1.0       0.78      0.76      0.77        84\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.65      0.65      0.65       123\n",
      "weighted avg       0.70      0.69      0.69       123\n",
      "\n",
      "confusion matrix is [[21 18]\n",
      " [20 64]]\n",
      "accuracy score correspond to random state 64 is: 0.6910569105691057\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.61      0.65        44\n",
      "         1.0       0.80      0.85      0.82        79\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.74      0.73      0.74       123\n",
      "weighted avg       0.76      0.76      0.76       123\n",
      "\n",
      "confusion matrix is [[27 17]\n",
      " [12 67]]\n",
      "accuracy score correspond to random state 65 is: 0.7642276422764228\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.41      0.46      0.43        35\n",
      "         1.0       0.77      0.74      0.76        88\n",
      "\n",
      "    accuracy                           0.66       123\n",
      "   macro avg       0.59      0.60      0.59       123\n",
      "weighted avg       0.67      0.66      0.66       123\n",
      "\n",
      "confusion matrix is [[16 19]\n",
      " [23 65]]\n",
      "accuracy score correspond to random state 66 is: 0.6585365853658537\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.67      0.56        30\n",
      "         1.0       0.88      0.77      0.82        93\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.68      0.72      0.69       123\n",
      "weighted avg       0.78      0.75      0.76       123\n",
      "\n",
      "confusion matrix is [[20 10]\n",
      " [21 72]]\n",
      "accuracy score correspond to random state 67 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.57      0.54        35\n",
      "         1.0       0.82      0.78      0.80        88\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.67      0.68      0.67       123\n",
      "weighted avg       0.73      0.72      0.73       123\n",
      "\n",
      "confusion matrix is [[20 15]\n",
      " [19 69]]\n",
      "accuracy score correspond to random state 68 is: 0.7235772357723578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.72      0.66        40\n",
      "         1.0       0.85      0.77      0.81        83\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.73      0.75      0.73       123\n",
      "weighted avg       0.77      0.76      0.76       123\n",
      "\n",
      "confusion matrix is [[29 11]\n",
      " [19 64]]\n",
      "accuracy score correspond to random state 69 is: 0.7560975609756098\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.56      0.58        41\n",
      "         1.0       0.79      0.82      0.80        82\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.70      0.69      0.69       123\n",
      "weighted avg       0.73      0.73      0.73       123\n",
      "\n",
      "confusion matrix is [[23 18]\n",
      " [15 67]]\n",
      "accuracy score correspond to random state 70 is: 0.7317073170731707\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.42      0.45        36\n",
      "         1.0       0.77      0.82      0.79        87\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.63      0.62      0.62       123\n",
      "weighted avg       0.69      0.70      0.69       123\n",
      "\n",
      "confusion matrix is [[15 21]\n",
      " [16 71]]\n",
      "accuracy score correspond to random state 71 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.56      0.51        34\n",
      "         1.0       0.82      0.76      0.79        89\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.65      0.66      0.65       123\n",
      "weighted avg       0.72      0.71      0.71       123\n",
      "\n",
      "confusion matrix is [[19 15]\n",
      " [21 68]]\n",
      "accuracy score correspond to random state 72 is: 0.7073170731707317\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.51      0.53        37\n",
      "         1.0       0.80      0.81      0.80        86\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.67      0.66      0.67       123\n",
      "weighted avg       0.72      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[19 18]\n",
      " [16 70]]\n",
      "accuracy score correspond to random state 73 is: 0.7235772357723578\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.55      0.58        47\n",
      "         1.0       0.74      0.79      0.76        76\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.68      0.67      0.67       123\n",
      "weighted avg       0.69      0.70      0.70       123\n",
      "\n",
      "confusion matrix is [[26 21]\n",
      " [16 60]]\n",
      "accuracy score correspond to random state 74 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.40      0.52        42\n",
      "         1.0       0.75      0.91      0.82        81\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.73      0.66      0.67       123\n",
      "weighted avg       0.73      0.74      0.72       123\n",
      "\n",
      "confusion matrix is [[17 25]\n",
      " [ 7 74]]\n",
      "accuracy score correspond to random state 75 is: 0.7398373983739838\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.59      0.60        39\n",
      "         1.0       0.81      0.82      0.82        84\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.71      0.71      0.71       123\n",
      "weighted avg       0.75      0.75      0.75       123\n",
      "\n",
      "confusion matrix is [[23 16]\n",
      " [15 69]]\n",
      "accuracy score correspond to random state 76 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.62      0.58        40\n",
      "         1.0       0.81      0.75      0.77        83\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.67      0.69      0.68       123\n",
      "weighted avg       0.72      0.71      0.71       123\n",
      "\n",
      "confusion matrix is [[25 15]\n",
      " [21 62]]\n",
      "accuracy score correspond to random state 77 is: 0.7073170731707317\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.50      0.44        34\n",
      "         1.0       0.79      0.71      0.75        89\n",
      "\n",
      "    accuracy                           0.65       123\n",
      "   macro avg       0.59      0.60      0.59       123\n",
      "weighted avg       0.68      0.65      0.66       123\n",
      "\n",
      "confusion matrix is [[17 17]\n",
      " [26 63]]\n",
      "accuracy score correspond to random state 78 is: 0.6504065040650406\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.54      0.59        41\n",
      "         1.0       0.79      0.85      0.82        82\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.72      0.70      0.70       123\n",
      "weighted avg       0.74      0.75      0.74       123\n",
      "\n",
      "confusion matrix is [[22 19]\n",
      " [12 70]]\n",
      "accuracy score correspond to random state 79 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.55      0.57        42\n",
      "         1.0       0.78      0.81      0.80        81\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.69      0.68      0.69       123\n",
      "weighted avg       0.72      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[23 19]\n",
      " [15 66]]\n",
      "accuracy score correspond to random state 80 is: 0.7235772357723578\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.58      0.52        33\n",
      "         1.0       0.83      0.77      0.80        90\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.65      0.67      0.66       123\n",
      "weighted avg       0.74      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[19 14]\n",
      " [21 69]]\n",
      "accuracy score correspond to random state 81 is: 0.7154471544715447\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.66      0.60        38\n",
      "         1.0       0.83      0.76      0.80        85\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.69      0.71      0.70       123\n",
      "weighted avg       0.75      0.73      0.74       123\n",
      "\n",
      "confusion matrix is [[25 13]\n",
      " [20 65]]\n",
      "accuracy score correspond to random state 82 is: 0.7317073170731707\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.48      0.42        29\n",
      "         1.0       0.83      0.76      0.79        94\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.60      0.62      0.61       123\n",
      "weighted avg       0.72      0.69      0.70       123\n",
      "\n",
      "confusion matrix is [[14 15]\n",
      " [23 71]]\n",
      "accuracy score correspond to random state 83 is: 0.6910569105691057\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.51      0.53        41\n",
      "         1.0       0.76      0.78      0.77        82\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.65      0.65      0.65       123\n",
      "weighted avg       0.69      0.69      0.69       123\n",
      "\n",
      "confusion matrix is [[21 20]\n",
      " [18 64]]\n",
      "accuracy score correspond to random state 84 is: 0.6910569105691057\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.52      0.54        42\n",
      "         1.0       0.76      0.79      0.78        81\n",
      "\n",
      "    accuracy                           0.70       123\n",
      "   macro avg       0.66      0.66      0.66       123\n",
      "weighted avg       0.69      0.70      0.70       123\n",
      "\n",
      "confusion matrix is [[22 20]\n",
      " [17 64]]\n",
      "accuracy score correspond to random state 85 is: 0.6991869918699187\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.40      0.46        45\n",
      "         1.0       0.70      0.79      0.74        78\n",
      "\n",
      "    accuracy                           0.65       123\n",
      "   macro avg       0.61      0.60      0.60       123\n",
      "weighted avg       0.64      0.65      0.64       123\n",
      "\n",
      "confusion matrix is [[18 27]\n",
      " [16 62]]\n",
      "accuracy score correspond to random state 86 is: 0.6504065040650406\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.54      0.52        39\n",
      "         1.0       0.78      0.75      0.76        84\n",
      "\n",
      "    accuracy                           0.68       123\n",
      "   macro avg       0.64      0.64      0.64       123\n",
      "weighted avg       0.69      0.68      0.69       123\n",
      "\n",
      "confusion matrix is [[21 18]\n",
      " [21 63]]\n",
      "accuracy score correspond to random state 87 is: 0.6829268292682927\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.63      0.60        41\n",
      "         1.0       0.81      0.76      0.78        82\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.69      0.70      0.69       123\n",
      "weighted avg       0.73      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[26 15]\n",
      " [20 62]]\n",
      "accuracy score correspond to random state 88 is: 0.7154471544715447\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.54      0.51        39\n",
      "         1.0       0.78      0.74      0.76        84\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.63      0.64      0.63       123\n",
      "weighted avg       0.68      0.67      0.68       123\n",
      "\n",
      "confusion matrix is [[21 18]\n",
      " [22 62]]\n",
      "accuracy score correspond to random state 89 is: 0.6747967479674797\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.51      0.58        41\n",
      "         1.0       0.78      0.87      0.82        82\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.72      0.69      0.70       123\n",
      "weighted avg       0.74      0.75      0.74       123\n",
      "\n",
      "confusion matrix is [[21 20]\n",
      " [11 71]]\n",
      "accuracy score correspond to random state 90 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.53      0.49        32\n",
      "         1.0       0.83      0.78      0.80        91\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.64      0.66      0.65       123\n",
      "weighted avg       0.73      0.72      0.72       123\n",
      "\n",
      "confusion matrix is [[17 15]\n",
      " [20 71]]\n",
      "accuracy score correspond to random state 91 is: 0.7154471544715447\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.52      0.55        46\n",
      "         1.0       0.73      0.77      0.75        77\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.65      0.64      0.65       123\n",
      "weighted avg       0.67      0.67      0.67       123\n",
      "\n",
      "confusion matrix is [[24 22]\n",
      " [18 59]]\n",
      "accuracy score correspond to random state 92 is: 0.6747967479674797\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.59      0.55        41\n",
      "         1.0       0.78      0.73      0.75        82\n",
      "\n",
      "    accuracy                           0.68       123\n",
      "   macro avg       0.65      0.66      0.65       123\n",
      "weighted avg       0.69      0.68      0.69       123\n",
      "\n",
      "confusion matrix is [[24 17]\n",
      " [22 60]]\n",
      "accuracy score correspond to random state 93 is: 0.6829268292682927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.48      0.41        33\n",
      "         1.0       0.78      0.68      0.73        90\n",
      "\n",
      "    accuracy                           0.63       123\n",
      "   macro avg       0.57      0.58      0.57       123\n",
      "weighted avg       0.67      0.63      0.64       123\n",
      "\n",
      "confusion matrix is [[16 17]\n",
      " [29 61]]\n",
      "accuracy score correspond to random state 94 is: 0.6260162601626016\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.51      0.52        47\n",
      "         1.0       0.70      0.71      0.71        76\n",
      "\n",
      "    accuracy                           0.63       123\n",
      "   macro avg       0.61      0.61      0.61       123\n",
      "weighted avg       0.63      0.63      0.63       123\n",
      "\n",
      "confusion matrix is [[24 23]\n",
      " [22 54]]\n",
      "accuracy score correspond to random state 95 is: 0.6341463414634146\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.48      0.58        44\n",
      "         1.0       0.76      0.90      0.82        79\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.74      0.69      0.70       123\n",
      "weighted avg       0.74      0.75      0.73       123\n",
      "\n",
      "confusion matrix is [[21 23]\n",
      " [ 8 71]]\n",
      "accuracy score correspond to random state 96 is: 0.7479674796747967\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.55      0.50        33\n",
      "         1.0       0.82      0.77      0.79        90\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.64      0.66      0.65       123\n",
      "weighted avg       0.72      0.71      0.71       123\n",
      "\n",
      "confusion matrix is [[18 15]\n",
      " [21 69]]\n",
      "accuracy score correspond to random state 97 is: 0.7073170731707317\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.65      0.57        37\n",
      "         1.0       0.83      0.73      0.78        86\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.67      0.69      0.67       123\n",
      "weighted avg       0.73      0.71      0.72       123\n",
      "\n",
      "confusion matrix is [[24 13]\n",
      " [23 63]]\n",
      "accuracy score correspond to random state 98 is: 0.7073170731707317\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.54      0.57        41\n",
      "         1.0       0.78      0.83      0.80        82\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.70      0.68      0.69       123\n",
      "weighted avg       0.72      0.73      0.73       123\n",
      "\n",
      "confusion matrix is [[22 19]\n",
      " [14 68]]\n",
      "accuracy score correspond to random state 99 is: 0.7317073170731707\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.52      0.57        48\n",
      "         1.0       0.72      0.80      0.76        75\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.67      0.66      0.66       123\n",
      "weighted avg       0.68      0.69      0.68       123\n",
      "\n",
      "confusion matrix is [[25 23]\n",
      " [15 60]]\n",
      "accuracy score correspond to random state 100 is: 0.6910569105691057\n",
      "max Accuracyscore corresponsds to  44 is: 0.7804878048780488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adregr=AdaBoostClassifier(n_estimators=50,base_estimator=dregr)\n",
    "maxraccuracy_score(adregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81300813, 0.7804878 , 0.7804878 , 0.85365854, 0.81967213])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lregr, x, y, cv=5)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81300813, 0.78861789, 0.78861789, 0.85365854, 0.81967213])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(Kregr, x, y, cv=5)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6       , 0.86666667, 0.86666667, 0.8       , 0.8       ,\n",
       "       0.86666667, 0.86666667, 0.8       , 0.93333333, 0.86666667,\n",
       "       0.06666667, 0.86666667, 1.        , 0.8       , 0.93333333,\n",
       "       0.93333333, 0.8       , 0.86666667, 0.93333333, 0.93333333,\n",
       "       1.        , 0.86666667, 0.8       , 0.86666667, 0.73333333,\n",
       "       0.8       , 0.86666667, 0.86666667, 0.8       , 0.86666667,\n",
       "       0.93333333, 1.        , 1.        , 0.8       , 0.66666667,\n",
       "       0.06666667, 0.8       , 0.86666667, 0.93333333, 0.73333333,\n",
       "       0.8       , 1.        , 0.8       , 0.86666667, 1.        ,\n",
       "       0.86666667, 0.8       , 0.13333333, 0.13333333, 0.        ,\n",
       "       0.86666667, 0.66666667, 0.13333333, 0.73333333, 0.8       ,\n",
       "       0.93333333, 0.73333333, 0.86666667, 0.13333333, 0.86666667,\n",
       "       0.6       , 0.86666667, 0.06666667, 0.73333333, 0.93333333,\n",
       "       0.8       , 0.86666667, 0.93333333, 0.86666667, 0.66666667,\n",
       "       0.        , 0.93333333, 0.93333333, 0.86666667, 0.13333333,\n",
       "       0.86666667, 0.93333333, 0.06666667, 0.        , 0.8       ,\n",
       "       0.86666667, 0.73333333, 0.86666667, 0.93333333, 0.86666667,\n",
       "       0.8       , 0.8       , 0.06666667, 1.        , 0.73333333,\n",
       "       0.93333333, 0.06666667, 0.13333333, 0.86666667, 1.        ,\n",
       "       0.93333333, 0.8       , 0.93333333, 0.8       , 0.86666667,\n",
       "       1.        , 0.93333333, 0.66666667, 0.86666667, 0.8       ,\n",
       "       0.06666667, 0.86666667, 0.06666667, 0.86666667, 0.86666667,\n",
       "       0.66666667, 0.06666667, 0.86666667, 0.73333333, 0.8       ,\n",
       "       0.93333333, 0.86666667, 0.86666667, 0.8       , 0.86666667,\n",
       "       0.93333333, 0.93333333, 0.8       ])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auc_Roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_prob=Kregr.predict_proba(x_test)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.11627907, 0.3255814 , 0.41860465,\n",
       "       0.51162791, 0.58139535, 0.58139535, 0.72093023, 0.93023256,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.    , 0.1125, 0.3125, 0.65  , 0.9   , 0.95  , 0.975 , 1.    ,\n",
       "       1.    , 1.    , 1.    ])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title(\"KNeighborsClassifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=63,test_size=0.20)\n",
    "\n",
    "# From the analysis it is clear that KNeighborsClassifier & Logistic Regression are  the best classifier at random state 63 with a accuracy score of 87\n",
    "# saving a file\n",
    "import pickle\n",
    "filename=\"picklekregr.pkl\"\n",
    "pickle.dump(KNeighborsClassifier,open(filename,\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
