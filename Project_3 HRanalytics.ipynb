{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2061</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2062</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0      41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1      49        No  Travel_Frequently        279  Research & Development   \n",
       "2      37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3      33        No  Travel_Frequently       1392  Research & Development   \n",
       "4      27        No      Travel_Rarely        591  Research & Development   \n",
       "...   ...       ...                ...        ...                     ...   \n",
       "1465   36        No  Travel_Frequently        884  Research & Development   \n",
       "1466   39        No      Travel_Rarely        613  Research & Development   \n",
       "1467   27        No      Travel_Rarely        155  Research & Development   \n",
       "1468   49        No  Travel_Frequently       1023                   Sales   \n",
       "1469   34        No      Travel_Rarely        628  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  \\\n",
       "0                    1          2  Life Sciences              1   \n",
       "1                    8          1  Life Sciences              1   \n",
       "2                    2          2          Other              1   \n",
       "3                    3          4  Life Sciences              1   \n",
       "4                    2          1        Medical              1   \n",
       "...                ...        ...            ...            ...   \n",
       "1465                23          2        Medical              1   \n",
       "1466                 6          1        Medical              1   \n",
       "1467                 4          3  Life Sciences              1   \n",
       "1468                 2          3        Medical              1   \n",
       "1469                 8          3        Medical              1   \n",
       "\n",
       "      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n",
       "0                  1  ...                         1            80   \n",
       "1                  2  ...                         4            80   \n",
       "2                  4  ...                         2            80   \n",
       "3                  5  ...                         3            80   \n",
       "4                  7  ...                         4            80   \n",
       "...              ...  ...                       ...           ...   \n",
       "1465            2061  ...                         3            80   \n",
       "1466            2062  ...                         1            80   \n",
       "1467            2064  ...                         2            80   \n",
       "1468            2065  ...                         4            80   \n",
       "1469            2068  ...                         1            80   \n",
       "\n",
       "      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                    0                  8                      0   \n",
       "1                    1                 10                      3   \n",
       "2                    0                  7                      3   \n",
       "3                    0                  8                      3   \n",
       "4                    1                  6                      3   \n",
       "...                ...                ...                    ...   \n",
       "1465                 1                 17                      3   \n",
       "1466                 1                  9                      5   \n",
       "1467                 1                  6                      0   \n",
       "1468                 0                 17                      3   \n",
       "1469                 0                  6                      3   \n",
       "\n",
       "     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                  1               6                  4   \n",
       "1                  3              10                  7   \n",
       "2                  3               0                  0   \n",
       "3                  3               8                  7   \n",
       "4                  3               2                  2   \n",
       "...              ...             ...                ...   \n",
       "1465               3               5                  2   \n",
       "1466               3               7                  7   \n",
       "1467               3               6                  2   \n",
       "1468               2               9                  6   \n",
       "1469               4               4                  3   \n",
       "\n",
       "      YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                           0                     5  \n",
       "1                           1                     7  \n",
       "2                           0                     0  \n",
       "3                           3                     0  \n",
       "4                           2                     2  \n",
       "...                       ...                   ...  \n",
       "1465                        0                     3  \n",
       "1466                        1                     7  \n",
       "1467                        0                     3  \n",
       "1468                        0                     8  \n",
       "1469                        1                     2  \n",
       "\n",
       "[1470 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "data=pd.read_csv(\"HR_analytics.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2061</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2062</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0      41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1      49        No  Travel_Frequently        279  Research & Development   \n",
       "2      37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3      33        No  Travel_Frequently       1392  Research & Development   \n",
       "4      27        No      Travel_Rarely        591  Research & Development   \n",
       "...   ...       ...                ...        ...                     ...   \n",
       "1465   36        No  Travel_Frequently        884  Research & Development   \n",
       "1466   39        No      Travel_Rarely        613  Research & Development   \n",
       "1467   27        No      Travel_Rarely        155  Research & Development   \n",
       "1468   49        No  Travel_Frequently       1023                   Sales   \n",
       "1469   34        No      Travel_Rarely        628  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  \\\n",
       "0                    1          2  Life Sciences              1   \n",
       "1                    8          1  Life Sciences              1   \n",
       "2                    2          2          Other              1   \n",
       "3                    3          4  Life Sciences              1   \n",
       "4                    2          1        Medical              1   \n",
       "...                ...        ...            ...            ...   \n",
       "1465                23          2        Medical              1   \n",
       "1466                 6          1        Medical              1   \n",
       "1467                 4          3  Life Sciences              1   \n",
       "1468                 2          3        Medical              1   \n",
       "1469                 8          3        Medical              1   \n",
       "\n",
       "      EmployeeNumber  ...  RelationshipSatisfaction StandardHours  \\\n",
       "0                  1  ...                         1            80   \n",
       "1                  2  ...                         4            80   \n",
       "2                  4  ...                         2            80   \n",
       "3                  5  ...                         3            80   \n",
       "4                  7  ...                         4            80   \n",
       "...              ...  ...                       ...           ...   \n",
       "1465            2061  ...                         3            80   \n",
       "1466            2062  ...                         1            80   \n",
       "1467            2064  ...                         2            80   \n",
       "1468            2065  ...                         4            80   \n",
       "1469            2068  ...                         1            80   \n",
       "\n",
       "      StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "0                    0                  8                      0   \n",
       "1                    1                 10                      3   \n",
       "2                    0                  7                      3   \n",
       "3                    0                  8                      3   \n",
       "4                    1                  6                      3   \n",
       "...                ...                ...                    ...   \n",
       "1465                 1                 17                      3   \n",
       "1466                 1                  9                      5   \n",
       "1467                 1                  6                      0   \n",
       "1468                 0                 17                      3   \n",
       "1469                 0                  6                      3   \n",
       "\n",
       "     WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "0                  1               6                  4   \n",
       "1                  3              10                  7   \n",
       "2                  3               0                  0   \n",
       "3                  3               8                  7   \n",
       "4                  3               2                  2   \n",
       "...              ...             ...                ...   \n",
       "1465               3               5                  2   \n",
       "1466               3               7                  7   \n",
       "1467               3               6                  2   \n",
       "1468               2               9                  6   \n",
       "1469               4               4                  3   \n",
       "\n",
       "      YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                           0                     5  \n",
       "1                           1                     7  \n",
       "2                           0                     0  \n",
       "3                           3                     0  \n",
       "4                           2                     2  \n",
       "...                       ...                   ...  \n",
       "1465                        0                     3  \n",
       "1466                        1                     7  \n",
       "1467                        0                     3  \n",
       "1468                        0                     8  \n",
       "1469                        1                     2  \n",
       "\n",
       "[1470 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata=pd.DataFrame(data)\n",
    "df_HRdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
       "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
       "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
       "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
       "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
       "       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
       "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
       "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
       "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
       "       'YearsWithCurrManager'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce4604db20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BIVARIATE ANALYSIS\n",
    "df_HRdata[\"Department\"].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data from categorical form to numerical\n",
    "le=LabelEncoder()\n",
    "df_HRdata[\"Attrition\"]=le.fit_transform(df_HRdata[\"Attrition\"])\n",
    "df_HRdata[\"Department\"]=le.fit_transform(df_HRdata[\"Department\"])\n",
    "df_HRdata[\"EducationField\"]=le.fit_transform(df_HRdata[\"EducationField\"])\n",
    "df_HRdata[\"BusinessTravel\"]=le.fit_transform(df_HRdata[\"BusinessTravel\"])\n",
    "df_HRdata[\"Gender\"]=le.fit_transform(df_HRdata[\"Gender\"])\n",
    "df_HRdata[\"JobRole\"]=le.fit_transform(df_HRdata[\"JobRole\"])\n",
    "df_HRdata[\"MaritalStatus\"]=le.fit_transform(df_HRdata[\"MaritalStatus\"])\n",
    "df_HRdata[\"Over18\"]=le.fit_transform(df_HRdata[\"Over18\"])\n",
    "df_HRdata[\"OverTime\"]=le.fit_transform(df_HRdata[\"OverTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1373</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1392</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2061</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2062</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1023</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Attrition  BusinessTravel  DailyRate  Department  DistanceFromHome  \\\n",
       "0      41          1               2       1102           2                 1   \n",
       "1      49          0               1        279           1                 8   \n",
       "2      37          1               2       1373           1                 2   \n",
       "3      33          0               1       1392           1                 3   \n",
       "4      27          0               2        591           1                 2   \n",
       "...   ...        ...             ...        ...         ...               ...   \n",
       "1465   36          0               1        884           1                23   \n",
       "1466   39          0               2        613           1                 6   \n",
       "1467   27          0               2        155           1                 4   \n",
       "1468   49          0               1       1023           2                 2   \n",
       "1469   34          0               2        628           1                 8   \n",
       "\n",
       "      Education  EducationField  EmployeeCount  EmployeeNumber  ...  \\\n",
       "0             2               1              1               1  ...   \n",
       "1             1               1              1               2  ...   \n",
       "2             2               4              1               4  ...   \n",
       "3             4               1              1               5  ...   \n",
       "4             1               3              1               7  ...   \n",
       "...         ...             ...            ...             ...  ...   \n",
       "1465          2               3              1            2061  ...   \n",
       "1466          1               3              1            2062  ...   \n",
       "1467          3               1              1            2064  ...   \n",
       "1468          3               3              1            2065  ...   \n",
       "1469          3               3              1            2068  ...   \n",
       "\n",
       "      RelationshipSatisfaction  StandardHours  StockOptionLevel  \\\n",
       "0                            1             80                 0   \n",
       "1                            4             80                 1   \n",
       "2                            2             80                 0   \n",
       "3                            3             80                 0   \n",
       "4                            4             80                 1   \n",
       "...                        ...            ...               ...   \n",
       "1465                         3             80                 1   \n",
       "1466                         1             80                 1   \n",
       "1467                         2             80                 1   \n",
       "1468                         4             80                 0   \n",
       "1469                         1             80                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "0                     8                      0                1   \n",
       "1                    10                      3                3   \n",
       "2                     7                      3                3   \n",
       "3                     8                      3                3   \n",
       "4                     6                      3                3   \n",
       "...                 ...                    ...              ...   \n",
       "1465                 17                      3                3   \n",
       "1466                  9                      5                3   \n",
       "1467                  6                      0                3   \n",
       "1468                 17                      3                2   \n",
       "1469                  6                      3                4   \n",
       "\n",
       "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                  6                   4                        0   \n",
       "1                 10                   7                        1   \n",
       "2                  0                   0                        0   \n",
       "3                  8                   7                        3   \n",
       "4                  2                   2                        2   \n",
       "...              ...                 ...                      ...   \n",
       "1465               5                   2                        0   \n",
       "1466               7                   7                        1   \n",
       "1467               6                   2                        0   \n",
       "1468               9                   6                        0   \n",
       "1469               4                   3                        1   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "0                        5  \n",
       "1                        7  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "1465                     3  \n",
       "1466                     7  \n",
       "1467                     3  \n",
       "1468                     8  \n",
       "1469                     2  \n",
       "\n",
       "[1470 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         0\n",
       "Attrition                   0\n",
       "BusinessTravel              0\n",
       "DailyRate                   0\n",
       "Department                  0\n",
       "DistanceFromHome            0\n",
       "Education                   0\n",
       "EducationField              0\n",
       "EmployeeCount               0\n",
       "EmployeeNumber              0\n",
       "EnvironmentSatisfaction     0\n",
       "Gender                      0\n",
       "HourlyRate                  0\n",
       "JobInvolvement              0\n",
       "JobLevel                    0\n",
       "JobRole                     0\n",
       "JobSatisfaction             0\n",
       "MaritalStatus               0\n",
       "MonthlyIncome               0\n",
       "MonthlyRate                 0\n",
       "NumCompaniesWorked          0\n",
       "Over18                      0\n",
       "OverTime                    0\n",
       "PercentSalaryHike           0\n",
       "PerformanceRating           0\n",
       "RelationshipSatisfaction    0\n",
       "StandardHours               0\n",
       "StockOptionLevel            0\n",
       "TotalWorkingYears           0\n",
       "TrainingTimesLastYear       0\n",
       "WorkLifeBalance             0\n",
       "YearsAtCompany              0\n",
       "YearsInCurrentRole          0\n",
       "YearsSinceLastPromotion     0\n",
       "YearsWithCurrManager        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding of NUll Value\n",
    "df_HRdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         int64\n",
       "Attrition                   int32\n",
       "BusinessTravel              int32\n",
       "DailyRate                   int64\n",
       "Department                  int32\n",
       "DistanceFromHome            int64\n",
       "Education                   int64\n",
       "EducationField              int32\n",
       "EmployeeCount               int64\n",
       "EmployeeNumber              int64\n",
       "EnvironmentSatisfaction     int64\n",
       "Gender                      int32\n",
       "HourlyRate                  int64\n",
       "JobInvolvement              int64\n",
       "JobLevel                    int64\n",
       "JobRole                     int32\n",
       "JobSatisfaction             int64\n",
       "MaritalStatus               int32\n",
       "MonthlyIncome               int64\n",
       "MonthlyRate                 int64\n",
       "NumCompaniesWorked          int64\n",
       "Over18                      int32\n",
       "OverTime                    int32\n",
       "PercentSalaryHike           int64\n",
       "PerformanceRating           int64\n",
       "RelationshipSatisfaction    int64\n",
       "StandardHours               int64\n",
       "StockOptionLevel            int64\n",
       "TotalWorkingYears           int64\n",
       "TrainingTimesLastYear       int64\n",
       "WorkLifeBalance             int64\n",
       "YearsAtCompany              int64\n",
       "YearsInCurrentRole          int64\n",
       "YearsSinceLastPromotion     int64\n",
       "YearsWithCurrManager        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.923810</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>1.607483</td>\n",
       "      <td>802.485714</td>\n",
       "      <td>1.260544</td>\n",
       "      <td>9.192517</td>\n",
       "      <td>2.912925</td>\n",
       "      <td>2.247619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024.865306</td>\n",
       "      <td>...</td>\n",
       "      <td>2.712245</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>11.279592</td>\n",
       "      <td>2.799320</td>\n",
       "      <td>2.761224</td>\n",
       "      <td>7.008163</td>\n",
       "      <td>4.229252</td>\n",
       "      <td>2.187755</td>\n",
       "      <td>4.123129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.135373</td>\n",
       "      <td>0.367863</td>\n",
       "      <td>0.665455</td>\n",
       "      <td>403.509100</td>\n",
       "      <td>0.527792</td>\n",
       "      <td>8.106864</td>\n",
       "      <td>1.024165</td>\n",
       "      <td>1.331369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>602.024335</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>7.780782</td>\n",
       "      <td>1.289271</td>\n",
       "      <td>0.706476</td>\n",
       "      <td>6.126525</td>\n",
       "      <td>3.623137</td>\n",
       "      <td>3.222430</td>\n",
       "      <td>3.568136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>491.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1020.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1157.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1555.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2068.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age    Attrition  BusinessTravel    DailyRate   Department  \\\n",
       "count  1470.000000  1470.000000     1470.000000  1470.000000  1470.000000   \n",
       "mean     36.923810     0.161224        1.607483   802.485714     1.260544   \n",
       "std       9.135373     0.367863        0.665455   403.509100     0.527792   \n",
       "min      18.000000     0.000000        0.000000   102.000000     0.000000   \n",
       "25%      30.000000     0.000000        1.000000   465.000000     1.000000   \n",
       "50%      36.000000     0.000000        2.000000   802.000000     1.000000   \n",
       "75%      43.000000     0.000000        2.000000  1157.000000     2.000000   \n",
       "max      60.000000     1.000000        2.000000  1499.000000     2.000000   \n",
       "\n",
       "       DistanceFromHome    Education  EducationField  EmployeeCount  \\\n",
       "count       1470.000000  1470.000000     1470.000000         1470.0   \n",
       "mean           9.192517     2.912925        2.247619            1.0   \n",
       "std            8.106864     1.024165        1.331369            0.0   \n",
       "min            1.000000     1.000000        0.000000            1.0   \n",
       "25%            2.000000     2.000000        1.000000            1.0   \n",
       "50%            7.000000     3.000000        2.000000            1.0   \n",
       "75%           14.000000     4.000000        3.000000            1.0   \n",
       "max           29.000000     5.000000        5.000000            1.0   \n",
       "\n",
       "       EmployeeNumber  ...  RelationshipSatisfaction  StandardHours  \\\n",
       "count     1470.000000  ...               1470.000000         1470.0   \n",
       "mean      1024.865306  ...                  2.712245           80.0   \n",
       "std        602.024335  ...                  1.081209            0.0   \n",
       "min          1.000000  ...                  1.000000           80.0   \n",
       "25%        491.250000  ...                  2.000000           80.0   \n",
       "50%       1020.500000  ...                  3.000000           80.0   \n",
       "75%       1555.750000  ...                  4.000000           80.0   \n",
       "max       2068.000000  ...                  4.000000           80.0   \n",
       "\n",
       "       StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "count       1470.000000        1470.000000            1470.000000   \n",
       "mean           0.793878          11.279592               2.799320   \n",
       "std            0.852077           7.780782               1.289271   \n",
       "min            0.000000           0.000000               0.000000   \n",
       "25%            0.000000           6.000000               2.000000   \n",
       "50%            1.000000          10.000000               3.000000   \n",
       "75%            1.000000          15.000000               3.000000   \n",
       "max            3.000000          40.000000               6.000000   \n",
       "\n",
       "       WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  \\\n",
       "count      1470.000000     1470.000000         1470.000000   \n",
       "mean          2.761224        7.008163            4.229252   \n",
       "std           0.706476        6.126525            3.623137   \n",
       "min           1.000000        0.000000            0.000000   \n",
       "25%           2.000000        3.000000            2.000000   \n",
       "50%           3.000000        5.000000            3.000000   \n",
       "75%           3.000000        9.000000            7.000000   \n",
       "max           4.000000       40.000000           18.000000   \n",
       "\n",
       "       YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "count              1470.000000           1470.000000  \n",
       "mean                  2.187755              4.123129  \n",
       "std                   3.222430              3.568136  \n",
       "min                   0.000000              0.000000  \n",
       "25%                   0.000000              2.000000  \n",
       "50%                   1.000000              3.000000  \n",
       "75%                   3.000000              7.000000  \n",
       "max                  15.000000             17.000000  \n",
       "\n",
       "[8 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.159205</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>-0.031882</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.208034</td>\n",
       "      <td>-0.040873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037510</td>\n",
       "      <td>0.680381</td>\n",
       "      <td>-0.019621</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>0.311309</td>\n",
       "      <td>0.212901</td>\n",
       "      <td>0.216513</td>\n",
       "      <td>0.202089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attrition</th>\n",
       "      <td>-0.159205</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.056652</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>0.077924</td>\n",
       "      <td>-0.031373</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137145</td>\n",
       "      <td>-0.171063</td>\n",
       "      <td>-0.059478</td>\n",
       "      <td>-0.063939</td>\n",
       "      <td>-0.134392</td>\n",
       "      <td>-0.160545</td>\n",
       "      <td>-0.033019</td>\n",
       "      <td>-0.156199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BusinessTravel</th>\n",
       "      <td>0.024751</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004086</td>\n",
       "      <td>-0.009044</td>\n",
       "      <td>-0.024469</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>-0.011256</td>\n",
       "      <td>-0.014575</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>-0.032591</td>\n",
       "      <td>-0.022636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyRate</th>\n",
       "      <td>0.010661</td>\n",
       "      <td>-0.056652</td>\n",
       "      <td>-0.004086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>-0.016806</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042143</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>-0.037848</td>\n",
       "      <td>-0.034055</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>-0.033229</td>\n",
       "      <td>-0.026363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department</th>\n",
       "      <td>-0.031882</td>\n",
       "      <td>0.063991</td>\n",
       "      <td>-0.009044</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>-0.015762</td>\n",
       "      <td>0.036875</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.056315</td>\n",
       "      <td>0.040061</td>\n",
       "      <td>0.034282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.077924</td>\n",
       "      <td>-0.024469</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021042</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>-0.036942</td>\n",
       "      <td>-0.026556</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.014406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>0.208034</td>\n",
       "      <td>-0.031373</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>-0.016806</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>0.021042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>0.148280</td>\n",
       "      <td>-0.025100</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.069114</td>\n",
       "      <td>0.060236</td>\n",
       "      <td>0.054254</td>\n",
       "      <td>0.069065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EducationField</th>\n",
       "      <td>-0.040873</td>\n",
       "      <td>0.026846</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>-0.039592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016185</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>0.049195</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>-0.010506</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>-0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmployeeCount</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <td>-0.010145</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>-0.015578</td>\n",
       "      <td>-0.050990</td>\n",
       "      <td>-0.010895</td>\n",
       "      <td>0.032916</td>\n",
       "      <td>0.042070</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>-0.014365</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>-0.011240</td>\n",
       "      <td>-0.008416</td>\n",
       "      <td>-0.009019</td>\n",
       "      <td>-0.009197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <td>0.010146</td>\n",
       "      <td>-0.103369</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>-0.019395</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>-0.027128</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>-0.002693</td>\n",
       "      <td>-0.019359</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>-0.004999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.036311</td>\n",
       "      <td>0.029453</td>\n",
       "      <td>-0.032981</td>\n",
       "      <td>-0.011716</td>\n",
       "      <td>-0.041583</td>\n",
       "      <td>-0.001851</td>\n",
       "      <td>-0.016547</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012716</td>\n",
       "      <td>-0.046881</td>\n",
       "      <td>-0.038787</td>\n",
       "      <td>-0.002753</td>\n",
       "      <td>-0.029747</td>\n",
       "      <td>-0.041483</td>\n",
       "      <td>-0.026985</td>\n",
       "      <td>-0.030599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyRate</th>\n",
       "      <td>0.024287</td>\n",
       "      <td>-0.006846</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>0.031131</td>\n",
       "      <td>0.016775</td>\n",
       "      <td>-0.021941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050263</td>\n",
       "      <td>-0.002334</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>-0.004607</td>\n",
       "      <td>-0.019582</td>\n",
       "      <td>-0.024106</td>\n",
       "      <td>-0.026716</td>\n",
       "      <td>-0.020123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobInvolvement</th>\n",
       "      <td>0.029820</td>\n",
       "      <td>-0.130016</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.046135</td>\n",
       "      <td>-0.024586</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.042438</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>-0.005533</td>\n",
       "      <td>-0.015338</td>\n",
       "      <td>-0.014617</td>\n",
       "      <td>-0.021355</td>\n",
       "      <td>0.008717</td>\n",
       "      <td>-0.024184</td>\n",
       "      <td>0.025976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobLevel</th>\n",
       "      <td>0.509604</td>\n",
       "      <td>-0.169105</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.101963</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.101589</td>\n",
       "      <td>-0.044933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>0.782208</td>\n",
       "      <td>-0.018191</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>0.534739</td>\n",
       "      <td>0.389447</td>\n",
       "      <td>0.353885</td>\n",
       "      <td>0.375281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobRole</th>\n",
       "      <td>-0.122427</td>\n",
       "      <td>0.067151</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>-0.009472</td>\n",
       "      <td>0.662431</td>\n",
       "      <td>-0.001015</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.019171</td>\n",
       "      <td>-0.145439</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.027764</td>\n",
       "      <td>-0.083657</td>\n",
       "      <td>-0.028354</td>\n",
       "      <td>-0.046384</td>\n",
       "      <td>-0.041150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <td>-0.004892</td>\n",
       "      <td>-0.103481</td>\n",
       "      <td>-0.033962</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>-0.011296</td>\n",
       "      <td>-0.034401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>-0.020185</td>\n",
       "      <td>-0.005779</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.003803</td>\n",
       "      <td>-0.002305</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>-0.027656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaritalStatus</th>\n",
       "      <td>-0.095029</td>\n",
       "      <td>0.162070</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>-0.069586</td>\n",
       "      <td>0.056073</td>\n",
       "      <td>-0.014437</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.662577</td>\n",
       "      <td>-0.077886</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>0.014708</td>\n",
       "      <td>-0.059986</td>\n",
       "      <td>-0.065822</td>\n",
       "      <td>-0.030915</td>\n",
       "      <td>-0.038570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <td>0.497855</td>\n",
       "      <td>-0.159840</td>\n",
       "      <td>0.034319</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>-0.017014</td>\n",
       "      <td>0.094961</td>\n",
       "      <td>-0.041070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.772893</td>\n",
       "      <td>-0.021736</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.514285</td>\n",
       "      <td>0.363818</td>\n",
       "      <td>0.344978</td>\n",
       "      <td>0.344079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MonthlyRate</th>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>-0.014107</td>\n",
       "      <td>-0.032182</td>\n",
       "      <td>0.023642</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.026084</td>\n",
       "      <td>-0.027182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034323</td>\n",
       "      <td>0.026442</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.023655</td>\n",
       "      <td>-0.012815</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>-0.036746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <td>0.299635</td>\n",
       "      <td>0.043494</td>\n",
       "      <td>0.020875</td>\n",
       "      <td>0.038153</td>\n",
       "      <td>-0.035882</td>\n",
       "      <td>-0.029251</td>\n",
       "      <td>0.126317</td>\n",
       "      <td>-0.008663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.237639</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>-0.008366</td>\n",
       "      <td>-0.118421</td>\n",
       "      <td>-0.090754</td>\n",
       "      <td>-0.036814</td>\n",
       "      <td>-0.110319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Over18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverTime</th>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.246118</td>\n",
       "      <td>0.016543</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.025514</td>\n",
       "      <td>-0.020322</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>-0.079113</td>\n",
       "      <td>-0.027092</td>\n",
       "      <td>-0.011687</td>\n",
       "      <td>-0.029758</td>\n",
       "      <td>-0.012239</td>\n",
       "      <td>-0.041586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <td>0.003634</td>\n",
       "      <td>-0.013478</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.007840</td>\n",
       "      <td>0.040235</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-0.011214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.012944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.020608</td>\n",
       "      <td>-0.005221</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.035991</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>-0.011985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PerformanceRating</th>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>-0.026341</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>-0.024604</td>\n",
       "      <td>0.027110</td>\n",
       "      <td>-0.024539</td>\n",
       "      <td>-0.005614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>-0.015579</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.034986</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.022827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <td>0.053535</td>\n",
       "      <td>-0.045872</td>\n",
       "      <td>-0.035986</td>\n",
       "      <td>0.007846</td>\n",
       "      <td>-0.022414</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>-0.009118</td>\n",
       "      <td>-0.004378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.069861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>-0.015123</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>-0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StandardHours</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <td>0.037510</td>\n",
       "      <td>-0.137145</td>\n",
       "      <td>-0.016727</td>\n",
       "      <td>0.042143</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>-0.016185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062227</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.050818</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.024698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <td>0.680381</td>\n",
       "      <td>-0.171063</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>-0.015762</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.148280</td>\n",
       "      <td>-0.027848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024054</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.035662</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.628133</td>\n",
       "      <td>0.460365</td>\n",
       "      <td>0.404858</td>\n",
       "      <td>0.459188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <td>-0.019621</td>\n",
       "      <td>-0.059478</td>\n",
       "      <td>0.015240</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.036875</td>\n",
       "      <td>-0.036942</td>\n",
       "      <td>-0.025100</td>\n",
       "      <td>0.049195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>-0.035662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.004096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.063939</td>\n",
       "      <td>-0.011256</td>\n",
       "      <td>-0.037848</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>-0.026556</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.041191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.028072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <td>0.311309</td>\n",
       "      <td>-0.134392</td>\n",
       "      <td>-0.014575</td>\n",
       "      <td>-0.034055</td>\n",
       "      <td>0.022920</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.069114</td>\n",
       "      <td>-0.018692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.628133</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.758754</td>\n",
       "      <td>0.618409</td>\n",
       "      <td>0.769212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <td>0.212901</td>\n",
       "      <td>-0.160545</td>\n",
       "      <td>-0.011497</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.056315</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>0.060236</td>\n",
       "      <td>-0.010506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050818</td>\n",
       "      <td>0.460365</td>\n",
       "      <td>-0.005738</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>0.758754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.548056</td>\n",
       "      <td>0.714365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <td>0.216513</td>\n",
       "      <td>-0.033019</td>\n",
       "      <td>-0.032591</td>\n",
       "      <td>-0.033229</td>\n",
       "      <td>0.040061</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.054254</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>0.404858</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.008941</td>\n",
       "      <td>0.618409</td>\n",
       "      <td>0.548056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <td>0.202089</td>\n",
       "      <td>-0.156199</td>\n",
       "      <td>-0.022636</td>\n",
       "      <td>-0.026363</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>0.069065</td>\n",
       "      <td>-0.004130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.459188</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.769212</td>\n",
       "      <td>0.714365</td>\n",
       "      <td>0.510224</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Age  Attrition  BusinessTravel  DailyRate  \\\n",
       "Age                       1.000000  -0.159205        0.024751   0.010661   \n",
       "Attrition                -0.159205   1.000000        0.000074  -0.056652   \n",
       "BusinessTravel            0.024751   0.000074        1.000000  -0.004086   \n",
       "DailyRate                 0.010661  -0.056652       -0.004086   1.000000   \n",
       "Department               -0.031882   0.063991       -0.009044   0.007109   \n",
       "DistanceFromHome         -0.001686   0.077924       -0.024469  -0.004985   \n",
       "Education                 0.208034  -0.031373        0.000757  -0.016806   \n",
       "EducationField           -0.040873   0.026846        0.023724   0.037709   \n",
       "EmployeeCount                  NaN        NaN             NaN        NaN   \n",
       "EmployeeNumber           -0.010145  -0.010577       -0.015578  -0.050990   \n",
       "EnvironmentSatisfaction   0.010146  -0.103369        0.004174   0.018355   \n",
       "Gender                   -0.036311   0.029453       -0.032981  -0.011716   \n",
       "HourlyRate                0.024287  -0.006846        0.026528   0.023381   \n",
       "JobInvolvement            0.029820  -0.130016        0.039062   0.046135   \n",
       "JobLevel                  0.509604  -0.169105        0.019311   0.002966   \n",
       "JobRole                  -0.122427   0.067151        0.002724  -0.009472   \n",
       "JobSatisfaction          -0.004892  -0.103481       -0.033962   0.030571   \n",
       "MaritalStatus            -0.095029   0.162070        0.024001  -0.069586   \n",
       "MonthlyIncome             0.497855  -0.159840        0.034319   0.007707   \n",
       "MonthlyRate               0.028051   0.015170       -0.014107  -0.032182   \n",
       "NumCompaniesWorked        0.299635   0.043494        0.020875   0.038153   \n",
       "Over18                         NaN        NaN             NaN        NaN   \n",
       "OverTime                  0.028062   0.246118        0.016543   0.009135   \n",
       "PercentSalaryHike         0.003634  -0.013478       -0.029377   0.022704   \n",
       "PerformanceRating         0.001904   0.002889       -0.026341   0.000473   \n",
       "RelationshipSatisfaction  0.053535  -0.045872       -0.035986   0.007846   \n",
       "StandardHours                  NaN        NaN             NaN        NaN   \n",
       "StockOptionLevel          0.037510  -0.137145       -0.016727   0.042143   \n",
       "TotalWorkingYears         0.680381  -0.171063        0.034226   0.014515   \n",
       "TrainingTimesLastYear    -0.019621  -0.059478        0.015240   0.002453   \n",
       "WorkLifeBalance          -0.021490  -0.063939       -0.011256  -0.037848   \n",
       "YearsAtCompany            0.311309  -0.134392       -0.014575  -0.034055   \n",
       "YearsInCurrentRole        0.212901  -0.160545       -0.011497   0.009932   \n",
       "YearsSinceLastPromotion   0.216513  -0.033019       -0.032591  -0.033229   \n",
       "YearsWithCurrManager      0.202089  -0.156199       -0.022636  -0.026363   \n",
       "\n",
       "                          Department  DistanceFromHome  Education  \\\n",
       "Age                        -0.031882         -0.001686   0.208034   \n",
       "Attrition                   0.063991          0.077924  -0.031373   \n",
       "BusinessTravel             -0.009044         -0.024469   0.000757   \n",
       "DailyRate                   0.007109         -0.004985  -0.016806   \n",
       "Department                  1.000000          0.017225   0.007996   \n",
       "DistanceFromHome            0.017225          1.000000   0.021042   \n",
       "Education                   0.007996          0.021042   1.000000   \n",
       "EducationField              0.013720          0.002013  -0.039592   \n",
       "EmployeeCount                    NaN               NaN        NaN   \n",
       "EmployeeNumber             -0.010895          0.032916   0.042070   \n",
       "EnvironmentSatisfaction    -0.019395         -0.016075  -0.027128   \n",
       "Gender                     -0.041583         -0.001851  -0.016547   \n",
       "HourlyRate                 -0.004144          0.031131   0.016775   \n",
       "JobInvolvement             -0.024586          0.008783   0.042438   \n",
       "JobLevel                    0.101963          0.005303   0.101589   \n",
       "JobRole                     0.662431         -0.001015   0.004236   \n",
       "JobSatisfaction             0.021001         -0.003669  -0.011296   \n",
       "MaritalStatus               0.056073         -0.014437   0.004053   \n",
       "MonthlyIncome               0.053130         -0.017014   0.094961   \n",
       "MonthlyRate                 0.023642          0.027473  -0.026084   \n",
       "NumCompaniesWorked         -0.035882         -0.029251   0.126317   \n",
       "Over18                           NaN               NaN        NaN   \n",
       "OverTime                    0.007481          0.025514  -0.020322   \n",
       "PercentSalaryHike          -0.007840          0.040235  -0.011111   \n",
       "PerformanceRating          -0.024604          0.027110  -0.024539   \n",
       "RelationshipSatisfaction   -0.022414          0.006557  -0.009118   \n",
       "StandardHours                    NaN               NaN        NaN   \n",
       "StockOptionLevel           -0.012193          0.044872   0.018422   \n",
       "TotalWorkingYears          -0.015762          0.004628   0.148280   \n",
       "TrainingTimesLastYear       0.036875         -0.036942  -0.025100   \n",
       "WorkLifeBalance             0.026383         -0.026556   0.009819   \n",
       "YearsAtCompany              0.022920          0.009508   0.069114   \n",
       "YearsInCurrentRole          0.056315          0.018845   0.060236   \n",
       "YearsSinceLastPromotion     0.040061          0.010029   0.054254   \n",
       "YearsWithCurrManager        0.034282          0.014406   0.069065   \n",
       "\n",
       "                          EducationField  EmployeeCount  EmployeeNumber  ...  \\\n",
       "Age                            -0.040873            NaN       -0.010145  ...   \n",
       "Attrition                       0.026846            NaN       -0.010577  ...   \n",
       "BusinessTravel                  0.023724            NaN       -0.015578  ...   \n",
       "DailyRate                       0.037709            NaN       -0.050990  ...   \n",
       "Department                      0.013720            NaN       -0.010895  ...   \n",
       "DistanceFromHome                0.002013            NaN        0.032916  ...   \n",
       "Education                      -0.039592            NaN        0.042070  ...   \n",
       "EducationField                  1.000000            NaN       -0.002516  ...   \n",
       "EmployeeCount                        NaN            NaN             NaN  ...   \n",
       "EmployeeNumber                 -0.002516            NaN        1.000000  ...   \n",
       "EnvironmentSatisfaction         0.043163            NaN        0.017621  ...   \n",
       "Gender                         -0.002504            NaN        0.022556  ...   \n",
       "HourlyRate                     -0.021941            NaN        0.035179  ...   \n",
       "JobInvolvement                 -0.002655            NaN       -0.006888  ...   \n",
       "JobLevel                       -0.044933            NaN       -0.018519  ...   \n",
       "JobRole                         0.015599            NaN       -0.010336  ...   \n",
       "JobSatisfaction                -0.034401            NaN       -0.046247  ...   \n",
       "MaritalStatus                   0.014420            NaN       -0.008155  ...   \n",
       "MonthlyIncome                  -0.041070            NaN       -0.014829  ...   \n",
       "MonthlyRate                    -0.027182            NaN        0.012648  ...   \n",
       "NumCompaniesWorked             -0.008663            NaN       -0.001251  ...   \n",
       "Over18                               NaN            NaN             NaN  ...   \n",
       "OverTime                        0.002259            NaN       -0.024037  ...   \n",
       "PercentSalaryHike              -0.011214            NaN       -0.012944  ...   \n",
       "PerformanceRating              -0.005614            NaN       -0.020359  ...   \n",
       "RelationshipSatisfaction       -0.004378            NaN       -0.069861  ...   \n",
       "StandardHours                        NaN            NaN             NaN  ...   \n",
       "StockOptionLevel               -0.016185            NaN        0.062227  ...   \n",
       "TotalWorkingYears              -0.027848            NaN       -0.014365  ...   \n",
       "TrainingTimesLastYear           0.049195            NaN        0.023603  ...   \n",
       "WorkLifeBalance                 0.041191            NaN        0.010309  ...   \n",
       "YearsAtCompany                 -0.018692            NaN       -0.011240  ...   \n",
       "YearsInCurrentRole             -0.010506            NaN       -0.008416  ...   \n",
       "YearsSinceLastPromotion         0.002326            NaN       -0.009019  ...   \n",
       "YearsWithCurrManager           -0.004130            NaN       -0.009197  ...   \n",
       "\n",
       "                          RelationshipSatisfaction  StandardHours  \\\n",
       "Age                                       0.053535            NaN   \n",
       "Attrition                                -0.045872            NaN   \n",
       "BusinessTravel                           -0.035986            NaN   \n",
       "DailyRate                                 0.007846            NaN   \n",
       "Department                               -0.022414            NaN   \n",
       "DistanceFromHome                          0.006557            NaN   \n",
       "Education                                -0.009118            NaN   \n",
       "EducationField                           -0.004378            NaN   \n",
       "EmployeeCount                                  NaN            NaN   \n",
       "EmployeeNumber                           -0.069861            NaN   \n",
       "EnvironmentSatisfaction                   0.007665            NaN   \n",
       "Gender                                    0.022868            NaN   \n",
       "HourlyRate                                0.001330            NaN   \n",
       "JobInvolvement                            0.034297            NaN   \n",
       "JobLevel                                  0.021642            NaN   \n",
       "JobRole                                  -0.020218            NaN   \n",
       "JobSatisfaction                          -0.012454            NaN   \n",
       "MaritalStatus                             0.022549            NaN   \n",
       "MonthlyIncome                             0.025873            NaN   \n",
       "MonthlyRate                              -0.004085            NaN   \n",
       "NumCompaniesWorked                        0.052733            NaN   \n",
       "Over18                                         NaN            NaN   \n",
       "OverTime                                  0.048493            NaN   \n",
       "PercentSalaryHike                        -0.040490            NaN   \n",
       "PerformanceRating                        -0.031351            NaN   \n",
       "RelationshipSatisfaction                  1.000000            NaN   \n",
       "StandardHours                                  NaN            NaN   \n",
       "StockOptionLevel                         -0.045952            NaN   \n",
       "TotalWorkingYears                         0.024054            NaN   \n",
       "TrainingTimesLastYear                     0.002497            NaN   \n",
       "WorkLifeBalance                           0.019604            NaN   \n",
       "YearsAtCompany                            0.019367            NaN   \n",
       "YearsInCurrentRole                       -0.015123            NaN   \n",
       "YearsSinceLastPromotion                   0.033493            NaN   \n",
       "YearsWithCurrManager                     -0.000867            NaN   \n",
       "\n",
       "                          StockOptionLevel  TotalWorkingYears  \\\n",
       "Age                               0.037510           0.680381   \n",
       "Attrition                        -0.137145          -0.171063   \n",
       "BusinessTravel                   -0.016727           0.034226   \n",
       "DailyRate                         0.042143           0.014515   \n",
       "Department                       -0.012193          -0.015762   \n",
       "DistanceFromHome                  0.044872           0.004628   \n",
       "Education                         0.018422           0.148280   \n",
       "EducationField                   -0.016185          -0.027848   \n",
       "EmployeeCount                          NaN                NaN   \n",
       "EmployeeNumber                    0.062227          -0.014365   \n",
       "EnvironmentSatisfaction           0.003432          -0.002693   \n",
       "Gender                            0.012716          -0.046881   \n",
       "HourlyRate                        0.050263          -0.002334   \n",
       "JobInvolvement                    0.021523          -0.005533   \n",
       "JobLevel                          0.013984           0.782208   \n",
       "JobRole                          -0.019171          -0.145439   \n",
       "JobSatisfaction                   0.010690          -0.020185   \n",
       "MaritalStatus                    -0.662577          -0.077886   \n",
       "MonthlyIncome                     0.005408           0.772893   \n",
       "MonthlyRate                      -0.034323           0.026442   \n",
       "NumCompaniesWorked                0.030075           0.237639   \n",
       "Over18                                 NaN                NaN   \n",
       "OverTime                         -0.000449           0.012754   \n",
       "PercentSalaryHike                 0.007528          -0.020608   \n",
       "PerformanceRating                 0.003506           0.006744   \n",
       "RelationshipSatisfaction         -0.045952           0.024054   \n",
       "StandardHours                          NaN                NaN   \n",
       "StockOptionLevel                  1.000000           0.010136   \n",
       "TotalWorkingYears                 0.010136           1.000000   \n",
       "TrainingTimesLastYear             0.011274          -0.035662   \n",
       "WorkLifeBalance                   0.004129           0.001008   \n",
       "YearsAtCompany                    0.015058           0.628133   \n",
       "YearsInCurrentRole                0.050818           0.460365   \n",
       "YearsSinceLastPromotion           0.014352           0.404858   \n",
       "YearsWithCurrManager              0.024698           0.459188   \n",
       "\n",
       "                          TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "Age                                   -0.019621        -0.021490   \n",
       "Attrition                             -0.059478        -0.063939   \n",
       "BusinessTravel                         0.015240        -0.011256   \n",
       "DailyRate                              0.002453        -0.037848   \n",
       "Department                             0.036875         0.026383   \n",
       "DistanceFromHome                      -0.036942        -0.026556   \n",
       "Education                             -0.025100         0.009819   \n",
       "EducationField                         0.049195         0.041191   \n",
       "EmployeeCount                               NaN              NaN   \n",
       "EmployeeNumber                         0.023603         0.010309   \n",
       "EnvironmentSatisfaction               -0.019359         0.027627   \n",
       "Gender                                -0.038787        -0.002753   \n",
       "HourlyRate                            -0.008548        -0.004607   \n",
       "JobInvolvement                        -0.015338        -0.014617   \n",
       "JobLevel                              -0.018191         0.037818   \n",
       "JobRole                                0.001342         0.027764   \n",
       "JobSatisfaction                       -0.005779        -0.019459   \n",
       "MaritalStatus                          0.010629         0.014708   \n",
       "MonthlyIncome                         -0.021736         0.030683   \n",
       "MonthlyRate                            0.001467         0.007963   \n",
       "NumCompaniesWorked                    -0.066054        -0.008366   \n",
       "Over18                                      NaN              NaN   \n",
       "OverTime                              -0.079113        -0.027092   \n",
       "PercentSalaryHike                     -0.005221        -0.003280   \n",
       "PerformanceRating                     -0.015579         0.002572   \n",
       "RelationshipSatisfaction               0.002497         0.019604   \n",
       "StandardHours                               NaN              NaN   \n",
       "StockOptionLevel                       0.011274         0.004129   \n",
       "TotalWorkingYears                     -0.035662         0.001008   \n",
       "TrainingTimesLastYear                  1.000000         0.028072   \n",
       "WorkLifeBalance                        0.028072         1.000000   \n",
       "YearsAtCompany                         0.003569         0.012089   \n",
       "YearsInCurrentRole                    -0.005738         0.049856   \n",
       "YearsSinceLastPromotion               -0.002067         0.008941   \n",
       "YearsWithCurrManager                  -0.004096         0.002759   \n",
       "\n",
       "                          YearsAtCompany  YearsInCurrentRole  \\\n",
       "Age                             0.311309            0.212901   \n",
       "Attrition                      -0.134392           -0.160545   \n",
       "BusinessTravel                 -0.014575           -0.011497   \n",
       "DailyRate                      -0.034055            0.009932   \n",
       "Department                      0.022920            0.056315   \n",
       "DistanceFromHome                0.009508            0.018845   \n",
       "Education                       0.069114            0.060236   \n",
       "EducationField                 -0.018692           -0.010506   \n",
       "EmployeeCount                        NaN                 NaN   \n",
       "EmployeeNumber                 -0.011240           -0.008416   \n",
       "EnvironmentSatisfaction         0.001458            0.018007   \n",
       "Gender                         -0.029747           -0.041483   \n",
       "HourlyRate                     -0.019582           -0.024106   \n",
       "JobInvolvement                 -0.021355            0.008717   \n",
       "JobLevel                        0.534739            0.389447   \n",
       "JobRole                        -0.083657           -0.028354   \n",
       "JobSatisfaction                -0.003803           -0.002305   \n",
       "MaritalStatus                  -0.059986           -0.065822   \n",
       "MonthlyIncome                   0.514285            0.363818   \n",
       "MonthlyRate                    -0.023655           -0.012815   \n",
       "NumCompaniesWorked             -0.118421           -0.090754   \n",
       "Over18                               NaN                 NaN   \n",
       "OverTime                       -0.011687           -0.029758   \n",
       "PercentSalaryHike              -0.035991           -0.001520   \n",
       "PerformanceRating               0.003435            0.034986   \n",
       "RelationshipSatisfaction        0.019367           -0.015123   \n",
       "StandardHours                        NaN                 NaN   \n",
       "StockOptionLevel                0.015058            0.050818   \n",
       "TotalWorkingYears               0.628133            0.460365   \n",
       "TrainingTimesLastYear           0.003569           -0.005738   \n",
       "WorkLifeBalance                 0.012089            0.049856   \n",
       "YearsAtCompany                  1.000000            0.758754   \n",
       "YearsInCurrentRole              0.758754            1.000000   \n",
       "YearsSinceLastPromotion         0.618409            0.548056   \n",
       "YearsWithCurrManager            0.769212            0.714365   \n",
       "\n",
       "                          YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "Age                                      0.216513              0.202089  \n",
       "Attrition                               -0.033019             -0.156199  \n",
       "BusinessTravel                          -0.032591             -0.022636  \n",
       "DailyRate                               -0.033229             -0.026363  \n",
       "Department                               0.040061              0.034282  \n",
       "DistanceFromHome                         0.010029              0.014406  \n",
       "Education                                0.054254              0.069065  \n",
       "EducationField                           0.002326             -0.004130  \n",
       "EmployeeCount                                 NaN                   NaN  \n",
       "EmployeeNumber                          -0.009019             -0.009197  \n",
       "EnvironmentSatisfaction                  0.016194             -0.004999  \n",
       "Gender                                  -0.026985             -0.030599  \n",
       "HourlyRate                              -0.026716             -0.020123  \n",
       "JobInvolvement                          -0.024184              0.025976  \n",
       "JobLevel                                 0.353885              0.375281  \n",
       "JobRole                                 -0.046384             -0.041150  \n",
       "JobSatisfaction                         -0.018214             -0.027656  \n",
       "MaritalStatus                           -0.030915             -0.038570  \n",
       "MonthlyIncome                            0.344978              0.344079  \n",
       "MonthlyRate                              0.001567             -0.036746  \n",
       "NumCompaniesWorked                      -0.036814             -0.110319  \n",
       "Over18                                        NaN                   NaN  \n",
       "OverTime                                -0.012239             -0.041586  \n",
       "PercentSalaryHike                       -0.022154             -0.011985  \n",
       "PerformanceRating                        0.017896              0.022827  \n",
       "RelationshipSatisfaction                 0.033493             -0.000867  \n",
       "StandardHours                                 NaN                   NaN  \n",
       "StockOptionLevel                         0.014352              0.024698  \n",
       "TotalWorkingYears                        0.404858              0.459188  \n",
       "TrainingTimesLastYear                   -0.002067             -0.004096  \n",
       "WorkLifeBalance                          0.008941              0.002759  \n",
       "YearsAtCompany                           0.618409              0.769212  \n",
       "YearsInCurrentRole                       0.548056              0.714365  \n",
       "YearsSinceLastPromotion                  1.000000              0.510224  \n",
       "YearsWithCurrManager                     0.510224              1.000000  \n",
       "\n",
       "[35 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_HRdata.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce46797eb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df_HRdata.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(df_HRdata[\"Attrition\"],df_HRdata[\"DistanceFromHome\"])\n",
    "plt.xlabel(\"Attrition\")\n",
    "plt.ylabel(\"DistanceFromHome\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce469adee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata[\"WorkLifeBalance\"].value_counts().plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE478FE790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47915280>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE479397C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE4795AF40>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47983700>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE479A5DC0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE479A5EB0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46823AC0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46B7C940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46FBD6D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47410CA0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE473E64F0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47761F10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46882EE0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE4772A430>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE469C8130>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47320580>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE477959D0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE472C1E20>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE474CA2E0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47498730>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47368BB0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE4748D0A0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE474E55E0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE474EA8E0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE4753BD30>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE475661C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE475AA610>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE473AAA60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46924EB0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001CE47601340>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE469BF790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE46994BE0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE477E80D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE469624C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001CE469E5850>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 36 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata.hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce46bd6ca0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata[\"NumCompaniesWorked\"].value_counts().plot(kind='barh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce46b05280>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata[\"NumCompaniesWorked\"].hist(figsize=(20,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce46b1fee0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata[\"MonthlyIncome\"].hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ce4768bf10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_HRdata[\"Attrition\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the alalysis it is clear that most of the paramets which define the attrition of amployees such as distance from home,income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1373</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1392</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>591</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2061</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>613</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2062</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1023</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2065</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  BusinessTravel  DailyRate  Department  DistanceFromHome  Education  \\\n",
       "0      41               2       1102           2                 1          2   \n",
       "1      49               1        279           1                 8          1   \n",
       "2      37               2       1373           1                 2          2   \n",
       "3      33               1       1392           1                 3          4   \n",
       "4      27               2        591           1                 2          1   \n",
       "...   ...             ...        ...         ...               ...        ...   \n",
       "1465   36               1        884           1                23          2   \n",
       "1466   39               2        613           1                 6          1   \n",
       "1467   27               2        155           1                 4          3   \n",
       "1468   49               1       1023           2                 2          3   \n",
       "1469   34               2        628           1                 8          3   \n",
       "\n",
       "      EducationField  EmployeeCount  EmployeeNumber  EnvironmentSatisfaction  \\\n",
       "0                  1              1               1                        2   \n",
       "1                  1              1               2                        3   \n",
       "2                  4              1               4                        4   \n",
       "3                  1              1               5                        4   \n",
       "4                  3              1               7                        1   \n",
       "...              ...            ...             ...                      ...   \n",
       "1465               3              1            2061                        3   \n",
       "1466               3              1            2062                        4   \n",
       "1467               1              1            2064                        2   \n",
       "1468               3              1            2065                        4   \n",
       "1469               3              1            2068                        2   \n",
       "\n",
       "      ...  RelationshipSatisfaction  StandardHours  StockOptionLevel  \\\n",
       "0     ...                         1             80                 0   \n",
       "1     ...                         4             80                 1   \n",
       "2     ...                         2             80                 0   \n",
       "3     ...                         3             80                 0   \n",
       "4     ...                         4             80                 1   \n",
       "...   ...                       ...            ...               ...   \n",
       "1465  ...                         3             80                 1   \n",
       "1466  ...                         1             80                 1   \n",
       "1467  ...                         2             80                 1   \n",
       "1468  ...                         4             80                 0   \n",
       "1469  ...                         1             80                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "0                     8                      0                1   \n",
       "1                    10                      3                3   \n",
       "2                     7                      3                3   \n",
       "3                     8                      3                3   \n",
       "4                     6                      3                3   \n",
       "...                 ...                    ...              ...   \n",
       "1465                 17                      3                3   \n",
       "1466                  9                      5                3   \n",
       "1467                  6                      0                3   \n",
       "1468                 17                      3                2   \n",
       "1469                  6                      3                4   \n",
       "\n",
       "      YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                  6                   4                        0   \n",
       "1                 10                   7                        1   \n",
       "2                  0                   0                        0   \n",
       "3                  8                   7                        3   \n",
       "4                  2                   2                        2   \n",
       "...              ...                 ...                      ...   \n",
       "1465               5                   2                        0   \n",
       "1466               7                   7                        1   \n",
       "1467               6                   2                        0   \n",
       "1468               9                   6                        0   \n",
       "1469               4                   3                        1   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "0                        5  \n",
       "1                        7  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "1465                     3  \n",
       "1466                     7  \n",
       "1467                     3  \n",
       "1468                     8  \n",
       "1469                     2  \n",
       "\n",
       "[1470 rows x 34 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting of data\n",
    "x=df_HRdata.drop(\"Attrition\",axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_HRdata.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1465    0\n",
       "1466    0\n",
       "1467    0\n",
       "1468    0\n",
       "1469    0\n",
       "Name: Attrition, Length: 1470, dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lregr=LogisticRegression()\n",
    "def maxraccuracy_scrore(regr,x,y):\n",
    "    maxraccuracy_score=0\n",
    "    for r_state in range(42,101):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=r_state,test_size=0.20)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred=regr.predict(x_test)\n",
    "        acc_scr=accuracy_score(y_test,y_pred)\n",
    "        Class_rprt=classification_report(y_test,y_pred)\n",
    "        conf_rprt=confusion_matrix(y_test,y_pred)\n",
    "        print(\"classification report is\",Class_rprt)\n",
    "        print(\"confusion matrix is\",conf_rprt)\n",
    "        print(\"accuracy score correspond to random state\",r_state,\"is:\", acc_scr)\n",
    "        if acc_scr>maxraccuracy_score:\n",
    "            maxraccuracy_score=acc_scr\n",
    "            final_r_state=r_state\n",
    "            \n",
    "    print(\"max Accuracyscore corresponsds to \",final_r_state,\"is:\",maxraccuracy_score)\n",
    "    return final_r_state\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       255\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.75      0.87      0.81       294\n",
      "\n",
      "confusion matrix is [[255   0]\n",
      " [ 39   0]]\n",
      "accuracy score correspond to random state 42 is: 0.8673469387755102\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       232\n",
      "           1       0.67      0.03      0.06        62\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.73      0.51      0.47       294\n",
      "weighted avg       0.77      0.79      0.71       294\n",
      "\n",
      "confusion matrix is [[231   1]\n",
      " [ 60   2]]\n",
      "accuracy score correspond to random state 43 is: 0.7925170068027211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 45   0]]\n",
      "accuracy score correspond to random state 44 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.50      0.02      0.03        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.65      0.51      0.46       294\n",
      "weighted avg       0.75      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[236   1]\n",
      " [ 56   1]]\n",
      "accuracy score correspond to random state 45 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       238\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 56   0]]\n",
      "accuracy score correspond to random state 46 is: 0.8095238095238095\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 47 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 48 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.70      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 49 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       1.00      0.02      0.04        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.91      0.51      0.47       294\n",
      "weighted avg       0.85      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[241   0]\n",
      " [ 52   1]]\n",
      "accuracy score correspond to random state 50 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       248\n",
      "           1       1.00      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 45   1]]\n",
      "accuracy score correspond to random state 51 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       1.00      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.51      0.49       294\n",
      "weighted avg       0.88      0.86      0.80       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 41   1]]\n",
      "accuracy score correspond to random state 52 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       251\n",
      "           1       1.00      0.02      0.05        43\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.51      0.48       294\n",
      "weighted avg       0.88      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 42   1]]\n",
      "accuracy score correspond to random state 53 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[244   1]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 54 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       260\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.44      0.50      0.47       294\n",
      "weighted avg       0.78      0.88      0.83       294\n",
      "\n",
      "confusion matrix is [[259   1]\n",
      " [ 34   0]]\n",
      "accuracy score correspond to random state 55 is: 0.8809523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 56 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       254\n",
      "           1       1.00      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.93      0.51      0.49       294\n",
      "weighted avg       0.89      0.87      0.81       294\n",
      "\n",
      "confusion matrix is [[254   0]\n",
      " [ 39   1]]\n",
      "accuracy score correspond to random state 57 is: 0.8673469387755102\n",
      "classification report is"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[240   1]\n",
      " [ 53   0]]\n",
      "accuracy score correspond to random state 58 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 59 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 60 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       1.00      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 47   1]]\n",
      "accuracy score correspond to random state 61 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       241\n",
      "           1       0.40      0.04      0.07        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.61      0.51      0.48       294\n",
      "weighted avg       0.75      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[238   3]\n",
      " [ 51   2]]\n",
      "accuracy score correspond to random state 62 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 63 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       250\n",
      "           1       1.00      0.05      0.09        44\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.52      0.50       294\n",
      "weighted avg       0.88      0.86      0.80       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 42   2]]\n",
      "accuracy score correspond to random state 64 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       248\n",
      "           1       0.50      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.79      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 45   1]]\n",
      "accuracy score correspond to random state 65 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 66 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.50      0.02      0.05        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.68      0.51      0.48       294\n",
      "weighted avg       0.81      0.86      0.80       294\n",
      "\n",
      "confusion matrix is [[251   1]\n",
      " [ 41   1]]\n",
      "accuracy score correspond to random state 67 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       239\n",
      "           1       1.00      0.02      0.04        55\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.91      0.51      0.47       294\n",
      "weighted avg       0.85      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[239   0]\n",
      " [ 54   1]]\n",
      "accuracy score correspond to random state 68 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       236\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.40      0.50      0.44       294\n",
      "weighted avg       0.64      0.80      0.71       294\n",
      "\n",
      "confusion matrix is [[235   1]\n",
      " [ 58   0]]\n",
      "accuracy score correspond to random state 69 is: 0.7993197278911565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       238\n",
      "           1       1.00      0.02      0.04        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.91      0.51      0.47       294\n",
      "weighted avg       0.85      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 55   1]]\n",
      "accuracy score correspond to random state 70 is: 0.8129251700680272\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 71 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 72 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 73 is: 0.8537414965986394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       245\n",
      "           1       0.50      0.04      0.08        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.67      0.52      0.49       294\n",
      "weighted avg       0.78      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[243   2]\n",
      " [ 47   2]]\n",
      "accuracy score correspond to random state 74 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.65      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[237   0]\n",
      " [ 57   0]]\n",
      "accuracy score correspond to random state 75 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       243\n",
      "           1       1.00      0.06      0.11        51\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.53      0.51       294\n",
      "weighted avg       0.86      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[243   0]\n",
      " [ 48   3]]\n",
      "accuracy score correspond to random state 76 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.91       248\n",
      "           1       0.50      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.79      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 45   1]]\n",
      "accuracy score correspond to random state 77 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 78 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.50      0.02      0.03        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.65      0.51      0.46       294\n",
      "weighted avg       0.75      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[236   1]\n",
      " [ 56   1]]\n",
      "accuracy score correspond to random state 79 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 80 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 81 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 82 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 45   0]]\n",
      "accuracy score correspond to random state 83 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.50      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.78      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 47   1]]\n",
      "accuracy score correspond to random state 84 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 85 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 86 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       243\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[242   1]\n",
      " [ 51   0]]\n",
      "accuracy score correspond to random state 87 is: 0.8231292517006803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       242\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[240   2]\n",
      " [ 52   0]]\n",
      "accuracy score correspond to random state 88 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.50      0.02      0.04        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.51      0.47       294\n",
      "weighted avg       0.76      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[239   1]\n",
      " [ 53   1]]\n",
      "accuracy score correspond to random state 89 is: 0.8163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       1.00      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 47   1]]\n",
      "accuracy score correspond to random state 90 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 91 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       245\n",
      "           1       1.00      0.02      0.04        49\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.86      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 48   1]]\n",
      "accuracy score correspond to random state 92 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       1.00      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 44   1]]\n",
      "accuracy score correspond to random state 93 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   1]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 94 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       1.00      0.02      0.04        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.92      0.51      0.47       294\n",
      "weighted avg       0.86      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 49   1]]\n",
      "accuracy score correspond to random state 95 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.73       294\n",
      "\n",
      "confusion matrix is [[240   0]\n",
      " [ 54   0]]\n",
      "accuracy score correspond to random state 96 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       238\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 56   0]]\n",
      "accuracy score correspond to random state 97 is: 0.8095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 98 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       242\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[242   0]\n",
      " [ 52   0]]\n",
      "accuracy score correspond to random state 99 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       1.00      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 100 is: 0.8435374149659864\n",
      "max Accuracyscore corresponsds to  55 is: 0.8809523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxraccuracy_scrore(lregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 30}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=55,test_size=0.20)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_neighbors\":[5,10,15,20,25,30]}\n",
    "gkcv=GridSearchCV(estimator=KNeighborsClassifier(),param_grid=parameters)\n",
    "gkcv.fit(x_train,y_train)\n",
    "print(gkcv.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       255\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.49      0.46       294\n",
      "weighted avg       0.75      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[251   4]\n",
      " [ 39   0]]\n",
      "accuracy score correspond to random state 42 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88       232\n",
      "           1       0.33      0.02      0.03        62\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.56      0.50      0.46       294\n",
      "weighted avg       0.69      0.79      0.70       294\n",
      "\n",
      "confusion matrix is [[230   2]\n",
      " [ 61   1]]\n",
      "accuracy score correspond to random state 43 is: 0.7857142857142857\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       1.00      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 44   1]]\n",
      "accuracy score correspond to random state 44 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       237\n",
      "           1       0.33      0.02      0.03        57\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.57      0.50      0.46       294\n",
      "weighted avg       0.72      0.80      0.72       294\n",
      "\n",
      "confusion matrix is [[235   2]\n",
      " [ 56   1]]\n",
      "accuracy score correspond to random state 45 is: 0.8027210884353742\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       238\n",
      "           1       0.33      0.02      0.03        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.57      0.50      0.46       294\n",
      "weighted avg       0.72      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[236   2]\n",
      " [ 55   1]]\n",
      "accuracy score correspond to random state 46 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.49      0.45       294\n",
      "weighted avg       0.71      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[244   4]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 47 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.49      0.45       294\n",
      "weighted avg       0.70      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[243   3]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 48 is: 0.826530612244898\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 49 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.50      0.02      0.04        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.51      0.47       294\n",
      "weighted avg       0.76      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[240   1]\n",
      " [ 52   1]]\n",
      "accuracy score correspond to random state 50 is: 0.8197278911564626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   2]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 51 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 52 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       251\n",
      "           1       0.50      0.02      0.04        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.68      0.51      0.48       294\n",
      "weighted avg       0.80      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[250   1]\n",
      " [ 42   1]]\n",
      "accuracy score correspond to random state 53 is: 0.8537414965986394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       245\n",
      "           1       1.00      0.02      0.04        49\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.86      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 48   1]]\n",
      "accuracy score correspond to random state 54 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93       260\n",
      "           1       0.20      0.03      0.05        34\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.54      0.51      0.49       294\n",
      "weighted avg       0.81      0.87      0.83       294\n",
      "\n",
      "confusion matrix is [[256   4]\n",
      " [ 33   1]]\n",
      "accuracy score correspond to random state 55 is: 0.8741496598639455\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       1.00      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 47   1]]\n",
      "accuracy score correspond to random state 56 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       254\n",
      "           1       0.50      0.03      0.05        40\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.68      0.51      0.49       294\n",
      "weighted avg       0.82      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[253   1]\n",
      " [ 39   1]]\n",
      "accuracy score correspond to random state 57 is: 0.8639455782312925\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       241\n",
      "           1       1.00      0.04      0.07        53\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.91      0.52      0.49       294\n",
      "weighted avg       0.86      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[241   0]\n",
      " [ 51   2]]\n",
      "accuracy score correspond to random state 58 is: 0.826530612244898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 59 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[242   2]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 60 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       246\n",
      "           1       0.33      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.59      0.51      0.47       294\n",
      "weighted avg       0.76      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[244   2]\n",
      " [ 47   1]]\n",
      "accuracy score correspond to random state 61 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.50      0.02      0.04        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.51      0.47       294\n",
      "weighted avg       0.76      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[240   1]\n",
      " [ 52   1]]\n",
      "accuracy score correspond to random state 62 is: 0.8197278911564626\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.50      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.79      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 63 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       250\n",
      "           1       0.25      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.55      0.51      0.48       294\n",
      "weighted avg       0.76      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   3]\n",
      " [ 43   1]]\n",
      "accuracy score correspond to random state 64 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 65 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 66 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       252\n",
      "           1       0.25      0.02      0.04        42\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.55      0.51      0.48       294\n",
      "weighted avg       0.77      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[249   3]\n",
      " [ 41   1]]\n",
      "accuracy score correspond to random state 67 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       239\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.41      0.49      0.45       294\n",
      "weighted avg       0.66      0.80      0.72       294\n",
      "\n",
      "confusion matrix is [[236   3]\n",
      " [ 55   0]]\n",
      "accuracy score correspond to random state 68 is: 0.8027210884353742\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       236\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.40      0.50      0.44       294\n",
      "weighted avg       0.64      0.80      0.71       294\n",
      "\n",
      "confusion matrix is [[235   1]\n",
      " [ 58   0]]\n",
      "accuracy score correspond to random state 69 is: 0.7993197278911565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       238\n",
      "           1       0.67      0.04      0.07        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.74      0.52      0.48       294\n",
      "weighted avg       0.79      0.81      0.74       294\n",
      "\n",
      "confusion matrix is [[237   1]\n",
      " [ 54   2]]\n",
      "accuracy score correspond to random state 70 is: 0.8129251700680272\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.50      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.79      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 71 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[242   2]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 72 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       251\n",
      "           1       0.25      0.02      0.04        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.55      0.51      0.48       294\n",
      "weighted avg       0.77      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[248   3]\n",
      " [ 42   1]]\n",
      "accuracy score correspond to random state 73 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[244   1]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 74 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.65      0.80      0.72       294\n",
      "\n",
      "confusion matrix is [[236   1]\n",
      " [ 57   0]]\n",
      "accuracy score correspond to random state 75 is: 0.8027210884353742\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.90       243\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.41      0.49      0.45       294\n",
      "weighted avg       0.68      0.81      0.74       294\n",
      "\n",
      "confusion matrix is [[239   4]\n",
      " [ 51   0]]\n",
      "accuracy score correspond to random state 76 is: 0.8129251700680272\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       248\n",
      "           1       0.75      0.07      0.12        46\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.80      0.53      0.52       294\n",
      "weighted avg       0.84      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 43   3]]\n",
      "accuracy score correspond to random state 77 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[250   2]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 78 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.50      0.02      0.03        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.65      0.51      0.46       294\n",
      "weighted avg       0.75      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[236   1]\n",
      " [ 56   1]]\n",
      "accuracy score correspond to random state 79 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       247\n",
      "           1       0.33      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.59      0.51      0.48       294\n",
      "weighted avg       0.76      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[245   2]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 80 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 81 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       245\n",
      "           1       0.50      0.04      0.08        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.67      0.52      0.49       294\n",
      "weighted avg       0.78      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[243   2]\n",
      " [ 47   2]]\n",
      "accuracy score correspond to random state 82 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       1.00      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.87      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 44   1]]\n",
      "accuracy score correspond to random state 83 is: 0.8503401360544217\n",
      "classification report is"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 84 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.70      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 85 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       250\n",
      "           1       0.33      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.59      0.51      0.48       294\n",
      "weighted avg       0.77      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[248   2]\n",
      " [ 43   1]]\n",
      "accuracy score correspond to random state 86 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       243\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[243   0]\n",
      " [ 51   0]]\n",
      "accuracy score correspond to random state 87 is: 0.826530612244898\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       242\n",
      "           1       0.50      0.02      0.04        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.51      0.47       294\n",
      "weighted avg       0.77      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[241   1]\n",
      " [ 51   1]]\n",
      "accuracy score correspond to random state 88 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.50      0.02      0.04        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.51      0.47       294\n",
      "weighted avg       0.76      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[239   1]\n",
      " [ 53   1]]\n",
      "accuracy score correspond to random state 89 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       246\n",
      "           1       1.00      0.06      0.12        48\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.92      0.53      0.52       294\n",
      "weighted avg       0.87      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 45   3]]\n",
      "accuracy score correspond to random state 90 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       250\n",
      "           1       0.25      0.02      0.04        44\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.55      0.51      0.48       294\n",
      "weighted avg       0.76      0.84      0.78       294\n",
      "\n",
      "confusion matrix is [[247   3]\n",
      " [ 43   1]]\n",
      "accuracy score correspond to random state 91 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       245\n",
      "           1       1.00      0.02      0.04        49\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.51      0.48       294\n",
      "weighted avg       0.86      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 48   1]]\n",
      "accuracy score correspond to random state 92 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.50      0.02      0.04        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.80      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[248   1]\n",
      " [ 44   1]]\n",
      "accuracy score correspond to random state 93 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   1]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 94 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       244\n",
      "           1       0.25      0.02      0.04        50\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.54      0.50      0.47       294\n",
      "weighted avg       0.73      0.82      0.76       294\n",
      "\n",
      "confusion matrix is [[241   3]\n",
      " [ 49   1]]\n",
      "accuracy score correspond to random state 95 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.73       294\n",
      "\n",
      "confusion matrix is [[240   0]\n",
      " [ 54   0]]\n",
      "accuracy score correspond to random state 96 is: 0.8163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89       238\n",
      "           1       0.33      0.02      0.03        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.57      0.50      0.46       294\n",
      "weighted avg       0.72      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[236   2]\n",
      " [ 55   1]]\n",
      "accuracy score correspond to random state 97 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   2]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 98 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       242\n",
      "           1       0.25      0.02      0.04        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.54      0.50      0.47       294\n",
      "weighted avg       0.72      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[239   3]\n",
      " [ 51   1]]\n",
      "accuracy score correspond to random state 99 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.50      0.02      0.04        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.67      0.51      0.48       294\n",
      "weighted avg       0.79      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 46   1]]\n",
      "accuracy score correspond to random state 100 is: 0.8401360544217688\n",
      "max Accuracyscore corresponsds to  55 is: 0.8741496598639455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kregr=KNeighborsClassifier(n_neighbors=10)\n",
    "maxraccuracy_scrore(Kregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       255\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.75      0.87      0.81       294\n",
      "\n",
      "confusion matrix is [[255   0]\n",
      " [ 39   0]]\n",
      "accuracy score correspond to random state 42 is: 0.8673469387755102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       232\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.39      0.50      0.44       294\n",
      "weighted avg       0.62      0.79      0.70       294\n",
      "\n",
      "confusion matrix is [[232   0]\n",
      " [ 62   0]]\n",
      "accuracy score correspond to random state 43 is: 0.7891156462585034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 45   0]]\n",
      "accuracy score correspond to random state 44 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.65      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[237   0]\n",
      " [ 57   0]]\n",
      "accuracy score correspond to random state 45 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       238\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 56   0]]\n",
      "accuracy score correspond to random state 46 is: 0.8095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 47 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 48 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 49 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[241   0]\n",
      " [ 53   0]]\n",
      "accuracy score correspond to random state 50 is: 0.8197278911564626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 51 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 52 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 53 is: 0.8537414965986394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 54 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       260\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.44      0.50      0.47       294\n",
      "weighted avg       0.78      0.88      0.83       294\n",
      "\n",
      "confusion matrix is [[260   0]\n",
      " [ 34   0]]\n",
      "accuracy score correspond to random state 55 is: 0.8843537414965986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 56 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       254\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.75      0.86      0.80       294\n",
      "\n",
      "confusion matrix is [[254   0]\n",
      " [ 40   0]]\n",
      "accuracy score correspond to random state 57 is: 0.8639455782312925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[241   0]\n",
      " [ 53   0]]\n",
      "accuracy score correspond to random state 58 is: 0.8197278911564626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 59 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 60 is: 0.8299319727891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 61 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       241\n",
      "           1       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[241   0]\n",
      " [ 53   0]]\n",
      "accuracy score correspond to random state 62 is: 0.8197278911564626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 63 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 64 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 65 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 66 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 67 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90       239\n",
      "           1       0.00      0.00      0.00        55\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.73       294\n",
      "\n",
      "confusion matrix is [[239   0]\n",
      " [ 55   0]]\n",
      "accuracy score correspond to random state 68 is: 0.8129251700680272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       236\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.64      0.80      0.71       294\n",
      "\n",
      "confusion matrix is [[236   0]\n",
      " [ 58   0]]\n",
      "accuracy score correspond to random state 69 is: 0.8027210884353742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       238\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 56   0]]\n",
      "accuracy score correspond to random state 70 is: 0.8095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 71 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 72 is: 0.8299319727891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 73 is: 0.8537414965986394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 74 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.65      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[237   0]\n",
      " [ 57   0]]\n",
      "accuracy score correspond to random state 75 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       243\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[243   0]\n",
      " [ 51   0]]\n",
      "accuracy score correspond to random state 76 is: 0.826530612244898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       248\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[248   0]\n",
      " [ 46   0]]\n",
      "accuracy score correspond to random state 77 is: 0.8435374149659864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       252\n",
      "           1       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.86      0.79       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 42   0]]\n",
      "accuracy score correspond to random state 78 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       237\n",
      "           1       0.00      0.00      0.00        57\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.65      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[237   0]\n",
      " [ 57   0]]\n",
      "accuracy score correspond to random state 79 is: 0.8061224489795918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 80 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 81 is: 0.8401360544217688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 82 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 45   0]]\n",
      "accuracy score correspond to random state 83 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 84 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 85 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 86 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       243\n",
      "           1       0.00      0.00      0.00        51\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[243   0]\n",
      " [ 51   0]]\n",
      "accuracy score correspond to random state 87 is: 0.826530612244898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       242\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[242   0]\n",
      " [ 52   0]]\n",
      "accuracy score correspond to random state 88 is: 0.8231292517006803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.73       294\n",
      "\n",
      "confusion matrix is [[240   0]\n",
      " [ 54   0]]\n",
      "accuracy score correspond to random state 89 is: 0.8163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       246\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.70      0.84      0.76       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 48   0]]\n",
      "accuracy score correspond to random state 90 is: 0.8367346938775511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 91 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       245\n",
      "           1       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.42      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.76       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 49   0]]\n",
      "accuracy score correspond to random state 92 is: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       249\n",
      "           1       0.00      0.00      0.00        45\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[249   0]\n",
      " [ 45   0]]\n",
      "accuracy score correspond to random state 93 is: 0.8469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       250\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.72      0.85      0.78       294\n",
      "\n",
      "confusion matrix is [[250   0]\n",
      " [ 44   0]]\n",
      "accuracy score correspond to random state 94 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       244\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.69      0.83      0.75       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 50   0]]\n",
      "accuracy score correspond to random state 95 is: 0.8299319727891157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       240\n",
      "           1       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.67      0.82      0.73       294\n",
      "\n",
      "confusion matrix is [[240   0]\n",
      " [ 54   0]]\n",
      "accuracy score correspond to random state 96 is: 0.8163265306122449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       238\n",
      "           1       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.40      0.50      0.45       294\n",
      "weighted avg       0.66      0.81      0.72       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 56   0]]\n",
      "accuracy score correspond to random state 97 is: 0.8095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       251\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.43      0.50      0.46       294\n",
      "weighted avg       0.73      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 43   0]]\n",
      "accuracy score correspond to random state 98 is: 0.8537414965986394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       242\n",
      "           1       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.41      0.50      0.45       294\n",
      "weighted avg       0.68      0.82      0.74       294\n",
      "\n",
      "confusion matrix is [[242   0]\n",
      " [ 52   0]]\n",
      "accuracy score correspond to random state 99 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       247\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.42      0.50      0.46       294\n",
      "weighted avg       0.71      0.84      0.77       294\n",
      "\n",
      "confusion matrix is [[247   0]\n",
      " [ 47   0]]\n",
      "accuracy score correspond to random state 100 is: 0.8401360544217688\n",
      "max Accuracyscore corresponsds to  55 is: 0.8843537414965986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sregr=SVC(kernel=\"poly\")\n",
    "maxraccuracy_scrore(sregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       255\n",
      "           1       0.20      0.23      0.21        39\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.54      0.54      0.54       294\n",
      "weighted avg       0.79      0.78      0.78       294\n",
      "\n",
      "confusion matrix is [[219  36]\n",
      " [ 30   9]]\n",
      "accuracy score correspond to random state 42 is: 0.7755102040816326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       232\n",
      "           1       0.38      0.34      0.36        62\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.60      0.59      0.60       294\n",
      "weighted avg       0.73      0.74      0.74       294\n",
      "\n",
      "confusion matrix is [[197  35]\n",
      " [ 41  21]]\n",
      "accuracy score correspond to random state 43 is: 0.7414965986394558\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       249\n",
      "           1       0.19      0.22      0.21        45\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.52      0.53      0.52       294\n",
      "weighted avg       0.75      0.74      0.75       294\n",
      "\n",
      "confusion matrix is [[207  42]\n",
      " [ 35  10]]\n",
      "accuracy score correspond to random state 44 is: 0.7380952380952381\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       237\n",
      "           1       0.42      0.39      0.40        57\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.63      0.63      0.63       294\n",
      "weighted avg       0.77      0.78      0.77       294\n",
      "\n",
      "confusion matrix is [[206  31]\n",
      " [ 35  22]]\n",
      "accuracy score correspond to random state 45 is: 0.7755102040816326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       238\n",
      "           1       0.49      0.48      0.49        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.68      0.68      0.68       294\n",
      "weighted avg       0.80      0.81      0.81       294\n",
      "\n",
      "confusion matrix is [[210  28]\n",
      " [ 29  27]]\n",
      "accuracy score correspond to random state 46 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       248\n",
      "           1       0.34      0.39      0.36        46\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.61      0.63      0.62       294\n",
      "weighted avg       0.80      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[213  35]\n",
      " [ 28  18]]\n",
      "accuracy score correspond to random state 47 is: 0.7857142857142857\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       246\n",
      "           1       0.30      0.38      0.33        48\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.58      0.60      0.59       294\n",
      "weighted avg       0.78      0.75      0.76       294\n",
      "\n",
      "confusion matrix is [[203  43]\n",
      " [ 30  18]]\n",
      "accuracy score correspond to random state 48 is: 0.7517006802721088\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       246\n",
      "           1       0.27      0.29      0.28        48\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.57      0.57      0.57       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "confusion matrix is [[209  37]\n",
      " [ 34  14]]\n",
      "accuracy score correspond to random state 49 is: 0.7585034013605442\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       241\n",
      "           1       0.40      0.43      0.42        53\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.64      0.65      0.64       294\n",
      "weighted avg       0.79      0.78      0.79       294\n",
      "\n",
      "confusion matrix is [[207  34]\n",
      " [ 30  23]]\n",
      "accuracy score correspond to random state 50 is: 0.782312925170068\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       248\n",
      "           1       0.32      0.33      0.32        46\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.79      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[216  32]\n",
      " [ 31  15]]\n",
      "accuracy score correspond to random state 51 is: 0.7857142857142857\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       252\n",
      "           1       0.30      0.40      0.34        42\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.60      0.62      0.61       294\n",
      "weighted avg       0.81      0.78      0.79       294\n",
      "\n",
      "confusion matrix is [[212  40]\n",
      " [ 25  17]]\n",
      "accuracy score correspond to random state 52 is: 0.7789115646258503\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       251\n",
      "           1       0.31      0.35      0.33        43\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.60      0.61      0.60       294\n",
      "weighted avg       0.80      0.79      0.80       294\n",
      "\n",
      "confusion matrix is [[218  33]\n",
      " [ 28  15]]\n",
      "accuracy score correspond to random state 53 is: 0.7925170068027211\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       245\n",
      "           1       0.39      0.41      0.40        49\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.80      0.80      0.80       294\n",
      "\n",
      "confusion matrix is [[214  31]\n",
      " [ 29  20]]\n",
      "accuracy score correspond to random state 54 is: 0.7959183673469388\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89       260\n",
      "           1       0.29      0.47      0.36        34\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.61      0.66      0.62       294\n",
      "weighted avg       0.85      0.81      0.82       294\n",
      "\n",
      "confusion matrix is [[221  39]\n",
      " [ 18  16]]\n",
      "accuracy score correspond to random state 55 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       246\n",
      "           1       0.35      0.42      0.38        48\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.62      0.63      0.62       294\n",
      "weighted avg       0.80      0.78      0.79       294\n",
      "\n",
      "confusion matrix is [[209  37]\n",
      " [ 28  20]]\n",
      "accuracy score correspond to random state 56 is: 0.7789115646258503\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       254\n",
      "           1       0.33      0.45      0.38        40\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.62      0.65      0.63       294\n",
      "weighted avg       0.83      0.80      0.81       294\n",
      "\n",
      "confusion matrix is [[217  37]\n",
      " [ 22  18]]\n",
      "accuracy score correspond to random state 57 is: 0.7993197278911565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       241\n",
      "           1       0.23      0.19      0.21        53\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.53      0.52      0.52       294\n",
      "weighted avg       0.72      0.74      0.73       294\n",
      "\n",
      "confusion matrix is [[207  34]\n",
      " [ 43  10]]\n",
      "accuracy score correspond to random state 58 is: 0.7380952380952381\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       248\n",
      "           1       0.36      0.46      0.40        46\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.63      0.65      0.64       294\n",
      "weighted avg       0.81      0.79      0.80       294\n",
      "\n",
      "confusion matrix is [[211  37]\n",
      " [ 25  21]]\n",
      "accuracy score correspond to random state 59 is: 0.7891156462585034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       244\n",
      "           1       0.24      0.22      0.23        50\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.54      0.54      0.54       294\n",
      "weighted avg       0.74      0.75      0.75       294\n",
      "\n",
      "confusion matrix is [[210  34]\n",
      " [ 39  11]]\n",
      "accuracy score correspond to random state 60 is: 0.7517006802721088\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.87       246\n",
      "           1       0.32      0.33      0.33        48\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.59      0.60      0.60       294\n",
      "weighted avg       0.78      0.78      0.78       294\n",
      "\n",
      "confusion matrix is [[212  34]\n",
      " [ 32  16]]\n",
      "accuracy score correspond to random state 61 is: 0.7755102040816326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       241\n",
      "           1       0.33      0.25      0.28        53\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.58      0.57      0.57       294\n",
      "weighted avg       0.75      0.77      0.76       294\n",
      "\n",
      "confusion matrix is [[214  27]\n",
      " [ 40  13]]\n",
      "accuracy score correspond to random state 62 is: 0.7721088435374149\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87       247\n",
      "           1       0.36      0.40      0.38        47\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.62      0.63      0.63       294\n",
      "weighted avg       0.80      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[213  34]\n",
      " [ 28  19]]\n",
      "accuracy score correspond to random state 63 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87       250\n",
      "           1       0.32      0.36      0.34        44\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.60      0.61      0.61       294\n",
      "weighted avg       0.80      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[216  34]\n",
      " [ 28  16]]\n",
      "accuracy score correspond to random state 64 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       248\n",
      "           1       0.24      0.22      0.23        46\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.55      0.54      0.55       294\n",
      "weighted avg       0.76      0.77      0.76       294\n",
      "\n",
      "confusion matrix is [[216  32]\n",
      " [ 36  10]]\n",
      "accuracy score correspond to random state 65 is: 0.7687074829931972\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       248\n",
      "           1       0.40      0.43      0.42        46\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.65      0.66      0.65       294\n",
      "weighted avg       0.82      0.81      0.81       294\n",
      "\n",
      "confusion matrix is [[218  30]\n",
      " [ 26  20]]\n",
      "accuracy score correspond to random state 66 is: 0.8095238095238095\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       252\n",
      "           1       0.28      0.21      0.24        42\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.58      0.56      0.57       294\n",
      "weighted avg       0.79      0.81      0.80       294\n",
      "\n",
      "confusion matrix is [[229  23]\n",
      " [ 33   9]]\n",
      "accuracy score correspond to random state 67 is: 0.8095238095238095\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       239\n",
      "           1       0.34      0.36      0.35        55\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n",
      "confusion matrix is [[200  39]\n",
      " [ 35  20]]\n",
      "accuracy score correspond to random state 68 is: 0.7482993197278912\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       236\n",
      "           1       0.33      0.24      0.28        58\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.58      0.56      0.57       294\n",
      "weighted avg       0.73      0.76      0.74       294\n",
      "\n",
      "confusion matrix is [[208  28]\n",
      " [ 44  14]]\n",
      "accuracy score correspond to random state 69 is: 0.7551020408163265\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       238\n",
      "           1       0.41      0.32      0.36        56\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.63      0.61      0.61       294\n",
      "weighted avg       0.76      0.78      0.77       294\n",
      "\n",
      "confusion matrix is [[212  26]\n",
      " [ 38  18]]\n",
      "accuracy score correspond to random state 70 is: 0.782312925170068\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84       247\n",
      "           1       0.23      0.28      0.25        47\n",
      "\n",
      "    accuracy                           0.74       294\n",
      "   macro avg       0.54      0.55      0.55       294\n",
      "weighted avg       0.76      0.74      0.75       294\n",
      "\n",
      "confusion matrix is [[204  43]\n",
      " [ 34  13]]\n",
      "accuracy score correspond to random state 71 is: 0.7380952380952381\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       244\n",
      "           1       0.35      0.32      0.33        50\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.61      0.60      0.60       294\n",
      "weighted avg       0.78      0.78      0.78       294\n",
      "\n",
      "confusion matrix is [[214  30]\n",
      " [ 34  16]]\n",
      "accuracy score correspond to random state 72 is: 0.782312925170068\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       251\n",
      "           1       0.30      0.33      0.31        43\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.59      0.60      0.59       294\n",
      "weighted avg       0.80      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[218  33]\n",
      " [ 29  14]]\n",
      "accuracy score correspond to random state 73 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       245\n",
      "           1       0.24      0.29      0.26        49\n",
      "\n",
      "    accuracy                           0.73       294\n",
      "   macro avg       0.55      0.55      0.55       294\n",
      "weighted avg       0.75      0.73      0.74       294\n",
      "\n",
      "confusion matrix is [[201  44]\n",
      " [ 35  14]]\n",
      "accuracy score correspond to random state 74 is: 0.7312925170068028\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       237\n",
      "           1       0.34      0.26      0.30        57\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.59      0.57      0.58       294\n",
      "weighted avg       0.74      0.76      0.75       294\n",
      "\n",
      "confusion matrix is [[208  29]\n",
      " [ 42  15]]\n",
      "accuracy score correspond to random state 75 is: 0.7585034013605442\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       243\n",
      "           1       0.43      0.41      0.42        51\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.80      0.80      0.80       294\n",
      "\n",
      "confusion matrix is [[215  28]\n",
      " [ 30  21]]\n",
      "accuracy score correspond to random state 76 is: 0.8027210884353742\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       248\n",
      "           1       0.26      0.28      0.27        46\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.56      0.57      0.56       294\n",
      "weighted avg       0.77      0.76      0.77       294\n",
      "\n",
      "confusion matrix is [[211  37]\n",
      " [ 33  13]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score correspond to random state 77 is: 0.7619047619047619\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       252\n",
      "           1       0.26      0.31      0.28        42\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.57      0.58      0.57       294\n",
      "weighted avg       0.79      0.78      0.78       294\n",
      "\n",
      "confusion matrix is [[215  37]\n",
      " [ 29  13]]\n",
      "accuracy score correspond to random state 78 is: 0.7755102040816326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       237\n",
      "           1       0.36      0.28      0.31        57\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.60      0.58      0.58       294\n",
      "weighted avg       0.74      0.76      0.75       294\n",
      "\n",
      "confusion matrix is [[208  29]\n",
      " [ 41  16]]\n",
      "accuracy score correspond to random state 79 is: 0.7619047619047619\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       247\n",
      "           1       0.39      0.38      0.39        47\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.64      0.63      0.64       294\n",
      "weighted avg       0.80      0.81      0.81       294\n",
      "\n",
      "confusion matrix is [[219  28]\n",
      " [ 29  18]]\n",
      "accuracy score correspond to random state 80 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       247\n",
      "           1       0.39      0.40      0.40        47\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.64      0.64      0.64       294\n",
      "weighted avg       0.81      0.80      0.80       294\n",
      "\n",
      "confusion matrix is [[217  30]\n",
      " [ 28  19]]\n",
      "accuracy score correspond to random state 81 is: 0.8027210884353742\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       245\n",
      "           1       0.29      0.27      0.28        49\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.57      0.57      0.57       294\n",
      "weighted avg       0.76      0.77      0.76       294\n",
      "\n",
      "confusion matrix is [[213  32]\n",
      " [ 36  13]]\n",
      "accuracy score correspond to random state 82 is: 0.7687074829931972\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       249\n",
      "           1       0.28      0.31      0.29        45\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.58      0.58      0.58       294\n",
      "weighted avg       0.78      0.77      0.78       294\n",
      "\n",
      "confusion matrix is [[213  36]\n",
      " [ 31  14]]\n",
      "accuracy score correspond to random state 83 is: 0.7721088435374149\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       246\n",
      "           1       0.39      0.50      0.44        48\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.64      0.67      0.65       294\n",
      "weighted avg       0.81      0.79      0.80       294\n",
      "\n",
      "confusion matrix is [[208  38]\n",
      " [ 24  24]]\n",
      "accuracy score correspond to random state 84 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       246\n",
      "           1       0.33      0.29      0.31        48\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.60      0.59      0.59       294\n",
      "weighted avg       0.78      0.79      0.78       294\n",
      "\n",
      "confusion matrix is [[218  28]\n",
      " [ 34  14]]\n",
      "accuracy score correspond to random state 85 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       250\n",
      "           1       0.36      0.36      0.36        44\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.62      0.62      0.62       294\n",
      "weighted avg       0.81      0.81      0.81       294\n",
      "\n",
      "confusion matrix is [[221  29]\n",
      " [ 28  16]]\n",
      "accuracy score correspond to random state 86 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       243\n",
      "           1       0.42      0.43      0.43        51\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.65      0.65      0.65       294\n",
      "weighted avg       0.80      0.80      0.80       294\n",
      "\n",
      "confusion matrix is [[213  30]\n",
      " [ 29  22]]\n",
      "accuracy score correspond to random state 87 is: 0.7993197278911565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       242\n",
      "           1       0.41      0.42      0.42        52\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.64      0.65      0.64       294\n",
      "weighted avg       0.79      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[210  32]\n",
      " [ 30  22]]\n",
      "accuracy score correspond to random state 88 is: 0.7891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       240\n",
      "           1       0.35      0.35      0.35        54\n",
      "\n",
      "    accuracy                           0.76       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.76      0.76      0.76       294\n",
      "\n",
      "confusion matrix is [[205  35]\n",
      " [ 35  19]]\n",
      "accuracy score correspond to random state 89 is: 0.7619047619047619\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       246\n",
      "           1       0.32      0.35      0.34        48\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.60      0.60      0.60       294\n",
      "weighted avg       0.78      0.77      0.78       294\n",
      "\n",
      "confusion matrix is [[210  36]\n",
      " [ 31  17]]\n",
      "accuracy score correspond to random state 90 is: 0.7721088435374149\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       250\n",
      "           1       0.29      0.39      0.33        44\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.59      0.61      0.59       294\n",
      "weighted avg       0.80      0.77      0.78       294\n",
      "\n",
      "confusion matrix is [[208  42]\n",
      " [ 27  17]]\n",
      "accuracy score correspond to random state 91 is: 0.7653061224489796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       245\n",
      "           1       0.36      0.33      0.34        49\n",
      "\n",
      "    accuracy                           0.79       294\n",
      "   macro avg       0.62      0.61      0.61       294\n",
      "weighted avg       0.78      0.79      0.79       294\n",
      "\n",
      "confusion matrix is [[217  28]\n",
      " [ 33  16]]\n",
      "accuracy score correspond to random state 92 is: 0.7925170068027211\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       249\n",
      "           1       0.27      0.29      0.28        45\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.57      0.57      0.57       294\n",
      "weighted avg       0.78      0.77      0.78       294\n",
      "\n",
      "confusion matrix is [[214  35]\n",
      " [ 32  13]]\n",
      "accuracy score correspond to random state 93 is: 0.7721088435374149\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       250\n",
      "           1       0.30      0.36      0.33        44\n",
      "\n",
      "    accuracy                           0.78       294\n",
      "   macro avg       0.59      0.61      0.60       294\n",
      "weighted avg       0.80      0.78      0.78       294\n",
      "\n",
      "confusion matrix is [[212  38]\n",
      " [ 28  16]]\n",
      "accuracy score correspond to random state 94 is: 0.7755102040816326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       244\n",
      "           1       0.36      0.42      0.39        50\n",
      "\n",
      "    accuracy                           0.77       294\n",
      "   macro avg       0.62      0.63      0.62       294\n",
      "weighted avg       0.79      0.77      0.78       294\n",
      "\n",
      "confusion matrix is [[206  38]\n",
      " [ 29  21]]\n",
      "accuracy score correspond to random state 95 is: 0.7721088435374149\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       240\n",
      "           1       0.33      0.35      0.34        54\n",
      "\n",
      "    accuracy                           0.75       294\n",
      "   macro avg       0.59      0.60      0.59       294\n",
      "weighted avg       0.76      0.75      0.75       294\n",
      "\n",
      "confusion matrix is [[202  38]\n",
      " [ 35  19]]\n",
      "accuracy score correspond to random state 96 is: 0.7517006802721088\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       238\n",
      "           1       0.50      0.41      0.45        56\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.68      0.66      0.67       294\n",
      "weighted avg       0.80      0.81      0.80       294\n",
      "\n",
      "confusion matrix is [[215  23]\n",
      " [ 33  23]]\n",
      "accuracy score correspond to random state 97 is: 0.8095238095238095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       251\n",
      "           1       0.33      0.33      0.33        43\n",
      "\n",
      "    accuracy                           0.81       294\n",
      "   macro avg       0.61      0.61      0.61       294\n",
      "weighted avg       0.80      0.81      0.81       294\n",
      "\n",
      "confusion matrix is [[223  28]\n",
      " [ 29  14]]\n",
      "accuracy score correspond to random state 98 is: 0.8061224489795918\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       242\n",
      "           1       0.44      0.46      0.45        52\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.66      0.67      0.66       294\n",
      "weighted avg       0.80      0.80      0.80       294\n",
      "\n",
      "confusion matrix is [[211  31]\n",
      " [ 28  24]]\n",
      "accuracy score correspond to random state 99 is: 0.7993197278911565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       247\n",
      "           1       0.44      0.43      0.43        47\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.67      0.66      0.66       294\n",
      "weighted avg       0.82      0.82      0.82       294\n",
      "\n",
      "confusion matrix is [[222  25]\n",
      " [ 27  20]]\n",
      "accuracy score correspond to random state 100 is: 0.8231292517006803\n",
      "max Accuracyscore corresponsds to  100 is: 0.8231292517006803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dregr=DecisionTreeClassifier()\n",
    "maxraccuracy_scrore(dregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       255\n",
      "           1       0.80      0.10      0.18        39\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.84      0.55      0.56       294\n",
      "weighted avg       0.87      0.88      0.83       294\n",
      "\n",
      "confusion matrix is [[254   1]\n",
      " [ 35   4]]\n",
      "accuracy score correspond to random state 42 is: 0.8775510204081632\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89       232\n",
      "           1       0.67      0.10      0.17        62\n",
      "\n",
      "    accuracy                           0.80       294\n",
      "   macro avg       0.74      0.54      0.53       294\n",
      "weighted avg       0.77      0.80      0.73       294\n",
      "\n",
      "confusion matrix is [[229   3]\n",
      " [ 56   6]]\n",
      "accuracy score correspond to random state 43 is: 0.7993197278911565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       249\n",
      "           1       0.70      0.16      0.25        45\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.78      0.57      0.59       294\n",
      "weighted avg       0.84      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[246   3]\n",
      " [ 38   7]]\n",
      "accuracy score correspond to random state 44 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       237\n",
      "           1       0.73      0.14      0.24        57\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.78      0.56      0.57       294\n",
      "weighted avg       0.81      0.82      0.77       294\n",
      "\n",
      "confusion matrix is [[234   3]\n",
      " [ 49   8]]\n",
      "accuracy score correspond to random state 45 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.98      0.90       238\n",
      "           1       0.64      0.12      0.21        56\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.73      0.55      0.55       294\n",
      "weighted avg       0.79      0.82      0.77       294\n",
      "\n",
      "confusion matrix is [[234   4]\n",
      " [ 49   7]]\n",
      "accuracy score correspond to random state 46 is: 0.8197278911564626\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       248\n",
      "           1       0.73      0.17      0.28        46\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.80      0.58      0.60       294\n",
      "weighted avg       0.84      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[245   3]\n",
      " [ 38   8]]\n",
      "accuracy score correspond to random state 47 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       246\n",
      "           1       0.88      0.15      0.25        48\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.87      0.57      0.59       294\n",
      "weighted avg       0.86      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 41   7]]\n",
      "accuracy score correspond to random state 48 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       246\n",
      "           1       0.71      0.10      0.18        48\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.78      0.55      0.55       294\n",
      "weighted avg       0.83      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[244   2]\n",
      " [ 43   5]]\n",
      "accuracy score correspond to random state 49 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       241\n",
      "           1       0.62      0.09      0.16        53\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.73      0.54      0.53       294\n",
      "weighted avg       0.79      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[238   3]\n",
      " [ 48   5]]\n",
      "accuracy score correspond to random state 50 is: 0.826530612244898\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       248\n",
      "           1       0.92      0.24      0.38        46\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.90      0.62      0.66       294\n",
      "weighted avg       0.88      0.88      0.85       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 35  11]]\n",
      "accuracy score correspond to random state 51 is: 0.8775510204081632\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       252\n",
      "           1       1.00      0.21      0.35        42\n",
      "\n",
      "    accuracy                           0.89       294\n",
      "   macro avg       0.94      0.61      0.65       294\n",
      "weighted avg       0.90      0.89      0.85       294\n",
      "\n",
      "confusion matrix is [[252   0]\n",
      " [ 33   9]]\n",
      "accuracy score correspond to random state 52 is: 0.8877551020408163\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       251\n",
      "           1       1.00      0.09      0.17        43\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.93      0.55      0.55       294\n",
      "weighted avg       0.89      0.87      0.82       294\n",
      "\n",
      "confusion matrix is [[251   0]\n",
      " [ 39   4]]\n",
      "accuracy score correspond to random state 53 is: 0.8673469387755102\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       245\n",
      "           1       0.69      0.18      0.29        49\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.77      0.58      0.60       294\n",
      "weighted avg       0.83      0.85      0.81       294\n",
      "\n",
      "confusion matrix is [[241   4]\n",
      " [ 40   9]]\n",
      "accuracy score correspond to random state 54 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       260\n",
      "           1       0.75      0.09      0.16        34\n",
      "\n",
      "    accuracy                           0.89       294\n",
      "   macro avg       0.82      0.54      0.55       294\n",
      "weighted avg       0.88      0.89      0.85       294\n",
      "\n",
      "confusion matrix is [[259   1]\n",
      " [ 31   3]]\n",
      "accuracy score correspond to random state 55 is: 0.891156462585034\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       246\n",
      "           1       1.00      0.17      0.29        48\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.58      0.61       294\n",
      "weighted avg       0.88      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[246   0]\n",
      " [ 40   8]]\n",
      "accuracy score correspond to random state 56 is: 0.8639455782312925\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       254\n",
      "           1       0.57      0.10      0.17        40\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.72      0.54      0.55       294\n",
      "weighted avg       0.83      0.87      0.82       294\n",
      "\n",
      "confusion matrix is [[251   3]\n",
      " [ 36   4]]\n",
      "accuracy score correspond to random state 57 is: 0.8673469387755102\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       241\n",
      "           1       0.75      0.17      0.28        53\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.80      0.58      0.59       294\n",
      "weighted avg       0.83      0.84      0.80       294\n",
      "\n",
      "confusion matrix is [[238   3]\n",
      " [ 44   9]]\n",
      "accuracy score correspond to random state 58 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       248\n",
      "           1       0.78      0.15      0.25        46\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.82      0.57      0.59       294\n",
      "weighted avg       0.85      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[246   2]\n",
      " [ 39   7]]\n",
      "accuracy score correspond to random state 59 is: 0.8605442176870748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       244\n",
      "           1       0.86      0.12      0.21        50\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.85      0.56      0.56       294\n",
      "weighted avg       0.85      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[243   1]\n",
      " [ 44   6]]\n",
      "accuracy score correspond to random state 60 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       246\n",
      "           1       0.73      0.17      0.27        48\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.79      0.58      0.59       294\n",
      "weighted avg       0.84      0.85      0.81       294\n",
      "\n",
      "confusion matrix is [[243   3]\n",
      " [ 40   8]]\n",
      "accuracy score correspond to random state 61 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       241\n",
      "           1       0.83      0.09      0.17        53\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.83      0.55      0.54       294\n",
      "weighted avg       0.83      0.83      0.77       294\n",
      "\n",
      "confusion matrix is [[240   1]\n",
      " [ 48   5]]\n",
      "accuracy score correspond to random state 62 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       247\n",
      "           1       0.70      0.15      0.25        47\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.78      0.57      0.58       294\n",
      "weighted avg       0.83      0.85      0.81       294\n",
      "\n",
      "confusion matrix is [[244   3]\n",
      " [ 40   7]]\n",
      "accuracy score correspond to random state 63 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.92       250\n",
      "           1       0.56      0.11      0.19        44\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.71      0.55      0.55       294\n",
      "weighted avg       0.82      0.85      0.81       294\n",
      "\n",
      "confusion matrix is [[246   4]\n",
      " [ 39   5]]\n",
      "accuracy score correspond to random state 64 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       248\n",
      "           1       0.62      0.11      0.19        46\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.74      0.55      0.55       294\n",
      "weighted avg       0.82      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[245   3]\n",
      " [ 41   5]]\n",
      "accuracy score correspond to random state 65 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93       248\n",
      "           1       0.92      0.24      0.38        46\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.90      0.62      0.66       294\n",
      "weighted avg       0.88      0.88      0.85       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 35  11]]\n",
      "accuracy score correspond to random state 66 is: 0.8775510204081632\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       252\n",
      "           1       0.75      0.14      0.24        42\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.81      0.57      0.58       294\n",
      "weighted avg       0.86      0.87      0.83       294\n",
      "\n",
      "confusion matrix is [[250   2]\n",
      " [ 36   6]]\n",
      "accuracy score correspond to random state 67 is: 0.8707482993197279\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91       239\n",
      "           1       0.69      0.20      0.31        55\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.76      0.59      0.61       294\n",
      "weighted avg       0.81      0.83      0.79       294\n",
      "\n",
      "confusion matrix is [[234   5]\n",
      " [ 44  11]]\n",
      "accuracy score correspond to random state 68 is: 0.8333333333333334\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       236\n",
      "           1       0.88      0.12      0.21        58\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.85      0.56      0.56       294\n",
      "weighted avg       0.83      0.82      0.76       294\n",
      "\n",
      "confusion matrix is [[235   1]\n",
      " [ 51   7]]\n",
      "accuracy score correspond to random state 69 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       238\n",
      "           1       1.00      0.16      0.28        56\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.58      0.59       294\n",
      "weighted avg       0.87      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[238   0]\n",
      " [ 47   9]]\n",
      "accuracy score correspond to random state 70 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       247\n",
      "           1       0.55      0.13      0.21        47\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.70      0.55      0.56       294\n",
      "weighted avg       0.81      0.84      0.80       294\n",
      "\n",
      "confusion matrix is [[242   5]\n",
      " [ 41   6]]\n",
      "accuracy score correspond to random state 71 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       244\n",
      "           1       0.75      0.12      0.21        50\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.80      0.56      0.56       294\n",
      "weighted avg       0.83      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[242   2]\n",
      " [ 44   6]]\n",
      "accuracy score correspond to random state 72 is: 0.8435374149659864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       251\n",
      "           1       0.82      0.21      0.33        43\n",
      "\n",
      "    accuracy                           0.88       294\n",
      "   macro avg       0.85      0.60      0.63       294\n",
      "weighted avg       0.87      0.88      0.84       294\n",
      "\n",
      "confusion matrix is [[249   2]\n",
      " [ 34   9]]\n",
      "accuracy score correspond to random state 73 is: 0.8775510204081632\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       245\n",
      "           1       0.54      0.14      0.23        49\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.69      0.56      0.57       294\n",
      "weighted avg       0.80      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[239   6]\n",
      " [ 42   7]]\n",
      "accuracy score correspond to random state 74 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       237\n",
      "           1       0.73      0.14      0.24        57\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.78      0.56      0.57       294\n",
      "weighted avg       0.81      0.82      0.77       294\n",
      "\n",
      "confusion matrix is [[234   3]\n",
      " [ 49   8]]\n",
      "accuracy score correspond to random state 75 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.91       243\n",
      "           1       0.64      0.14      0.23        51\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.74      0.56      0.57       294\n",
      "weighted avg       0.81      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[239   4]\n",
      " [ 44   7]]\n",
      "accuracy score correspond to random state 76 is: 0.8367346938775511\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       248\n",
      "           1       0.75      0.07      0.12        46\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.80      0.53      0.52       294\n",
      "weighted avg       0.84      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[247   1]\n",
      " [ 43   3]]\n",
      "accuracy score correspond to random state 77 is: 0.8503401360544217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       252\n",
      "           1       0.75      0.07      0.13        42\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.81      0.53      0.53       294\n",
      "weighted avg       0.85      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[251   1]\n",
      " [ 39   3]]\n",
      "accuracy score correspond to random state 78 is: 0.8639455782312925\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.90       237\n",
      "           1       0.64      0.12      0.21        57\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.73      0.55      0.55       294\n",
      "weighted avg       0.79      0.82      0.76       294\n",
      "\n",
      "confusion matrix is [[233   4]\n",
      " [ 50   7]]\n",
      "accuracy score correspond to random state 79 is: 0.8163265306122449\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.92       247\n",
      "           1       0.67      0.09      0.15        47\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.76      0.54      0.53       294\n",
      "weighted avg       0.82      0.85      0.79       294\n",
      "\n",
      "confusion matrix is [[245   2]\n",
      " [ 43   4]]\n",
      "accuracy score correspond to random state 80 is: 0.8469387755102041\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       247\n",
      "           1       0.90      0.19      0.32        47\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.88      0.59      0.62       294\n",
      "weighted avg       0.87      0.87      0.83       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 38   9]]\n",
      "accuracy score correspond to random state 81 is: 0.8673469387755102\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       245\n",
      "           1       0.86      0.12      0.21        49\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.85      0.56      0.57       294\n",
      "weighted avg       0.85      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[244   1]\n",
      " [ 43   6]]\n",
      "accuracy score correspond to random state 82 is: 0.8503401360544217\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       249\n",
      "           1       0.83      0.11      0.20        45\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.85      0.55      0.56       294\n",
      "weighted avg       0.86      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[248   1]\n",
      " [ 40   5]]\n",
      "accuracy score correspond to random state 83 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       246\n",
      "           1       0.92      0.25      0.39        48\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.90      0.62      0.66       294\n",
      "weighted avg       0.88      0.87      0.84       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 36  12]]\n",
      "accuracy score correspond to random state 84 is: 0.8741496598639455\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       246\n",
      "           1       0.86      0.12      0.22        48\n",
      "\n",
      "    accuracy                           0.85       294\n",
      "   macro avg       0.86      0.56      0.57       294\n",
      "weighted avg       0.85      0.85      0.80       294\n",
      "\n",
      "confusion matrix is [[245   1]\n",
      " [ 42   6]]\n",
      "accuracy score correspond to random state 85 is: 0.8537414965986394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       250\n",
      "           1       0.67      0.14      0.23        44\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.77      0.56      0.57       294\n",
      "weighted avg       0.84      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[247   3]\n",
      " [ 38   6]]\n",
      "accuracy score correspond to random state 86 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       243\n",
      "           1       0.70      0.14      0.23        51\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.77      0.56      0.57       294\n",
      "weighted avg       0.82      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[240   3]\n",
      " [ 44   7]]\n",
      "accuracy score correspond to random state 87 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90       242\n",
      "           1       0.50      0.06      0.10        52\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.66      0.52      0.50       294\n",
      "weighted avg       0.77      0.82      0.76       294\n",
      "\n",
      "confusion matrix is [[239   3]\n",
      " [ 49   3]]\n",
      "accuracy score correspond to random state 88 is: 0.8231292517006803\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       240\n",
      "           1       1.00      0.13      0.23        54\n",
      "\n",
      "    accuracy                           0.84       294\n",
      "   macro avg       0.92      0.56      0.57       294\n",
      "weighted avg       0.87      0.84      0.79       294\n",
      "\n",
      "confusion matrix is [[240   0]\n",
      " [ 47   7]]\n",
      "accuracy score correspond to random state 89 is: 0.8401360544217688\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       246\n",
      "           1       0.80      0.17      0.28        48\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.83      0.58      0.60       294\n",
      "weighted avg       0.85      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[244   2]\n",
      " [ 40   8]]\n",
      "accuracy score correspond to random state 90 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       250\n",
      "           1       0.67      0.09      0.16        44\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.76      0.54      0.54       294\n",
      "weighted avg       0.83      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[248   2]\n",
      " [ 40   4]]\n",
      "accuracy score correspond to random state 91 is: 0.8571428571428571\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       245\n",
      "           1       1.00      0.24      0.39        49\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.93      0.62      0.66       294\n",
      "weighted avg       0.89      0.87      0.84       294\n",
      "\n",
      "confusion matrix is [[245   0]\n",
      " [ 37  12]]\n",
      "accuracy score correspond to random state 92 is: 0.8741496598639455\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       249\n",
      "           1       0.90      0.20      0.33        45\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.89      0.60      0.63       294\n",
      "weighted avg       0.88      0.87      0.84       294\n",
      "\n",
      "confusion matrix is [[248   1]\n",
      " [ 36   9]]\n",
      "accuracy score correspond to random state 93 is: 0.8741496598639455\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       250\n",
      "           1       0.80      0.09      0.16        44\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.83      0.54      0.54       294\n",
      "weighted avg       0.85      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[249   1]\n",
      " [ 40   4]]\n",
      "accuracy score correspond to random state 94 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       244\n",
      "           1       1.00      0.16      0.28        50\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.58      0.60       294\n",
      "weighted avg       0.88      0.86      0.81       294\n",
      "\n",
      "confusion matrix is [[244   0]\n",
      " [ 42   8]]\n",
      "accuracy score correspond to random state 95 is: 0.8571428571428571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90       240\n",
      "           1       0.67      0.15      0.24        54\n",
      "\n",
      "    accuracy                           0.83       294\n",
      "   macro avg       0.75      0.57      0.57       294\n",
      "weighted avg       0.81      0.83      0.78       294\n",
      "\n",
      "confusion matrix is [[236   4]\n",
      " [ 46   8]]\n",
      "accuracy score correspond to random state 96 is: 0.8299319727891157\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90       238\n",
      "           1       0.80      0.07      0.13        56\n",
      "\n",
      "    accuracy                           0.82       294\n",
      "   macro avg       0.81      0.53      0.52       294\n",
      "weighted avg       0.82      0.82      0.75       294\n",
      "\n",
      "confusion matrix is [[237   1]\n",
      " [ 52   4]]\n",
      "accuracy score correspond to random state 97 is: 0.8197278911564626\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       251\n",
      "           1       0.80      0.19      0.30        43\n",
      "\n",
      "    accuracy                           0.87       294\n",
      "   macro avg       0.84      0.59      0.62       294\n",
      "weighted avg       0.87      0.87      0.84       294\n",
      "\n",
      "confusion matrix is [[249   2]\n",
      " [ 35   8]]\n",
      "accuracy score correspond to random state 98 is: 0.8741496598639455\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       242\n",
      "           1       1.00      0.21      0.35        52\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.93      0.61      0.64       294\n",
      "weighted avg       0.88      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[242   0]\n",
      " [ 41  11]]\n",
      "accuracy score correspond to random state 99 is: 0.8605442176870748\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       247\n",
      "           1       0.89      0.17      0.29        47\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.88      0.58      0.61       294\n",
      "weighted avg       0.87      0.86      0.82       294\n",
      "\n",
      "confusion matrix is [[246   1]\n",
      " [ 39   8]]\n",
      "accuracy score correspond to random state 100 is: 0.8639455782312925\n",
      "max Accuracyscore corresponsds to  55 is: 0.891156462585034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rregr=RandomForestClassifier(n_estimators=100)\n",
    "maxraccuracy_scrore(rregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auc_Roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11, 0.04, 0.07, 0.07, 0.05, 0.08, 0.  , 0.02, 0.02, 0.06, 0.19,\n",
       "       0.05, 0.49, 0.16, 0.07, 0.43, 0.02, 0.07, 0.01, 0.12, 0.09, 0.12,\n",
       "       0.57, 0.07, 0.02, 0.19, 0.76, 0.34, 0.01, 0.06, 0.06, 0.02, 0.86,\n",
       "       0.1 , 0.21, 0.1 , 0.03, 0.1 , 0.37, 0.06, 0.11, 0.14, 0.74, 0.01,\n",
       "       0.18, 0.01, 0.01, 0.02, 0.06, 0.  , 0.05, 0.09, 0.02, 0.06, 0.13,\n",
       "       0.12, 0.11, 0.03, 0.03, 0.01, 0.12, 0.05, 0.  , 0.02, 0.02, 0.03,\n",
       "       0.06, 0.03, 0.1 , 0.03, 0.01, 0.07, 0.04, 0.17, 0.04, 0.  , 0.1 ,\n",
       "       0.02, 0.13, 0.13, 0.12, 0.07, 0.07, 0.04, 0.  , 0.05, 0.61, 0.03,\n",
       "       0.03, 0.01, 0.18, 0.08, 0.05, 0.  , 0.05, 0.01, 0.01, 0.5 , 0.06,\n",
       "       0.14, 0.06, 0.1 , 0.02, 0.  , 0.11, 0.02, 0.04, 0.03, 0.28, 0.08,\n",
       "       0.16, 0.06, 0.09, 0.04, 0.69, 0.07, 0.02, 0.06, 0.16, 0.05, 0.05,\n",
       "       0.15, 0.05, 0.01, 0.04, 0.06, 0.86, 0.13, 0.9 , 0.72, 0.83, 0.05,\n",
       "       0.08, 0.14, 0.05, 0.06, 0.06, 0.01, 0.11, 0.09, 0.08, 0.32, 0.02,\n",
       "       0.24, 0.05, 0.72, 0.01, 0.03, 0.01, 0.01, 0.02, 0.02, 0.79, 0.08,\n",
       "       0.03, 0.75, 0.02, 0.1 , 0.03, 0.08, 0.07, 0.08, 0.  , 0.03, 0.  ,\n",
       "       0.03, 0.05, 0.01, 0.06, 0.18, 0.67, 0.13, 0.1 , 0.3 , 0.09, 0.01,\n",
       "       0.11, 0.06, 0.05, 0.03, 0.04, 0.07, 0.02, 0.61, 0.04, 0.05, 0.02,\n",
       "       0.01, 0.77, 0.03, 0.08, 0.  , 0.01, 0.04, 0.06, 0.2 , 0.03, 0.14,\n",
       "       0.8 , 0.14, 0.  , 0.02, 0.05, 0.09, 0.17, 0.  , 0.02, 0.05, 0.07,\n",
       "       0.05, 0.08, 0.09, 0.07, 0.12, 0.25, 0.03, 0.05, 0.32, 0.12, 0.02,\n",
       "       0.04, 0.26, 0.02, 0.53, 0.06, 0.71, 0.05, 0.02, 0.01, 0.04, 0.03,\n",
       "       0.19, 0.02, 0.  , 0.11, 0.04, 0.03, 0.09, 0.73, 0.02, 0.07, 0.06,\n",
       "       0.34, 0.04, 0.71, 0.75, 0.  , 0.11, 0.15, 0.05, 0.09, 0.01, 0.22,\n",
       "       0.1 , 0.07, 0.09, 0.1 , 0.78, 0.01, 0.13, 0.13, 0.05, 0.1 , 0.02,\n",
       "       0.  , 0.05, 0.04, 0.05, 0.21, 0.1 , 0.04, 0.04, 0.17, 0.2 , 0.06,\n",
       "       0.37, 0.07, 0.04, 0.05, 0.  , 0.13, 0.14, 0.12, 0.1 , 0.04, 0.26,\n",
       "       0.01, 0.02, 0.12, 0.05, 0.01, 0.03, 0.06, 0.02])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob=rregr.predict_proba(x_test)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00769231, 0.01538462, 0.01538462, 0.02307692, 0.02307692,\n",
       "       0.02692308, 0.03461538, 0.03461538, 0.04230769, 0.05      ,\n",
       "       0.05384615, 0.06538462, 0.08076923, 0.09230769, 0.1       ,\n",
       "       0.12307692, 0.15384615, 0.18846154, 0.21538462, 0.26538462,\n",
       "       0.34230769, 0.40384615, 0.48461538, 0.58076923, 0.65384615,\n",
       "       0.73461538, 0.84615385, 0.93846154, 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02941176, 0.08823529, 0.26470588, 0.32352941,\n",
       "       0.38235294, 0.5       , 0.55882353, 0.61764706, 0.70588235,\n",
       "       0.70588235, 0.70588235, 0.76470588, 0.76470588, 0.79411765,\n",
       "       0.79411765, 0.79411765, 0.82352941, 0.82352941, 0.82352941,\n",
       "       0.85294118, 0.85294118, 0.91176471, 0.91176471, 0.91176471,\n",
       "       0.91176471, 0.91176471, 0.91176471, 0.94117647, 0.94117647,\n",
       "       0.94117647, 0.94117647, 0.94117647, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title(\"Random forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9542986425339366"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score=roc_auc_score(y_test,y_pred_prob)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the analysis it is clear that Random forest is the best classifier for the random state of 55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a file\n",
    "import pickle\n",
    "filename=\"pickrrregr.pkl\"\n",
    "pickle.dump(RandomForestClassifier,open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
