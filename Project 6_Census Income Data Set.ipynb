{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns\n",
    "# age - self explanatory(age of the person)\n",
    "# Workclass -self explanatory(government,private,..)\n",
    "#fnlwgt =  Sample weight and it can be removed\n",
    "#education - self explanatory( master,bachelor)\n",
    "# education-num - number of years of education in total\n",
    "# Capital gain/ capital loss = income from investment sources other than salary/wages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per- week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workClass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per- week  native-country  \\\n",
       "0         Male          2174             0               40   United-States   \n",
       "1         Male             0             0               13   United-States   \n",
       "2         Male             0             0               40   United-States   \n",
       "3         Male             0             0               40   United-States   \n",
       "4       Female             0             0               40            Cuba   \n",
       "...        ...           ...           ...              ...             ...   \n",
       "32556   Female             0             0               38   United-States   \n",
       "32557     Male             0             0               40   United-States   \n",
       "32558   Female             0             0               40   United-States   \n",
       "32559     Male             0             0               20   United-States   \n",
       "32560   Female         15024             0               40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Census Income Data Set.csv\",names=[\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per- week\", \"native-country\", \"income\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cencusdata=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per- week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workClass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per- week  native-country  \\\n",
       "0         Male          2174             0               40   United-States   \n",
       "1         Male             0             0               13   United-States   \n",
       "2         Male             0             0               40   United-States   \n",
       "3         Male             0             0               40   United-States   \n",
       "4       Female             0             0               40            Cuba   \n",
       "...        ...           ...           ...              ...             ...   \n",
       "32556   Female             0             0               38   United-States   \n",
       "32557     Male             0             0               40   United-States   \n",
       "32558   Female             0             0               40   United-States   \n",
       "32559     Male             0             0               20   United-States   \n",
       "32560   Female         15024             0               40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workClass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "education-num      0\n",
       "marital-status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "capital-gain       0\n",
       "capital-loss       0\n",
       "hours-per- week    0\n",
       "native-country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       "workClass          object\n",
       "fnlwgt              int64\n",
       "education          object\n",
       "education-num       int64\n",
       "marital-status     object\n",
       "occupation         object\n",
       "relationship       object\n",
       "race               object\n",
       "sex                object\n",
       "capital-gain        int64\n",
       "capital-loss        int64\n",
       "hours-per- week     int64\n",
       "native-country     object\n",
       "income             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0.558743\n",
       "fnlwgt              1.446980\n",
       "education-num      -0.311676\n",
       "capital-gain       11.953848\n",
       "capital-loss        4.594629\n",
       "hours-per- week     0.227643\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for skewness in the data\n",
    "df_cencusdata.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac207f3430>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphical representation of skewness\n",
    "# Fnlwgt stands for the sample weight and this can be removed as it has no impact on target value\n",
    "# capital gain and loss also dont have any impact on the income as most of the value are zero so no need to eliminate skewness\n",
    "df_cencusdata[\"fnlwgt\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac20c03b20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cencusdata[\"capital-gain\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2ac20c65250>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cencusdata[\"capital-loss\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As these features will not create any impact on the income so ultimately we have to drop so no need to eliminate skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features=[\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\"race\", \"sex\", \"hours-per- week\", \"native-country\", \"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 15)\n",
      "(32561, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df_cencusdata[df_cencusdata.isnull().any(axis = 1)].shape)\n",
    "df_cencusdata = df_cencusdata.dropna()\n",
    "print(df_cencusdata.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata = df_cencusdata.replace(' ?', np.nan)\n",
    "df_cencusdata.dropna()\n",
    "df_cencusdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(y=\"workClass\",hue=\"income\",data=df_cencusdata)\n",
    "plt.ylabel(\"workClass\")\n",
    "plt.legend([\"<=50K\",\">50K\"])\n",
    "plt.title(\"income distribution among class\")\n",
    "plt.show()\n",
    "\n",
    "# there are maximum jobs in private sector and also the maximum income variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwcAAAGDCAYAAAB+5myoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde9hVZZ3/8fdHxEAlDM0GQSKl8lBIgnZSy3Q6OI6nLE3T1CnKsTIb6ddMRU4HM+n3a5qszCyV6aDmedDMRvPQwVAKJcW08ZColYKaWhLi9/fHXg9tH58HHuA5Ae/Xde1rr32ve93ru9az4Vrffd/3WqkqJEmSJGm9gQ5AkiRJ0uBgciBJkiQJMDmQJEmS1DA5kCRJkgSYHEiSJElqmBxIkiRJAkwOJK2DktyS5PUDHUdvSXJ3kj2b5X9Lcnovtv14kq2a5TOTfKYX2z41ySd6q722dk9I8u0+aHfZuVgTJKkkE/p5n7sm+U1/7lNS71p/oAOQpP5WVdsPdAx9papO7Em9JFcD366q5SYSVbVxb8SV5Ajg3VW1S1vb7+uNtvtLb52LtUmSAl5cVb8FqKrrgJcObFSSVoc9B5KkZ0nij0eStA4yOZC0zuk0DOeEJOcmmZnksWbI0ZS2ulsmuSDJg0kWJjmlKV8vyceT3JPkj832I5t145shHUcmuTfJw0nel2SnJDcneaSjnbb9HJVkflP3h0leuJz4D2v2uzDJxzqtWzakJsmwJN9u6j2S5IYkL0jyWWBX4JRmqEzHMVWSY5LcAdzRVtY+NGWzJD9qztU1HXG2HfP6bbFcneTdSbYFTgVe3ezvkWb9M4YpJXlPkt8mWZTkkiRbtK2r5hze0ZyjryTJcv7Mw5Kc08T5yyQ7tLX10ST/26y7Ncn+besmNMf1aJKHkpzTKYYJzfJezbaPJbkvyfHd/K168j15V5LfNfv7WFftNPWfk+QLTd0/pDUsa3jb+mlJHkhyf5KjOm17dZJ3t30+IslP2j5v3/xdFzVt/1tTvnOSnzffnweSnJJkg2bdtc3mNzV/14OSvD7JgrZ2t232/Uha/7b2aVt3ZvN3vLQ5j79IsnV3xy+pf5gcSBLsA5wNbAJcAnRcLA8BZgH3AOOBMU09gCOa1+7AVsDGHdu1eSXwYuAg4D+AjwF7AtsDb0/yumY/+wH/BhwAPB+4DvheV4Em2Q74GnAYsAWwKTC2m+N6FzAS2LKp9z7gL1X1sWYf76+qjavq/W3b7NfEvV03bR4KfBrYDJgLfKebestU1fxm3z9v9rdJF8f1BuBzwNuB0bTO+dmdqu0N7ATs0NR703J2uy/wfWAU8F3goiRDm3X/Sys5Ggn8O/DtJKObdZ8GrgCeR+u8frmb9r8JvLeqRgAvA67qpt4RrPh7sgutoTh7ANObZKornwdeAkwCJtD6Pk4HSPJm4Hjg72l95/bspo1nSTIC+B/gclrfqQnAlc3qpcBxtP7er25i/GeAqtqtqbND83c9p1O7Q4H/pnU+Nwc+AHwnSfuwo3fQ+hs8D/gt8Nmexi2pb5gcSBL8pKouq6qlwH/RuvgE2JnWxdK0qnqiqp6sqo5fWw8F/l9V3VlVjwP/ChycZw7H+XSzzRXAE8D3quqPVXUfrYvzVzT13gt8rqrmV9VTwInApHTde3AgMKuqrq2qxcAngKe7Oa4ltJKCCVW1tKrmVNWfVnAuPldVi6rqL92sv7Rt3x+j1Ruw5Qra7IlDgW9V1S+btv+1aXt8W52TquqRqvod8GNaF8ndmVNV51XVEuD/AcOAVwFU1fer6v6qerq5oL2D1t8aWufshcAWnf7enS0Btkvy3Kp6uKp+uZzjWtH35N+r6i9VdRNwE3/7/i3T9JK8Bziu+fs8Rut7cnBT5e3AGVX166p6AjhhOeems72B31fV/22O+bGq+gVA8525vqqeqqq7ga8Dr+thu6+ilQydVFV/raqraCXb72irc0FVzW6+999h+X9TSf3A5ECS4Pdty3+mNSRlfVq/uN/TXLh0tgWtX7c73EPrJg8vaCv7Q9vyX7r43DHB9YXAl5qhF48Ai4DQ+mW4q/3e2/GhuRBc2M1x/RfwQ+DsZqjJyW2/nnfn3p6uby52FzUxra5nnM+m7YU88xx0/jstb4Jwe5xPAws64kxyeJK5bef7ZbR+GQf4CK1zP7sZBnMUXXsrsBdwTzMM6dU9OS66/p705LieD2wIzGmL+/KmvGM/7X+7e+i5LWn1pjxLkpckmZXk90n+RCsh2ayrul3YAri3Of/tca3q31RSPzA5kKTu3QuMS9eTc++ndVHfYRzwFM9MAFZmP++tqk3aXsOr6mdd1H2A1sUcAEk2pNU78CxVtaSq/r2qtgNeQ+sX4sM7VncTS3flHdr3vTGtYTv30+oZgdYFbIe/W4l2n3E+k2xE67juW8F2PYlzPVpDhO5vemO+Abwf2LQZ4vRrWgkBVfX7qnpPVW1Bq0fnq+nidqBVdUNV7UtruMxFwLk9OS5W/XvyEK2Ecvu278jItjsoPeN70eyn3RN0/7e5F+hurP/XgNto3ZHoubSGvy1vrke7+4Etm/PfHteq/k0l9QOTA0nq3mxaF10nJdkorQm+r23WfQ84LsmLmovkE4FzuullWJFTgX9Nsj1AkpFJ3tZN3fOAvZPs0kwM/RTd/F+eZPckL2/mTvyJ1lCYpc3qP9AaA7+y9mrb96eBX1TVvVX1IK2LvncmGdL84t5+wfkHYGzHZNYufBc4MsmkJM+hdT5/0QxlWRWTkxzQJHYfAhYD1wMb0UpUHgRIciStngOaz29L0jGH4+Gm7tL2hpNskOTQJCObYUt/6lynTa98T5pf378BfDHJ5k0cY5J0zLs4FzgiyXZNwvjJTk3MBQ5IsmGT7PxT27pZwN8l+VBak55HJHlls25Ec3yPJ9kGOLpTu8v7Hv2CVlLykSRD03q2yD/y7LkkkgYRkwNJ6kYzB+EfaU3Q/B2toSkHNau/RWvYzrXAXcCTtCZcrsp+LqQ12fTsZujGr4G3dFP3FuAYWhfTD9C6gF3QVV1avw6fR+vibj5wDdDxcLAvAQemdeef/1yJcL9L68JzETCZ1pj6Du8BptEaDrQ90N7zcRVwC/D7JA91cVxX0po/cX5zXFvzt/H0q+JiWn+rh2lN3j6g6Um5Ffi/wM9pXdi+HPhp23Y7Ab9I8jityenHVtVdXbR/GHB38/d6H/DObuLote8J8H9oTdq9vtnv/9A8U6CqfkBr0vtVTZ3OE6S/CPyV1jGfRdtE8mb+wt/T+q7/ntYcjN2b1ccDhwCP0UpOnjHpmNbchrOaoU5vb19RVX+lNdn/LbR6Pr4KHF5Vt63S0UvqF6laUU+vJEmSpHWBPQeSJEmSAJMDSZIkSQ2TA0mSJEmAyYEkSZKkhsmBJEmSJKD1lEYNEptttlmNHz9+oMOQJEnSWmzOnDkPVdXzu1pncjCIjB8/nhtvvHGgw5AkSdJaLMk93a0zORhE5i9YyORpMwc6DGmdNmfG4QMdgiRJA8Y5B5IkSZIAkwNJkiRJDZMDSZIkScAalhwkuTvJvCRzm/d9V7GdE5Icvwr73mxV9idJkiStCdbECcm7V9VDSV4KXAFcPNABdZYkQKrq6YGORZIkSeqpNarnoJPnAg93fEhyUZI5SW5JMrWt/M1JfpnkpiRXtm2/XZKrk9yZ5INt9d+ZZHbTO/H1JEM67zjJh5P8unl9qCkbn2R+kq8CvwS2THJmU2dekuP64iRIkiRJvWVN7Dn4cfPL/FbA29vKj6qqRUmGAzckOZ9W8vMNYLequivJqLb62wC7AyOA3yT5GjABOAh4bVUtaS70DwWW3V80yWTgSOCVQIBfJLmGVqLyUuDIqvrnpt6YqnpZs90mvX8qJEmSpN6zJiYHHcOKtgauTHJ1VT0OfDDJ/k2dLYEXA88Hrq2quwCqalFbO5dW1WJgcZI/Ai8A9gAm00ouAIYDf+y0/12AC6vqCYAkFwC7ApcA91TV9U29O4GtknwZuJTWEKhnaXo5pgKMGTmUC0fMWKWTIq2ucdPnDXQIkiRpgK2JyQEAVfW/Sf5Aa3jQhsCewKur6s9JrgaG0fplv7ppYnHb8lJa5yLAWVX1r8vZdZaz7om2+B5OsgPwJuAYWr0cR3VxHKcBpwFMHDO8u1glSZKkPrfGzjlIsjnwIuAeYCTwcJMYbAO8qqn2c+B1SV7UbDOqy8b+5krgwKZtkoxK8sJOda4F9kuyYZKNgP2B67qIbzNgvao6H/gEsOOqHKckSZLUX9bEnoMfJ1kKDAU+WlV/SHI58L4kNwO/Aa4HqKoHm2E7FyRZj9YQob/vruGqujXJx4ErmvpLaP3qf09bnV8mOROY3RSdXlW/SjK+U3NjgDOadgCW1xshSZIkDbhUOZJlsJg4ZnjNeu+EgQ5D6yjnHEiStG5IMqeqpnS1bo0dViRJkiSpd5kcSJIkSQJMDiRJkiQ11sQJyWutDUZvz7jpNw50GJIkSVpH2XMgSZIkCTA5kCRJktQwOZAkSZIEOOdgUJm/YCGTp80c6DAkSZLUx+bMOHygQ+iSPQeSJEmSAJMDSZIkSQ2TA0mSJEmAyYEkSZKkxlqXHCS5O8lmbZ9fn2RWs/yCJLOS3JTk1iSX9VNMRyQ5pT/2JUmSJK2qde1uRZ8CflRVXwJIMnFVG0oypKqW9lpkkiRJ0gBb63oOVmA0sKDjQ1Xd3FWlJFsnuT7JDUk+leTxpvz1SX6c5LvAvKbsoiRzktySZGpbG0cmuT3JNcBr+/SoJEmSpF6wtvYc/DhJx6/6GwO3NctfAc5J8n7gf4Azqur+Lrb/EvClqvpekvd1Wrcz8LKquqv5fFRVLUoyHLghyfnABsC/A5OBR4EfA7/qKtAmoZgKMGbkUC4cMWMVDldrinHT5w10CJIkSd1aW3sOdq+qSVU1CXh3R2FV/RDYCvgGsA3wqyTP72L7VwPfb5a/22nd7LbEAOCDSW4Crge2BF4MvBK4uqoerKq/Aud0F2hVnVZVU6pqyqiNhqzcUUqSJEm9aG3tOehWVS2idcH/3Wai8m5JdgT+oVk/aQVNPNGxkOT1wJ7Aq6vqz0muBoZ17KqXQ5ckSZL61Nrac9ClJG9IsmGzPALYGvhdVX2sracBWr0Ab22WD15OkyOBh5vEYBvgVU35L4DXJ9k0yVDgbb1+MJIkSVIvW6eSA1pzAG5McjPwc+D0qrqhi3ofAj6cZDatScyPdtPe5cD6TXufppVUUFUPACc0+/gf4Je9eRCSJElSX0iVo186a3oX/lJVleRg4B1VtW9f73fimOE1670T+no3GkBOSJYkSQMtyZyqmtLVunVuzkEPTQZOSRLgEeCoAY5HkiRJ6nMmB12oquuAHQY6DkmSJKk/mRwMIhuM3p5x028c6DAkSZK0jlrXJiRLkiRJ6obJgSRJkiTA5ECSJElSwzkHg8j8BQuZPG3mQIexxpoz4/CBDkGSJGmNZs+BJEmSJMDkQJIkSVLD5ECSJEkSYHIgSZIkqWFy0I0kn01yb5LHO5XvluSXSZ5KcmBb+fgkh7R9PiLJKf0ZsyRJkrQ6TA6699/Azl2U/w44Avhup/LxwCGdK0uSJElrCm9l2o2quh4gSefyu5vypzttchKwbZK5wFnAw8AWSS4HtgYurKqP9HHYkiRJ0iqz56D3fBS4rqomVdUXm7JJwEHAy4GDkmw5YNFJkiRJK2DPQd+6sqoeBUhyK/BC4N72CkmmAlMBxowcyoUjZixbN276vP6LVJIkSes8ew761uK25aV0kYxV1WlVNaWqpozaaEj/RSZJkiR1YnLQex4DRgx0EJIkSdKqMjnoRpKTkywANkyyIMkJTflOTfnbgK8nuaXZ5GbgqSQ3JTluYKKWJEmSVp1zDrrR3FnoWXcXqqobgLFdlC8B9uhUfGbb+r17OURJkiSpV9lzIEmSJAkwOZAkSZLUMDmQJEmSBDjnYFDZYPT2jJt+40CHIUmSpHWUPQeSJEmSAJMDSZIkSQ2TA0mSJEmAcw4GlfkLFjJ52syBDqNPzJlx+ECHIEmSpBWw50CSJEkSYHIgSZIkqWFyIEmSJAkwOZAkSZLUWCuTgyR3J7muU9ncJL9exfb+rXcikyRJkgavtTI5aIxIsiVAkm1Xs62VTg6SDFnNfUqSJEn9am1ODs4FDmqW3wF8r2NFkvFJrkvyy+b1mqZ8dJJrO3oZkuya5CRgeFP2nabeO5PMbsq+3pEIJHk8yaeS/AJ4dZKTktya5OYkX+jXo5ckSZJWUqpqoGPodUnuBt4InFlVr0nyK+BQ4NyqelmSDYGnq+rJJC8GvldVU5L8CzCsqj7bXPBvWFWPJXm8qjZu2t4WOBk4oKqWJPkqcH1VzUxSwEFVdW6SUcDPgW2qqpJsUlWPdBHrVGAqwJiRQyf/7MMv7evTs0YZN33eQIcgSZK0Vkkyp6qmdLVubX4I2iLg4SQHA/OBP7etGwqckmQSsBR4SVN+A/CtJEOBi6pqbhft7gFMBm5IAjAc+GOzbilwfrP8J+BJ4PQklwKzugqyqk4DTgOYOGb42pepSZIkaY2xNg8rAjgH+AptQ4oaxwF/AHYApgAbAFTVtcBuwH3AfyXp6rG+Ac6qqknN66VVdUKz7smqWtq09RSwM61kYT/g8t48MEmSJKm3re3JwYW0hgD9sFP5SOCBqnoaOAzomDPwQuCPVfUN4JvAjk39JU1vAsCVwIFJNm+2GdVs9wxJNgZGVtVlwIeASb16ZJIkSVIvW5uHFVFVjwGfB2iGAHX4KnB+krcBPwaeaMpfD0xLsgR4HOjoOTgNuDnJL6vq0CQfB65Ish6wBDgGuKfT7kcAFycZRqu34bhePjxJkiSpV62VE5LXVBPHDK9Z750w0GEMKk5IliRJ6l3Lm5C8tg8rkiRJktRDJgeSJEmSgLV8zsGaZoPR2zNu+o0DHYYkSZLWUfYcSJIkSQJMDiRJkiQ1TA4kSZIkAc45GFTmL1jI5GkzBzoMAObM6Orh0JIkSVqb2XMgSZIkCTA5kCRJktQwOZAkSZIEmBxIkiRJapgcrKQkByW5OcktSU5uK98vyXZtn69OMmVgopQkSZJWnsnBSkiyKTAD2KOqtgdekGSPZvV+wHbdbixJkiQNciYHK2cr4PaqerD5/D/AW5O8BtgHmJFkbpKtm/VvSzI7ye1Jdh2IgCVJkqSe8jkHK+e3wDZJxgMLaPUWbFBVP0tyCTCrqs4DSAKwflXtnGQv4JPAnp0bTDIVmAowZuRQLhwxg3HT5/XHsUiSJEnPYM/BSqiqh4GjgXOA64C7gaeWs8kFzfscYHw3bZ5WVVOqasqojYb0XrCSJEnSSrLnYCVV1X8D/w3LfvVfupzqi5v3pXiuJUmSNMjZc7CSkmzevD8P+Gfg9GbVY8CIgYpLkiRJWl0mByvvS0luBX4KnFRVtzflZwPTkvyqbUKyJEmStMZwqMtKqqp3dFP+U555K9PXt617iG7mHEiSJEmDhT0HkiRJkgCTA0mSJEkNkwNJkiRJgMnBoLLB6O19AJokSZIGjMmBJEmSJMDkQJIkSVLD5ECSJEkS4HMOBpX5CxYyedrMgQ5DkqQuzZlx+ECHIKmP2XMgSZIkCTA5kCRJktQwOZAkSZIE9FNykOSoJPOS3Jzk10n27Y/9rookVyeZ0izfnWSzgY5JkiRJ6g99PiE5yVjgY8COVfVoko2B5/f1fiVJkiStnP7oOdgceAx4HKCqHq+quwCSTEpyfdOjcGGS5zXlVyf5YpJrk8xPslOSC5LckeQzHQ0neWeS2UnmJvl6kiGdd55kSJIvtPVcfKAp3yPJr5rybyV5zvIOort9JfmnJLc3MX8jySlN+fOTnJ/khub12t45nZIkSVLf6I/k4CbgD8BdSc5I8o9t62YC/6eqJgLzgE+2rftrVe0GnApcDBwDvAw4IsmmSbYFDgJeW1WTgKXAoV3sfyrwIuAVzX6+k2QYcCZwUFW9nFYPytHdHUB3+0qyBfAJ4FXA3wPbtG32JeCLVbUT8Fbg9BWcJ0mSJGlA9fmwoqpamuTNwE7AHsAXk0wGvghsUlXXNFXPAr7ftuklzfs84JaqegAgyZ3AlsAuwGTghiQAw4E/dhHCnsCpVfVUE8+iJDsAd1XV7W37Pgb4j24OY49u9rUzcE1VLWpi+z7wkrb9btfUB3hukhFV9Vh7w0mm0kpgGDNyKBeOmNFNCOpv46bPG+gQJEmS+lW/PAStqgqYDcxO8iPgDFrJwfIsbt6fblvu+Lw+EOCsqvrX9o2S7M/feiDe3dSrTm2HlbO8fXVnPeDVVfWX5TVcVacBpwFMHDO8c5ySJElSv+nzYUVJtkiyY1vRJOCeqnoUeDjJrk35YcA1z2qge1cCBybZvNnPqCQvrKoLq2pS87oRuAJ4X5L1O+oBtwHjk0zo4b673BethOd1SZ7XtP/Wtm2uAN7fdh4mrcSxSZIkSf2uP3oOhgJfaMbnPwk8CLyvWfcu4NQkGwJ3Akf2tNGqujXJx4ErkqwHLKE1NOieTlVPpzXU5+YkS4BvVNUpSY4Evt9c1N9Aa27DSu2rqq5PciLwC+B+4Fbg0WazDwJfSXIzrfN8bdtxS5IkSYNOWiN+tKqSbFxVjzdJxoXAt6rqwlVpa+KY4TXrvRNWXFH9wjkHkiRpbZRkTlVN6WqdT0hefSckmQv8GrgLuGiA45EkSZJWSb9MSF6bVdXxAx2DJEmS1BvsOZAkSZIE2HMwqGwwenvGTb9xoMOQJEnSOsqeA0mSJEmAyYEkSZKkhsmBJEmSJMA5B4PK/AULmTxt5kCH0efmzDh8oEOQJElSF+w5kCRJkgSYHEiSJElqmBxIkiRJAkwOJEmSJDUGTXKQ5BVJKsmbBjqWlZHk9UlmDXQckiRJ0uoaNMkB8A7gJ827JEmSpH42KJKDJAEOBI4A3phkWFO+UZJLk9yU5NdJDmrKT0pya5Kbk3yhKXthkiubsiuTjGvKX5DkwqaNm5K8pov975zkZ0l+1by/tCkfkuQLSeY17X6gKX9zktuS/AQ4oK2dE5KcleSKJHcnOSDJyc32lycZ2qcnUpIkSVoNg+U5B68F7qqq/01yNbAXcAHwZuD+qvoHgCQjk4wC9ge2qapKsknTxinAzKo6K8lRwH8C+zXv11TV/kmGABt3sf/bgN2q6qkkewInAm8FpgIvAl7RrBvVJC7fAN4A/BY4p1NbWwO7A9sBPwfeWlUfSXIh8A/ARe2Vk0xt9sOYkUO5cMSMlT97XRg3fV6vtCNJkqR1x6DoOaA1lOjsZvls/ja0aB6wZ5LPJ9m1qh4F/gQ8CZye5ADgz03dVwPfbZb/C9ilWX4D8DWAqlratNHZSOD7SX4NfBHYvinfEzi1qp5qtl8EbEMrkbmjqgr4dqe2flBVS5rYhwCXtx3L+M47rqrTqmpKVU0ZtdGQbk+QJEmS1NcGPDlofs1/KzA9yd3Al4G3JBlRVbcDk2ldWH8uyfTmQn1n4HxaPQOXd90ytZx9HpNkbvPaAvg08OOqehnwj8CwjqrdtNNt28BigKp6GljSJBAATzN4emokSZKkZxnw5IDWr/M3VdWWVTW+ql5Ic+HfXLj/uaq+DXwB2DHJxsDIqroM+BAwqWnnZ8DBzfKhtCY3A1wJHA3L5hA8t6q+UlWTmtf9tHoO7mvqH9EW2xXA+5Ks32w/itYQpBcl2bqp4wRqSZIkrRUGQ3LwDuDCTmXnA4cALwdmJ5kLfAz4DDACmJXkZuAa4Lhmmw8CRzblhwHHNuXHArsnmQfM4W9DhtqdTKtn4qe0hgJ1OB34HXBzkpuAQ6rqSVpzBC5tJiTfs8pHLkmSJA0i+duoFw20iWOG16z3TuiVtpyQLEmSpK4kmVNVU7paNxh6DiRJkiQNAiYHkiRJkgDvnjOobDB6e8ZNv3Ggw5AkSdI6qkfJQZKXANOAF7ZvU1Vv6KO4JEmSJPWznvYcfB84ldaTgZf2XTiSJEmSBkpPk4OnquprfRqJJEmSpAHV0+Tgv5P8M63nESzuKKyqRX0S1Tpq/oKFTJ42c6DDGPTmzDh8oEOQJElaK/U0OXhX8z6trayArXo3HEmSJEkDpUfJQVW9qK8DkSRJklbFkiVLWLBgAU8++eRAhzKoDBs2jLFjxzJ06NAeb9PTuxUNBY4GdmuKrga+XlVLVjZISZIkqTctWLCAESNGMH78eJIMdDiDQlWxcOFCFixYwIte1PPf+Xv6ELSvAZOBrzavyU2ZJEmSNKCefPJJNt10UxODNknYdNNNV7o3padzDnaqqh3aPl+V5KaV2lMvSfIK4JfAm6vqhwMRgyRJkgYXE4NnW5Vz0tOeg6VJtm7b0VYM3PMO3gH8pHmXJEmS1Et62nMwDfhxkjuB0HpS8pF9FlU30kp/DgT+HrguybCqejLJRsC5wFhgCPDpqjonyUnAPsBTwBVVdXySFwLfAp4PPAgcWVW/S/ICWg9667gD09FV9bO2fW8LnFVVOzefxwOXVNXEJHsAX6B1Pm9otl2cZCfgS8BGtG4Bu0dVPdZnJ0iSJEm9fmv4/riN+tVXX82+++67bH7AAQccwPTp0wG4/PLLOfbYY1m6dCnvfve7+ehHPwrAEUccwd57782BBx7IokWL2GOPPfjgBz/IkUeu+mV6T+9WdGWSFwMvpZUc3FZVi1ewWV94LXBXVf1vkquBvYALgDcD91fVPwAkGZlkFLA/sE1VVZJNmjZOAWZW1VlJjgL+E9iveb+mqvZPMgTYuH3HVTU/yQZJtqqqO4GDgHOTDAPOpHXhf3uSmcDRSb4KnAMcVFU3JHku8Je+OzWSJEkaTP7617+yZMkSNtpoox7V33XXXZk1a9YzypYuXcoxxxzDj370I8aOHctOO+3EPvvsw3bbbbeszqOPPsqb3vQmpk6dulqJAawgOUjyhqq6KskBnVZtnYSqumC19r7y3gGc3SyfDRxGKzmYB3whyeeBWVV1XZL1gSeB05NcCnSc6VcDHcfzX8DJzfIbgMMBqmop8GgX+z8XeDtwEq3k4CBaCdNdVXV7U+cs4BjgSuCBqrqhafNPXR1QkqnAVIAxI4dy4YgZPT4Zq2rc9Hl9vg9JkmFy/EMAACAASURBVKR11fz58zn99NO54IILuOCCC3jFK16xym3Nnj2bCRMmsNVWrcEtBx98MBdffPGy5ODxxx/nLW95C4cccghHH330ase+ojkHr2ve/7GL196rvfeV0Pya/1ZgepK7gS8Db0kyorkwn0wrSfhckulV9RSwM3A+rZ6By7tpupazz2OSzG1eW9DqCXh7kpcAVVV30OpJ6XLz5bW9bOdVp1XVlKqaMmqjISuqLkmSpEHoiSee4IwzzmCXXXbh3e9+N9tuuy0333zzssTguOOOY9KkSc96nXTSScva+PnPf84OO+zAW97yFm655RYA7rvvPrbccstldcaOHct999237POHP/xhdtllF4477rheOY7l9hxU1SebxU9V1V3t65L094PR9gRuqqo3tcVwFrBfkiuBRVX17SSPA0ck2RjYsKouS3I98Ntms58BB9PqNTiU1uRmaP3SfzTwH00islFVfQX4SnsQSZYCn6CVKADcBoxPMqGqfkurN+OapnyLJDs1w4pGAH9pkhZJkiStRUaPHs3EiRM5/fTT2WabbZ61/otf/OJyt99xxx2555572HjjjbnsssvYb7/9uOOOO6h69m/N7XchesMb3sDFF1/M8ccfz+abb77ax9HTuxWd30XZeau995XzDuDCTmXnA4cALwdmJ5kLfAz4DDACmJXkZloX6x3p1AeBI5vyw4Bjm/Jjgd2TzAPmANt3E8c5wDtpDTGiqp6kNTn7+822TwOnVtVfaQ07+nJz29cfAcNW/fAlSZI0WJ133nmMGTOG/fffn0996lPcc889z1i/op6D5z73uWy8cWvK61577cWSJUt46KGHGDt2LPfee++ydhYsWMAWW2yx7PPBBx/M0UcfzV577cVjj63+fW9WNOdgG1oXySM7zTt4Lv18oVtVR3RRdglwSfOxq2ce7NzFNnfTml/QufwPwL49iOMLtO5M1F52JfCswWTNfINXrahNSZIkrdne+MY38sY3vpGFCxfy7W9/m3333ZfNNtuM008/nfHjx6+w5+D3v/89L3jBC0jC7Nmzefrpp9l0003ZZJNNuOOOO7jrrrsYM2YMZ599Nt/97nefse2HPvQhHnjgAfbff38uu+wyNthgg1U+jhXdreiltOYWbEJrnkGHx4D3rPJeJUmSpD7SH7ce7c6mm27Ksccey7HHHsvs2bMZMqRnc0rPO+88vva1r7H++uszfPhwzj77bJKw/vrrc8opp/CmN72JpUuXctRRR7H99s8e4PL5z3+eI488ksMOO4zvfe97rLdeTwcIPVO6Gsf0rErJq6vq56u0B/XYxDHDa9Z7J/T5frxbkSRJWpvMnz+fbbfddqDDGJS6OjdJ5lTVlK7q9/QhaL9KcgytIUbLhhNV1VGrGqgkSZKkwaWnycF/0br7zpuAT9G6y8/8vgpqXbXB6O0ZN/3GgQ5DkiRJ66ieDkaaUFWfAJ6oqrOAf6B1hyBJkiRJa4meJgdLmvdHkrwMGAmM75OIJEmSJA2Ing4rOi3J84CP07p16MbA9D6LSpIkSVK/61FyUFWnN4vXAlv1XTjrtvkLFjJ52syBDqPHBvI2YZIkSep9PUoOkpwInFxVjzSfnwf8S1V9vC+DkyRJklbW7z7Vu1Nje+M28EcccQTXXHMNI0eOBODMM89k0qRJVBXHHnssl112GRtuuCFnnnkmO+64IwAbb7wxjz/+OACXXXYZxx57LFdeeSXjxo1b7Xi609M5B2/pSAwAquphYK++CUmSJElaszz88MMrrDNjxgzmzp3L3LlzmTRpEgA/+MEPuOOOO7jjjjs47bTTOProo5+13ZVXXskHPvABLr/88j5NDKDnycGQJM/p+JBkOPCc5dSXJEmS1hlTpkzhkEMO4aqrrqInDxnucPHFF3P44YeThFe96lU88sgjPPDAA8vWX3fddbznPe/h0ksvZeutt+6L0J+hp8nBt4Erk/xTkqOAHwFn9V1YvSPJiCRz214PJfmPZt1+SbZrq3t1ki6fFNepzUlJrm/auzHJzm3le7XVOyHJ8X1xXJIkSRpcbr/9dg455BBOOeUUtttuO0488UTuv//+Z9T52Mc+xsSJEznuuONYvHgxAPfddx9bbrnlsjpjx47lvvvuA2Dx4sXsu+++XHTRRWyzzTb9chw9Sg6q6mTgs8C2tJ6S/OmmbFCrqseqalLHC7gHuKBZvR+wXfdbd+tk4N+b9qY3nwEm4VArSZKkddKQIUPYe++9ueCCC7j22mu58847GTduHLNnzwbgc5/7HLfddhs33HADixYt4vOf/zxAl70MSQAYOnQor3nNa/jmN7/Zb8fR054DquoHVXV8Vf1LVf2wL4PqC0leDGwOXJfkNcA+wIymB6Cjj+ZtSWYnuT3Jrt00VcBzm+WRwP1JNqD15OiDmvYOatZv1/RI3Jnkg31zZJIkSRoMHn30UU477TT22Wcfbr/9dr75zW8yceJEAEaPHk0SnvOc53DkkUcuSxrGjh3Lvffeu6yNBQsWsMUWWwCw3nrrce6553LDDTdw4okn9ssx9Cg5SPJYkj81ryeTLE3yp74Orpe9AzinWn5G63kN05pehf9t6qxfVTsDHwI+2U07H6KVVNwLfAH416r6K61ehHOa9s5p6m4DvAnYGfhkkqF9c2iSJEkaSO985zvZcccdufPOO5k5cybXXnst73rXuxg2bBjAsnkEVcVFF13Ey172MgD22WcfZs6cSVVx/fXXM3LkSEaPHr2s3Q033JBZs2bxne98p196EHr6nIMR7Z+T7EfrgndNcjBw2ArqdAw5mkP3T4A+Gjiuqs5P8nbgm8Ce3dS9tKoWA4uT/BF4AbCgvUKSqcBUgDEjh3LhiBlA79wyS5IkaV00ENdRb3/72znzzDNZf/2uL68PPfRQHnzwQaqKSZMmceqppwKw1157cdlllzFhwgQ23HBDzjjjjGdtO2rUKC6//HJ22203NttsM/bdd98+O46ePiH5GarqoiQf7e1g+kqSHWj1CsxZQdXFzftSmnOT5AzgFcD9VbUX8C7g2Kbe94HTOzfSRXvPaLNdVZ0GnAYwcczwnk9tlyRJ0qCxzz77LHf9VVdd1WV5Er7yla90ua7jGQcAW265JXfdddeqB9hDPX0I2gFtH9cDptAae7+meAfwvU5ljwEjuqj7DFV1ZKei+4HXAVcDbwDuWJn2JEmSpMGqpz0H/9i2/BRwN9B3/Rm97+08+05CZwPfaCYKH7gSbb0H+FKS9YEnaYYEAT8GPppkLvC51YxXkiRJ6nc9nXPQ+dfzNUpVbdVF2U955q1MX9+27iG6mXNQVT8BJndRvgjYaTkxvKzHAUuSJGmlVNWyW4CqZWUextZhuclBki+znOFDVeXtOSVJkjSghg0bxsKFC9l0001NEBpVxcKFC5fdLamnVtRzcGPz/lpav7J33KLzbbTu6CNJkiQNqLFjx7JgwQIefPDBgQ5lUBk2bBhjx45dqW2WmxxU1VkASY4Adq+qJc3nU4ErVi1MSZIkqfcMHTqUF73oRQMdxlqhpxOSt6B1J55FzeeNmzL1og1Gb8+46TeuuKIkSZLUB3qaHJwE/DLJ1c3n1wEn9EVAkiRJkgbGej2sdyYwHZhI6ynCrwPm91FMkiRJkgZAT3sOvgo8DQyvqkuSPA84n+XculOSJEnSmqWnycErq2rHJL8CqKqHk2zQh3Gtk+YvWMjkaTO7XT9nxuH9GI0kSZLWNT0dVrQkyRCaZx4keT6tngRJkiRJa4meJgf/CVwIbJ7ks8BPgBP7LCpJkiRJ/a5Hw4qq6jtJ5gB7AAH2qyonJEuSJElrkZ7OOaCqbgNu68NYJEmSJA2gng4rGhSS3J1kXvO6NclnkjxnFds6IkmvPcgtyX5Jtuut9iRJkqT+tkYlB43dq+rlwM7AVsBpq9jOEazkU56bSdnd2Q8wOZAkSdIaa01MDgCoqseB9wH7JRmVlhlJft30LBzUUTfJR5qym5KclORAYArwnSRzkwxPskeSXzX1vtXRI9H0VkxP8hPgbUnek+SGpq3zk2yY5DXAPsCMpr2tm9flSeYkuS7JNgNwmiRJkqQe6/Gcg8Goqv6U5C7gxcBYYBKwA7AZcEOSa5uy/Wg9q+HPSUZV1aIk7weOr6obkwyj9RToParq9iQzgaOB/2h29WRV7QKQZNOq+kaz/Bngn6rqy0kuAWZV1XnNuiuB91XVHUleSetBcm/ofAxJpgJTAcaMHMqFI2Z0e7y/+1T365Zn3PR5q7SdJEmS1i1rbM9BmzTvuwDfq6qlVfUH4BpaT3DeEzijqv4MUFWLumjjpcBdVXV78/ksYLe29ee0Lb+s6QmYBxwKbP+sgJKNgdcA308yF/g6MLqr4KvqtKqaUlVTRm20vFFLkiRJUt9ao3sOkowAxgO387ck4VnVaB7etrymVrD+ibblM2ndyvWmJEcAr++i/nrAI1U1aQXtSpIkSYPGGttz0Pw6/1Xgoqp6GLgWOCjJkOYJzrsBs4ErgKOSbNhsN6pp4jFgRLN8GzA+yYTm82G0eh66MgJ4IMlQWj0HHZa1V1V/Au5K8rZmn0myw+oesyRJktSX1sTk4MdJfk3rwv93wHub8guBm4GbgKuAj1TV76vqcuAS4MZmiM/xTf0zgVObsgBH0hoGNA94Gji1m/1/AvgF8COe+dyHs4FpzaTmrWklDv+U5CbgFmDf1T5ySZIkqQ+lakUjbtRfJo4ZXrPeO2HFFVeSE5IlSZLUIcmcqprS1bo1sedAkiRJUh8wOZAkSZIErOF3K1rbbDB6e8ZNv3Ggw5AkSdI6yp4DSZIkSYDJgSRJkqSGyYEkSZIkwORAkiRJUsMJyYPI/AULmTxtZo/qzplxeB9HI0mSpHWNPQeSJEmSAJMDSZIkSQ2TA0mSJEnAIE4OktydZF6Sm5JckeTvVnL7GUluSTJjNWK4OsmUVd2+rZ3XJ5m1uu1IkiRJfWnQJgeN3atqB+BG4N/aV6RlefG/F9ixqqb1ZYCSJEnS2mKwJwcdrgUmJBmfZH6SrwK/BLZsegh+3fQyHASQ5BJgI+AXHWUdkrwuydzm9askI5ryj7T1VJzUtsnbksxOcnuSXZu6w5Kc0dT/VZLdl1cuSZIkrQnWlFuZ7g3Ma5ZfChxZVf+c5K3AJGAHYDPghiTXVtU+SR6vqkldtHU8cExV/TTJxsCTSd4C7Ae8sqr+nGRUW/31q2rnJHsBnwT2BI4BqKqXJ9kGuCLJS5ZTLkmSJA16gz05+HGSpcDNwMeBTYB7qur6Zv0uwPeqainwhyTXADsBlyynzZ8C/y/Jd4ALqmpBkj2BM6rqzwBVtait/gXN+xxgfNt+v9zUvS3JPcBLllPerSRTgakAY0YO5cIRPZsi8btPrfJUimcZN33eiitJkiRprTfYhxXtXlWTqurwqnqkKXuibX1W1ECSY9qGEW1RVScB7waGA9c3v/AHqG6aWNy8L+VvyVR3+11hPJ1V1WlVNaWqpozaaMjKbi5JkiT1msGeHKzItcBBSYYkeT6wGzC7vUJVfaVJMCZV1f1Jtq6qeVX1eVoTnbcBrgCOSrIhQKdhRd3t99Cm7kuAccBvllMuSZIkDXqDfVjRilwIvBq4idYv/x+pqt+vYJsPNROFlwK3Aj+oqsVJJgE3JvkrcBmd7o7UyVeBU5PMA54Cjmja6K58dY5RkiRJ6hep6m40jfrbxDHDa9Z7J/T7fp1zIEmStO5IMqequnyW15o+rEiSJElSLzE5kCRJkgSYHEiSJElqrOkTktcqG4zennHTbxzoMCRJkrSOsudAkiRJEmByIEmSJKlhciBJkiQJcM7BoDJ/wUImT5vZJ23PmXF4n7QrSZKktYc9B5IkSZIAkwNJkiRJDZMDSZIkSYDJgSRJkqTGWp8cJLk6yW+SzG1emzfl+yXZrlO9KT1s8wNNm7ckObkpm5Rkr7Y6JyQ5vrePR5IkSeor68rdig6tqs6PHt4PmAXcujINJdkd2BeYWFWLO5INYBIwBbhsdYOVJEmSBsJa33PQlSSvAfYBZjS9CVs3q96WZHaS25Ps2s3mRwMnVdVigKr6Y5INgE8BBzXtHdTU3a7pkbgzyQf78pgkSZKk1ZWqGugY+lSSq4FNgaXA+cBnqqqSnAnMqqrz2urNqap/aYYHfbiq9uyivbnAxcCbgSeB46vqhiRHAFOq6v1NvROANwK7AyOA3wB/V1VLOrU3FZgKMGbk0MkLHvlrrx6/JEmS1C7JnKrqcjj9utBzcGhVvRzYtXkdtpy6FzTvc4Dx3dRZH3ge8CpgGnBuknRT99KqWlxVDwF/BF7QuUJVnVZVU6pqyqiNhqzwYCRJkqS+stYnB1V1X/P+GPBdYOflVF/cvC+lmY+R5IxmqFDHXIIFwAXVMht4GthsBe09o01JkiRpMFqrL1aTrA9sUlUPJRkK7A38T7P6MVrDfZarqo7sVHQR8Abg6iQvATYAHuppe5IkSdJgtbb3HDwH+GGSm4G5wH3AN5p1ZwPTkvyqbUJyT3wL2CrJr5s23lWtiRs/pjUBuX1CsiRJkrTGWOsnJK9JJo4ZXjff95eBDkOSJElrsXV9QrIkSZKkHjA5kCRJkgSYHAwqG4zefqBDkCRJ0jrM5ECSJEkSYHIgSZIkqWFyIEmSJAlYyx+CtqaZv2Ahk6fNHOgwBsScGYcPdAiSJEnrPHsOJEmSJAEmB5IkSZIaJgeSJEmSAJMDSZIkSQ2Tg24k+WySe5M83qn8OUnOSfLbJL9IMr4pH5/kkLZ6RyQ5pX+jliRJkladyUH3/hvYuYvyfwIerqoJwBeBzzfl44FDuqgvSZIkrRFMDrpRVddX1QNdrNoXOKtZPg/YI0mAk4Bdk8xNclyzfosklye5I8nJ/RC2JEmStMp8zsHKGwPcC1BVTyV5FNgU+ChwfFXtDa1hRcAk4BXAYuA3Sb5cVfe2N5ZkKjAVYMzIoVw4YsaydeOmz+vzg5EkSZI62HOw8tJFWXVT98qqerSqngRuBV74rA2rTquqKVU1ZdRGQ3ozTkmSJGmlmBysvAXAlgBJ1gdGAou6qbu4bXkp9tRIkiRpEDM5WHmXAO9qlg8ErqqqAh4DRgxYVJIkSdJqMjnoRpKTkywANkyyIMkJzapvApsm+S3wYVpzDQBuBp5KclPbhGRJkiRpjeEwl25U1UeAj3RR/iTwti7KlwB7dCo+s2393r0coiRJktSr7DmQJEmSBJgcSJIkSWqYHEiSJEkCnHMwqGwwenvGTb9xoMOQJEnSOsqeA0mSJEmAyYEkSZKkhsmBJEmSJMA5B4PK/AULmTxtZo/rz5lxeB9GI0mSpHWNPQeSJEmSAJMDSdL/b+/+g+wq6zuOvz8ToOVHkCJRSSCEFkaEthKzMAiCIBlBpUJnpAFLUWQmo5Wi2IEB7TC2MwxCmP4Aq5WiAkpraUohtOVHJ43SigQCBAIEBgZTWUkL2BYTbAMJ3/5xH5jb7e5mySa5d3ffr5mdPef7POe5z939zt793ueceyRJaiwOJEmSJAFTpDhIckmSZ5KsH0PfQ5N8cAz9ruoeL8mxSY7s2r82yUe2fNaSJEnS9jUligPgVuDwMfY9FBi1OEgyAOwxJHwscOT/7y1JkiRNDFOiOKiqe6pq7dB4klOTPJLkoSR3JdkJ+ANgQZKVSRYMc8w0YBFwQVdsDvBJ4Lx23NGt6Zgkdyd52lUESZIk9bup/lGmFwMnVNWPk+xRVS8nuRgYqKpzRjjmHGBJVa1NAkBVrUnyZ8D6qroCIMnZwN7Ae4CDgCXA4m38fCRJkqQtNtWLg+8D1ya5Ebhpc52TzAROpXMK0VjcXFWvAo8leesIYy4EFgLMnj3bexdIkiSpZ6bEaUUjqapPAr8H7AusTPLmoX2S3NFOFboGmAscADyVZA2wS5KnRnmIDd1DjTCHq6tqoKoGZsyYsaVPRZIkSRq3Kb1ykOSXqmo5sDzJr9EpEtYB01/rU1UnDDnsbV3Hr6+qA9ruOmD3bTxlSZIkaZuZEisHSS5PMkjnnf7BJF9sTYuSrEryCHAX8BCwDDh4pAuSR3Er8OtDLkiWJEmSJoxUVa/noGZgYKBWrFjR62lIkiRpEktyf1UNDNc2JVYOJEmSJG2exYEkSZIkwOJAkiRJUmNxIEmSJAmwOJAkSZLUWBxIkiRJAiwOJEmSJDVT+g7J/Wb14E+Yd/71r+/fv+jMHs5GkiRJU40rB5IkSZIAiwNJkiRJjcWBJEmSJMDiQJIkSVIzIYuDJGuSrEryUJI7k7xtGz3Ox5N8eSuNtSbJXltjLEmSJGlbmJDFQXNcVb0TWAF8vrshHRP5uUmSJEnb3WT4B/ou4IAkc5KsTvIV4AFg3yTnJ7kvycNJfh8gya5J/r6tOjySZEGLH5bk7ha/N8n0Nv7MJLcneTLJ5a89aJLT2+rFI0ku21xckiRJ6neT4T4HJwGr2vbbgbOq6reTvB84EDgcCLAkyTHADODZqvoQQJI3JdkJ+CtgQVXdl2R34L/bmIcCc4ENwBNJrgI2AZcB84D/BO5Mcgpw73Dxqrp5pMknWQgsBJg9e7b3NpAkSVLPTOSVg2VJVgK7A5e22L9W1T1t+/3t60E6KwkH0SkWVgHzk1yW5OiqepFOUbG2qu4DqKqfVtXGNs7Sqnqxqv4HeAzYDzgM+G5VPd/63QAcM0p8RFV1dVUNVNXAjBkzxv9TkSRJkrbQRF45OK6qXnhtJ8kewEtd7QEuraqvDT0wyTzgg8ClSe4EbgZqhMfZ0LW9ic7PLCP0HSkuSZIk9b2JvHKwOXcAn0iyG0CSWUnekmQm8LOq+jZwBfAu4HE61xYc1vpOTzJa4bQceG+SvZJMA04HvjdKXJIkSep7E3nlYFRVdWeSdwA/SAKwHjgDOABYlORV4BXgU1X1crsw+aokO9O53mD+KGOvTXIRsIzOasE/VNUtACPFJUmSpH6XqpHOptH2NjAwUCtWrOj1NCRJkjSJJbm/qgaGa5vMpxVJkiRJegMsDiRJkiQBFgeSJEmSGosDSZIkSYDFgSRJkqTG4kCSJEkSMInvczARrR78CfPOv367Pub9i87cro8nSZKk/uXKgSRJkiTA4kCSJElSY3EgSZIkCbA4kCRJktRYHIwgySVJnkmyfkj8c0keS/JwkqVJ9mvxOUk+2tXv40m+vL3nLUmSJG0pi4OR3QocPkz8QWCgqn4VWAxc3uJzgI8O01+SJEmaECwORlBV91TV2mHiy6rqZ233HmCftv0l4OgkK5Oc12Izk9ye5Mkklw8dS5IkSeonFgfjczZwW9u+EPjnqjq0qv6oxQ4FFgC/AixIsm8P5ihJkiSNiTdB20JJzgAGgPeO0m1pVb3Y+j8G7Ac8M2SchcBCgFlv2pG/nb6I2Rev2jaTliRJkkbhysEWSDIf+ALw4araMErX7rZNDFOMVdXVVTVQVQN77jptK89UkiRJGjtXDt6gJHOBrwEnVtVzXU3rgOm9mZUkSZI0fq4cjCDJ5UkGgV2SDCb5YmtaBOwG/HW7+HhJiz8MbEzyUNcFyZIkSdKE4crBCKrqAuCCYeLzR+j/CnD8kPC1Xe0nbc35SZIkSVubKweSJEmSAIsDSZIkSY3FgSRJkiTA4qCv7LT3Id7jQJIkST1jcSBJkiQJgFRVr+egJsk64Ilez0MT1l7AC72ehCY0c0jjYf5ovMyh7We/qpoxXIMfZdpfnqiqgV5PQhNTkhXmj8bDHNJ4mD8aL3OoP3hakSRJkiTA4kCSJElSY3HQX67u9QQ0oZk/Gi9zSONh/mi8zKE+4AXJkiRJkgBXDiRJkiQ1Fgd9IMmJSZ5I8lSSC3s9H/WHJPsmWZZkdZJHk3ymxfdM8o9Jnmzff6HrmItaHj2R5ISu+Lwkq1rblUnSi+ek3kgyLcmDSf6u7ZtDGpMkeyRZnOTx9rfo3eaP3ogk57XXsEeS/GWSnzeH+pvFQY8lmQb8KfAB4GDg9CQH93ZW6hMbgd+tqncARwCfbrlxIbC0qg4ElrZ9WttpwCHAicBXWn4BfBVYCBzYvk7cnk9EPfcZYHXXvjmksfoT4PaqOgh4J508Mn80JklmAecCA1X1y8A0OjliDvUxi4PeOxx4qqqerqqXge8AJ/d4TuoDVbW2qh5o2+vovCjPopMf17Vu1wGntO2Tge9U1Yaq+iHwFHB4kr2B3avqB9W5yOj6rmM0ySXZB/gQcE1X2BzSZiXZHTgG+DpAVb1cVf+F+aM3Zgdg5yQ7ALsAz2IO9TWLg96bBTzTtT/YYtLrkswB5gLLgbdW1VroFBDAW1q3kXJpVtseGtfU8MfABcCrXTFzSGPxi8DzwDfbaWnXJNkV80djVFU/Bq4AfgSsBV6sqjsxh/qaxUHvDXfOnB8hpdcl2Q34G+CzVfXT0boOE6tR4prkkpwEPFdV94/1kGFi5tDUtQPwLuCrVTUXeIl2+scIzB/9H+1agpOB/YGZwK5JzhjtkGFi5tB2ZnHQe4PAvl37+9BZcpNIsiOdwuCGqrqphf+9LbHSvj/X4iPl0mDbHhrX5HcU8OEka+icsvi+JN/GHNLYDAKDVbW87S+mUyyYPxqr+cAPq+r5qnoFuAk4EnOor1kc9N59wIFJ9k+yE50LcZb0eE7qA+2TGL4OrK6qP+xqWgJ8rG1/DLilK35akp9Lsj+dC7bubUu265Ic0cY8s+sYTWJVdVFV7VNVc+j8bfmnqjoDc0hjUFX/BjyT5O0tdDzwGOaPxu5HwBFJdmm/++PpXD9nDvWxHXo9gamuqjYmOQe4g85V/N+oqkd7PC31h6OA3wJWJVnZYp8HvgTcmORsOn94TwWoqkeT3EjnxXsj8Omq2tSO+xRwLbAzcFv70tRlDmmsfge4ob159TRwFp03Fs0fbVZVLU+yGHiATk48SOcuyLthDvUt75AsSZIkCfC0IkmSJEmNxYEkSZIkwOJAmW1RkAAAAaBJREFUkiRJUmNxIEmSJAmwOJAkSZLUWBxIkqaEJJ9Nskuv5yFJ/cyPMpUkTQntTtEDVfVCr+ciSf3KlQNJUt9IcmaSh5M8lORbSfZLsrTFliaZ3fpdm+QjXcetb9+PTfLdJIuTPJ7khnScC8wEliVZ1ptnJ0n9zzskS5L6QpJDgC8AR1XVC0n2BK4Drq+q65J8ArgSOGUzQ80FDgGeBb7fxrsyyeeA41w5kKSRuXIgSeoX7wMWv/bPe1X9B/Bu4C9a+7eA94xhnHurarCqXgVWAnO2wVwlaVKyOJAk9YsAm7sQ7rX2jbTXsCQBdurqs6FrexOukkvSmFkcSJL6xVLgN5K8GaCdVnQ3cFpr/03gX9r2GmBe2z4Z2HEM468Dpm+tyUrSZOS7KZKkvlBVjya5BPhekk3Ag8C5wDeSnA88D5zVuv85cEuSe+kUFS+N4SGuBm5Lsraqjtv6z0CSJj4/ylSSJEkS4GlFkiRJkhqLA0mSJEmAxYEkSZKkxuJAkiRJEmBxIEmSJKmxOJAkSZIEWBxIkiRJaiwOJEmSJAHwv8/jWzPBm1q4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(y=\"education\",hue=\"income\",data=df_cencusdata)\n",
    "plt.ylabel(\"education\")\n",
    "plt.legend([\"<=50K\",\">50K\"])\n",
    "plt.title(\"income distribution basis on education\")\n",
    "plt.show()\n",
    "\n",
    "# the worker with the master salary are getting maximum salary, so eductation is one of the important attribute while determining the income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(y=\"occupation\",hue=\"income\",data=df_cencusdata)\n",
    "plt.ylabel(\"occupation\")\n",
    "plt.legend([\"<=50K\",\">50K\"])\n",
    "plt.title(\"income distribution basis on occupation\")\n",
    "plt.show()\n",
    "\n",
    "# from the below graph it is observe that \"exec managerial\" and also the \"prof speciality\" occupation geeting a healthy salary no much high difference  between the salaries.\n",
    "# on the other hand the occupation like craft repair and machine op inspection are getting a less salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.countplot(x=\"race\",hue=\"income\",data=df_cencusdata)\n",
    "plt.xlabel(\"race\")\n",
    "plt.legend([\"<=50K\",\">50K\"])\n",
    "plt.title(\"income distribution basis on race\")\n",
    "plt.show()\n",
    "\n",
    "# maximum jobs is with the white people and also most high paid jobs is with the white peoples.\n",
    "#It also plays a important role while determing the income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing of categorical data to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per- week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "      <td>32561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.580326</td>\n",
       "      <td>2.868892</td>\n",
       "      <td>10498.892479</td>\n",
       "      <td>10.298210</td>\n",
       "      <td>9.080679</td>\n",
       "      <td>2.611836</td>\n",
       "      <td>5.572740</td>\n",
       "      <td>1.446362</td>\n",
       "      <td>3.665858</td>\n",
       "      <td>0.669205</td>\n",
       "      <td>1077.648844</td>\n",
       "      <td>87.303830</td>\n",
       "      <td>39.377937</td>\n",
       "      <td>35.718866</td>\n",
       "      <td>0.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.635502</td>\n",
       "      <td>1.455960</td>\n",
       "      <td>6048.972814</td>\n",
       "      <td>3.870264</td>\n",
       "      <td>2.572720</td>\n",
       "      <td>1.506222</td>\n",
       "      <td>4.228857</td>\n",
       "      <td>1.606771</td>\n",
       "      <td>0.848806</td>\n",
       "      <td>0.470506</td>\n",
       "      <td>7385.292085</td>\n",
       "      <td>402.960219</td>\n",
       "      <td>12.144006</td>\n",
       "      <td>7.823782</td>\n",
       "      <td>0.427581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5396.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10348.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15487.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21647.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age     workClass        fnlwgt     education  education-num  \\\n",
       "count  32561.000000  32561.000000  32561.000000  32561.000000   32561.000000   \n",
       "mean      21.580326      2.868892  10498.892479     10.298210       9.080679   \n",
       "std       13.635502      1.455960   6048.972814      3.870264       2.572720   \n",
       "min        0.000000     -1.000000      0.000000      0.000000       0.000000   \n",
       "25%       11.000000      3.000000   5396.000000      9.000000       8.000000   \n",
       "50%       20.000000      3.000000  10348.000000     11.000000       9.000000   \n",
       "75%       31.000000      3.000000  15487.000000     12.000000      11.000000   \n",
       "max       72.000000      7.000000  21647.000000     15.000000      15.000000   \n",
       "\n",
       "       marital-status    occupation  relationship          race           sex  \\\n",
       "count    32561.000000  32561.000000  32561.000000  32561.000000  32561.000000   \n",
       "mean         2.611836      5.572740      1.446362      3.665858      0.669205   \n",
       "std          1.506222      4.228857      1.606771      0.848806      0.470506   \n",
       "min          0.000000     -1.000000      0.000000      0.000000      0.000000   \n",
       "25%          2.000000      2.000000      0.000000      4.000000      0.000000   \n",
       "50%          2.000000      6.000000      1.000000      4.000000      1.000000   \n",
       "75%          4.000000      9.000000      3.000000      4.000000      1.000000   \n",
       "max          6.000000     13.000000      5.000000      4.000000      1.000000   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per- week  native-country  \\\n",
       "count  32561.000000  32561.000000     32561.000000    32561.000000   \n",
       "mean    1077.648844     87.303830        39.377937       35.718866   \n",
       "std     7385.292085    402.960219        12.144006        7.823782   \n",
       "min        0.000000      0.000000         0.000000       -1.000000   \n",
       "25%        0.000000      0.000000        39.000000       38.000000   \n",
       "50%        0.000000      0.000000        39.000000       38.000000   \n",
       "75%        0.000000      0.000000        44.000000       38.000000   \n",
       "max    99999.000000   4356.000000        93.000000       40.000000   \n",
       "\n",
       "             income  \n",
       "count  32561.000000  \n",
       "mean       0.240810  \n",
       "std        0.427581  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Features=[\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\"race\", \"sex\", \"hours-per- week\", \"native-country\", \"income\"]\n",
    "for column in Features:\n",
    "     data=df_cencusdata[column] = data=df_cencusdata[column].astype(\"category\").cat.codes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workClass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours-per- week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workClass  education  education-num  marital-status  occupation  \\\n",
       "0       22          6          9             12               4           0   \n",
       "1       33          5          9             12               2           3   \n",
       "2       21          3         11              8               0           5   \n",
       "3       36          3          1              6               2           5   \n",
       "4       11          3          9             12               2           9   \n",
       "...    ...        ...        ...            ...             ...         ...   \n",
       "32556   10          3          7             11               2          12   \n",
       "32557   23          3         11              8               2           6   \n",
       "32558   41          3         11              8               6           0   \n",
       "32559    5          3         11              8               4           0   \n",
       "32560   35          4         11              8               2           3   \n",
       "\n",
       "       relationship  race  sex  hours-per- week  native-country  income  \n",
       "0                 1     4    1               39              38       0  \n",
       "1                 0     4    1               12              38       0  \n",
       "2                 1     4    1               39              38       0  \n",
       "3                 0     2    1               39              38       0  \n",
       "4                 5     2    0               39               4       0  \n",
       "...             ...   ...  ...              ...             ...     ...  \n",
       "32556             5     4    0               37              38       0  \n",
       "32557             0     4    1               39              38       1  \n",
       "32558             4     4    0               39              38       0  \n",
       "32559             3     4    1               19              38       0  \n",
       "32560             5     4    0               39              38       1  \n",
       "\n",
       "[32561 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cencusdata1=df_cencusdata.drop([\"capital-gain\",\"capital-loss\",\"fnlwgt\"],axis=1)\n",
    "df_cencusdata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = df_cencusdata1.values\n",
    "x = array[:, 0:11]\n",
    "y = array[:, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 11)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lregr=LogisticRegression()\n",
    "def maxraccuracy_score(regr,x,y):\n",
    "    maxraccuracy_score=0\n",
    "    for r_state in range(42,101):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=r_state,test_size=0.20)\n",
    "        scaler = StandardScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.fit_transform(x_test)\n",
    "        regr.fit(x_train,y_train)\n",
    "        y_pred=regr.predict(x_test)\n",
    "        acc_scr=accuracy_score(y_test,y_pred)\n",
    "        Class_rprt=classification_report(y_test,y_pred)\n",
    "        conf_rprt=confusion_matrix(y_test,y_pred)\n",
    "        print(\"classification report is\",Class_rprt)\n",
    "        print(\"confusion matrix is\",conf_rprt)\n",
    "        print(\"accuracy score correspond to random state\",r_state,\"is:\", acc_scr)\n",
    "        if acc_scr>maxraccuracy_score:\n",
    "            maxraccuracy_score=acc_scr\n",
    "            final_r_state=r_state\n",
    "            \n",
    "    print(\"max Accuracyscore corresponsds to \",final_r_state,\"is:\",maxraccuracy_score)\n",
    "    return final_r_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4942\n",
      "           1       0.65      0.40      0.49      1571\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4599  343]\n",
      " [ 946  625]]\n",
      "accuracy score correspond to random state 42 is: 0.8020881314294488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4963\n",
      "           1       0.65      0.39      0.49      1550\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4642  321]\n",
      " [ 946  604]]\n",
      "accuracy score correspond to random state 43 is: 0.8054659910947336\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4940\n",
      "           1       0.64      0.40      0.50      1573\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4586  354]\n",
      " [ 938  635]]\n",
      "accuracy score correspond to random state 44 is: 0.8016275142023646\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4927\n",
      "           1       0.66      0.39      0.49      1586\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4615  312]\n",
      " [ 967  619]]\n",
      "accuracy score correspond to random state 45 is: 0.8036235221863964\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4952\n",
      "           1       0.67      0.41      0.51      1561\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.70      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4630  322]\n",
      " [ 919  642]]\n",
      "accuracy score correspond to random state 46 is: 0.8094580070627975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4946\n",
      "           1       0.64      0.40      0.49      1567\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4598  348]\n",
      " [ 941  626]]\n",
      "accuracy score correspond to random state 47 is: 0.8020881314294488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4940\n",
      "           1       0.69      0.40      0.51      1573\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.67      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4655  285]\n",
      " [ 942  631]]\n",
      "accuracy score correspond to random state 48 is: 0.8116075541225242\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4883\n",
      "           1       0.68      0.40      0.50      1630\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4581  302]\n",
      " [ 985  645]]\n",
      "accuracy score correspond to random state 49 is: 0.8023952095808383\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4968\n",
      "           1       0.67      0.41      0.51      1545\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4648  320]\n",
      " [ 906  639]]\n",
      "accuracy score correspond to random state 50 is: 0.811761093198219\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4888\n",
      "           1       0.67      0.39      0.49      1625\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4584  304]\n",
      " [ 997  628]]\n",
      "accuracy score correspond to random state 51 is: 0.8002456625211116\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4929\n",
      "           1       0.66      0.39      0.49      1584\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4613  316]\n",
      " [ 970  614]]\n",
      "accuracy score correspond to random state 52 is: 0.8025487486565331\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4899\n",
      "           1       0.65      0.38      0.48      1614\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.77      6513\n",
      "\n",
      "confusion matrix is [[4574  325]\n",
      " [1006  608]]\n",
      "accuracy score correspond to random state 53 is: 0.7956394902502687\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4937\n",
      "           1       0.67      0.40      0.50      1576\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4620  317]\n",
      " [ 945  631]]\n",
      "accuracy score correspond to random state 54 is: 0.8062336864732075\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4929\n",
      "           1       0.67      0.41      0.51      1584\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4613  316]\n",
      " [ 942  642]]\n",
      "accuracy score correspond to random state 55 is: 0.8068478427759865\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4965\n",
      "           1       0.66      0.39      0.49      1548\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.66      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4652  313]\n",
      " [ 943  605]]\n",
      "accuracy score correspond to random state 56 is: 0.8071549209273761\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4952\n",
      "           1       0.64      0.39      0.49      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4615  337]\n",
      " [ 949  612]]\n",
      "accuracy score correspond to random state 57 is: 0.8025487486565331\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4921\n",
      "           1       0.66      0.39      0.49      1592\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4600  321]\n",
      " [ 965  627]]\n",
      "accuracy score correspond to random state 58 is: 0.8025487486565331\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4956\n",
      "           1       0.67      0.41      0.51      1557\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.68      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4645  311]\n",
      " [ 914  643]]\n",
      "accuracy score correspond to random state 59 is: 0.8119146322739137\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4945\n",
      "           1       0.64      0.39      0.49      1568\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4606  339]\n",
      " [ 954  614]]\n",
      "accuracy score correspond to random state 60 is: 0.8014739751266697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4895\n",
      "           1       0.69      0.40      0.50      1618\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4612  283]\n",
      " [ 977  641]]\n",
      "accuracy score correspond to random state 61 is: 0.806540764624597\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4996\n",
      "           1       0.64      0.40      0.50      1517\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4647  349]\n",
      " [ 903  614]]\n",
      "accuracy score correspond to random state 62 is: 0.8077690772301551\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4980\n",
      "           1       0.64      0.41      0.50      1533\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4635  345]\n",
      " [ 909  624]]\n",
      "accuracy score correspond to random state 63 is: 0.8074619990787656\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4948\n",
      "           1       0.66      0.40      0.50      1565\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4628  320]\n",
      " [ 945  620]]\n",
      "accuracy score correspond to random state 64 is: 0.8057730692461231\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4921\n",
      "           1       0.67      0.40      0.50      1592\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4609  312]\n",
      " [ 961  631]]\n",
      "accuracy score correspond to random state 65 is: 0.804544756640565\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4957\n",
      "           1       0.65      0.41      0.50      1556\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4609  348]\n",
      " [ 920  636]]\n",
      "accuracy score correspond to random state 66 is: 0.8053124520190389\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      5007\n",
      "           1       0.64      0.42      0.50      1506\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4657  350]\n",
      " [ 880  626]]\n",
      "accuracy score correspond to random state 67 is: 0.8111469368954399\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4934\n",
      "           1       0.65      0.39      0.49      1579\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4599  335]\n",
      " [ 965  614]]\n",
      "accuracy score correspond to random state 68 is: 0.8003992015968064\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4951\n",
      "           1       0.67      0.42      0.52      1562\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.68      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4634  317]\n",
      " [ 910  652]]\n",
      "accuracy score correspond to random state 69 is: 0.8116075541225242\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4972\n",
      "           1       0.65      0.40      0.50      1541\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4630  342]\n",
      " [ 919  622]]\n",
      "accuracy score correspond to random state 70 is: 0.8063872255489022\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4888\n",
      "           1       0.67      0.39      0.49      1625\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4578  310]\n",
      " [ 994  631]]\n",
      "accuracy score correspond to random state 71 is: 0.7997850452940273\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88      4904\n",
      "           1       0.66      0.39      0.49      1609\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4581  323]\n",
      " [ 978  631]]\n",
      "accuracy score correspond to random state 72 is: 0.8002456625211116\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4906\n",
      "           1       0.67      0.41      0.51      1607\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4582  324]\n",
      " [ 953  654]]\n",
      "accuracy score correspond to random state 73 is: 0.803930600337786\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4983\n",
      "           1       0.64      0.42      0.51      1530\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4630  353]\n",
      " [ 891  639]]\n",
      "accuracy score correspond to random state 74 is: 0.8089973898357132\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4909\n",
      "           1       0.68      0.40      0.50      1604\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4610  299]\n",
      " [ 966  638]]\n",
      "accuracy score correspond to random state 75 is: 0.8057730692461231\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4994\n",
      "           1       0.64      0.42      0.51      1519\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4642  352]\n",
      " [ 884  635]]\n",
      "accuracy score correspond to random state 76 is: 0.8102257024412713\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4972\n",
      "           1       0.64      0.40      0.49      1541\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4623  349]\n",
      " [ 927  614]]\n",
      "accuracy score correspond to random state 77 is: 0.8040841394134808\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4979\n",
      "           1       0.66      0.40      0.50      1534\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4657  322]\n",
      " [ 915  619]]\n",
      "accuracy score correspond to random state 78 is: 0.8100721633655765\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4922\n",
      "           1       0.66      0.41      0.50      1591\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4588  334]\n",
      " [ 944  647]]\n",
      "accuracy score correspond to random state 79 is: 0.8037770612620913\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4952\n",
      "           1       0.64      0.40      0.49      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4599  353]\n",
      " [ 934  627]]\n",
      "accuracy score correspond to random state 80 is: 0.8023952095808383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4944\n",
      "           1       0.63      0.39      0.49      1569\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4588  356]\n",
      " [ 952  617]]\n",
      "accuracy score correspond to random state 81 is: 0.7991708889912482\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4967\n",
      "           1       0.66      0.42      0.51      1546\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.68      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4642  325]\n",
      " [ 903  643]]\n",
      "accuracy score correspond to random state 82 is: 0.8114540150468295\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4963\n",
      "           1       0.64      0.41      0.50      1550\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4606  357]\n",
      " [ 917  633]]\n",
      "accuracy score correspond to random state 83 is: 0.8043912175648703\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4945\n",
      "           1       0.67      0.40      0.50      1568\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4634  311]\n",
      " [ 946  622]]\n",
      "accuracy score correspond to random state 84 is: 0.8070013818516812\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4939\n",
      "           1       0.66      0.41      0.51      1574\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4611  328]\n",
      " [ 927  647]]\n",
      "accuracy score correspond to random state 85 is: 0.8073084600030708\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4962\n",
      "           1       0.63      0.38      0.48      1551\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4609  353]\n",
      " [ 955  596]]\n",
      "accuracy score correspond to random state 86 is: 0.7991708889912482\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4928\n",
      "           1       0.66      0.39      0.49      1585\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4610  318]\n",
      " [ 960  625]]\n",
      "accuracy score correspond to random state 87 is: 0.8037770612620913\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4936\n",
      "           1       0.67      0.41      0.51      1577\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.70      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4611  325]\n",
      " [ 926  651]]\n",
      "accuracy score correspond to random state 88 is: 0.8079226163058498\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4915\n",
      "           1       0.65      0.39      0.49      1598\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4572  343]\n",
      " [ 972  626]]\n",
      "accuracy score correspond to random state 89 is: 0.7980961154613849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4918\n",
      "           1       0.70      0.41      0.52      1595\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.68      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4631  287]\n",
      " [ 940  655]]\n",
      "accuracy score correspond to random state 90 is: 0.8116075541225242\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4896\n",
      "           1       0.67      0.40      0.50      1617\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4578  318]\n",
      " [ 976  641]]\n",
      "accuracy score correspond to random state 91 is: 0.801320436050975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4892\n",
      "           1       0.66      0.39      0.49      1621\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4567  325]\n",
      " [ 993  628]]\n",
      "accuracy score correspond to random state 92 is: 0.7976354982343006\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4908\n",
      "           1       0.65      0.39      0.49      1605\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4577  331]\n",
      " [ 978  627]]\n",
      "accuracy score correspond to random state 93 is: 0.7990173499155535\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4924\n",
      "           1       0.67      0.41      0.51      1589\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4610  314]\n",
      " [ 940  649]]\n",
      "accuracy score correspond to random state 94 is: 0.8074619990787656\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4937\n",
      "           1       0.67      0.41      0.51      1576\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.70      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4613  324]\n",
      " [ 926  650]]\n",
      "accuracy score correspond to random state 95 is: 0.8080761553815446\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      4880\n",
      "           1       0.67      0.38      0.49      1633\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4569  311]\n",
      " [1009  624]]\n",
      "accuracy score correspond to random state 96 is: 0.797328420082911\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4995\n",
      "           1       0.64      0.42      0.51      1518\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.68      0.70      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4637  358]\n",
      " [ 873  645]]\n",
      "accuracy score correspond to random state 97 is: 0.8109933978197451\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4871\n",
      "           1       0.70      0.39      0.50      1642\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.76      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.78      6513\n",
      "\n",
      "confusion matrix is [[4598  273]\n",
      " [ 996  646]]\n",
      "accuracy score correspond to random state 98 is: 0.8051589129433441\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4960\n",
      "           1       0.65      0.41      0.50      1553\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4613  347]\n",
      " [ 921  632]]\n",
      "accuracy score correspond to random state 99 is: 0.8053124520190389\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4908\n",
      "           1       0.69      0.38      0.49      1605\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.76      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4630  278]\n",
      " [ 993  612]]\n",
      "accuracy score correspond to random state 100 is: 0.8048518347919545\n",
      "max Accuracyscore corresponsds to  59 is: 0.8119146322739137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxraccuracy_score(lregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 20}\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=42,test_size=0.20)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"n_neighbors\":[5,10,15,20,25,30]}\n",
    "gkcv=GridSearchCV(estimator=KNeighborsClassifier(),param_grid=parameters)\n",
    "gkcv.fit(x_train,y_train)\n",
    "print(gkcv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4942\n",
      "           1       0.69      0.55      0.61      1571\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4561  381]\n",
      " [ 710  861]]\n",
      "accuracy score correspond to random state 42 is: 0.8324888684170121\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4963\n",
      "           1       0.68      0.54      0.60      1550\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4575  388]\n",
      " [ 720  830]]\n",
      "accuracy score correspond to random state 43 is: 0.8298787041302012\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4940\n",
      "           1       0.68      0.55      0.61      1573\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4531  409]\n",
      " [ 709  864]]\n",
      "accuracy score correspond to random state 44 is: 0.8283433133732535\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4927\n",
      "           1       0.68      0.55      0.61      1586\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4525  402]\n",
      " [ 715  871]]\n",
      "accuracy score correspond to random state 45 is: 0.8284968524489482\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4952\n",
      "           1       0.68      0.55      0.60      1561\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4547  405]\n",
      " [ 710  851]]\n",
      "accuracy score correspond to random state 46 is: 0.8288039306003377\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4946\n",
      "           1       0.68      0.55      0.61      1567\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4533  413]\n",
      " [ 705  862]]\n",
      "accuracy score correspond to random state 47 is: 0.8283433133732535\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4940\n",
      "           1       0.70      0.56      0.62      1573\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.83      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4554  386]\n",
      " [ 692  881]]\n",
      "accuracy score correspond to random state 48 is: 0.8344848764010441\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4883\n",
      "           1       0.70      0.56      0.62      1630\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4495  388]\n",
      " [ 715  915]]\n",
      "accuracy score correspond to random state 49 is: 0.8306463995086749\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4968\n",
      "           1       0.69      0.55      0.61      1545\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.75      6513\n",
      "weighted avg       0.83      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4582  386]\n",
      " [ 691  854]]\n",
      "accuracy score correspond to random state 50 is: 0.8346384154767388\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4888\n",
      "           1       0.69      0.57      0.63      1625\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4474  414]\n",
      " [ 697  928]]\n",
      "accuracy score correspond to random state 51 is: 0.8294180869031168\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      4929\n",
      "           1       0.66      0.53      0.59      1584\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4500  429]\n",
      " [ 741  843]]\n",
      "accuracy score correspond to random state 52 is: 0.8203592814371258\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4899\n",
      "           1       0.69      0.55      0.61      1614\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4510  389]\n",
      " [ 728  886]]\n",
      "accuracy score correspond to random state 53 is: 0.8284968524489482\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4937\n",
      "           1       0.68      0.53      0.59      1576\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.72      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4548  389]\n",
      " [ 745  831]]\n",
      "accuracy score correspond to random state 54 is: 0.8258866881621373\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4929\n",
      "           1       0.69      0.53      0.60      1584\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.72      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4553  376]\n",
      " [ 752  832]]\n",
      "accuracy score correspond to random state 55 is: 0.8268079226163059\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4965\n",
      "           1       0.68      0.55      0.61      1548\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4555  410]\n",
      " [ 693  855]]\n",
      "accuracy score correspond to random state 56 is: 0.8306463995086749\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4952\n",
      "           1       0.68      0.55      0.61      1561\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4540  412]\n",
      " [ 702  859]]\n",
      "accuracy score correspond to random state 57 is: 0.8289574696760326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4921\n",
      "           1       0.69      0.52      0.59      1592\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.77      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.82      6513\n",
      "\n",
      "confusion matrix is [[4538  383]\n",
      " [ 758  834]]\n",
      "accuracy score correspond to random state 58 is: 0.8248119146322739\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4956\n",
      "           1       0.69      0.54      0.61      1557\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4582  374]\n",
      " [ 712  845]]\n",
      "accuracy score correspond to random state 59 is: 0.833256563795486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4945\n",
      "           1       0.67      0.54      0.60      1568\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4522  423]\n",
      " [ 716  852]]\n",
      "accuracy score correspond to random state 60 is: 0.8251189927836634\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4895\n",
      "           1       0.69      0.54      0.61      1618\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4504  391]\n",
      " [ 740  878]]\n",
      "accuracy score correspond to random state 61 is: 0.8263473053892215\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4996\n",
      "           1       0.67      0.55      0.60      1517\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4575  421]\n",
      " [ 678  839]]\n",
      "accuracy score correspond to random state 62 is: 0.831260555811454\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4980\n",
      "           1       0.67      0.55      0.61      1533\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4563  417]\n",
      " [ 684  849]]\n",
      "accuracy score correspond to random state 63 is: 0.8309534776600644\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4948\n",
      "           1       0.69      0.55      0.61      1565\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4556  392]\n",
      " [ 711  854]]\n",
      "accuracy score correspond to random state 64 is: 0.8306463995086749\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4921\n",
      "           1       0.68      0.56      0.61      1592\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4506  415]\n",
      " [ 701  891]]\n",
      "accuracy score correspond to random state 65 is: 0.828650391524643\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      4957\n",
      "           1       0.70      0.55      0.61      1556\n",
      "\n",
      "    accuracy                           0.84      6513\n",
      "   macro avg       0.78      0.74      0.75      6513\n",
      "weighted avg       0.83      0.84      0.83      6513\n",
      "\n",
      "confusion matrix is [[4585  372]\n",
      " [ 701  855]]\n",
      "accuracy score correspond to random state 66 is: 0.8352525717795178\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      5007\n",
      "           1       0.67      0.57      0.61      1506\n",
      "\n",
      "    accuracy                           0.84      6513\n",
      "   macro avg       0.77      0.74      0.76      6513\n",
      "weighted avg       0.83      0.84      0.83      6513\n",
      "\n",
      "confusion matrix is [[4595  412]\n",
      " [ 655  851]]\n",
      "accuracy score correspond to random state 67 is: 0.8361738062336864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4934\n",
      "           1       0.68      0.55      0.61      1579\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4526  408]\n",
      " [ 716  863]]\n",
      "accuracy score correspond to random state 68 is: 0.8274220789190849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4951\n",
      "           1       0.67      0.55      0.60      1562\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4522  429]\n",
      " [ 702  860]]\n",
      "accuracy score correspond to random state 69 is: 0.8263473053892215\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      4972\n",
      "           1       0.70      0.56      0.62      1541\n",
      "\n",
      "    accuracy                           0.84      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.83      0.84      0.83      6513\n",
      "\n",
      "confusion matrix is [[4595  377]\n",
      " [ 675  866]]\n",
      "accuracy score correspond to random state 70 is: 0.8384768923691079\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      4888\n",
      "           1       0.71      0.54      0.61      1625\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4526  362]\n",
      " [ 745  880]]\n",
      "accuracy score correspond to random state 71 is: 0.8300322432058959\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4904\n",
      "           1       0.70      0.55      0.61      1609\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4524  380]\n",
      " [ 731  878]]\n",
      "accuracy score correspond to random state 72 is: 0.8294180869031168\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4906\n",
      "           1       0.68      0.56      0.61      1607\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4492  414]\n",
      " [ 710  897]]\n",
      "accuracy score correspond to random state 73 is: 0.8274220789190849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4983\n",
      "           1       0.66      0.56      0.60      1530\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.76      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4540  443]\n",
      " [ 677  853]]\n",
      "accuracy score correspond to random state 74 is: 0.828036235221864\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      4909\n",
      "           1       0.70      0.55      0.61      1604\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4542  367]\n",
      " [ 729  875]]\n",
      "accuracy score correspond to random state 75 is: 0.8317211730385383\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      4994\n",
      "           1       0.69      0.56      0.62      1519\n",
      "\n",
      "    accuracy                           0.84      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.83      0.84      0.83      6513\n",
      "\n",
      "confusion matrix is [[4603  391]\n",
      " [ 667  852]]\n",
      "accuracy score correspond to random state 76 is: 0.8375556579149394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4972\n",
      "           1       0.68      0.54      0.60      1541\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4569  403]\n",
      " [ 704  837]]\n",
      "accuracy score correspond to random state 77 is: 0.8300322432058959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4979\n",
      "           1       0.66      0.54      0.59      1534\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.76      0.73      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4545  434]\n",
      " [ 704  830]]\n",
      "accuracy score correspond to random state 78 is: 0.8252725318593582\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88      4922\n",
      "           1       0.67      0.52      0.58      1591\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.72      0.73      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4509  413]\n",
      " [ 770  821]]\n",
      "accuracy score correspond to random state 79 is: 0.8183632734530938\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4952\n",
      "           1       0.66      0.53      0.59      1561\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4516  436]\n",
      " [ 728  833]]\n",
      "accuracy score correspond to random state 80 is: 0.8212805158912944\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4944\n",
      "           1       0.68      0.56      0.61      1569\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.74      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4537  407]\n",
      " [ 695  874]]\n",
      "accuracy score correspond to random state 81 is: 0.8307999385843697\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4967\n",
      "           1       0.68      0.58      0.62      1546\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.75      0.76      6513\n",
      "weighted avg       0.83      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4539  428]\n",
      " [ 652  894]]\n",
      "accuracy score correspond to random state 82 is: 0.8341777982496545\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4963\n",
      "           1       0.68      0.52      0.59      1550\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.72      0.74      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4575  388]\n",
      " [ 740  810]]\n",
      "accuracy score correspond to random state 83 is: 0.8268079226163059\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      4945\n",
      "           1       0.67      0.55      0.60      1568\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4513  432]\n",
      " [ 704  864]]\n",
      "accuracy score correspond to random state 84 is: 0.8255796100107478\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4939\n",
      "           1       0.68      0.54      0.60      1574\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4543  396]\n",
      " [ 727  847]]\n",
      "accuracy score correspond to random state 85 is: 0.8275756179947796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      4962\n",
      "           1       0.64      0.54      0.59      1551\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.75      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4494  468]\n",
      " [ 710  841]]\n",
      "accuracy score correspond to random state 86 is: 0.8191309688315677\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4928\n",
      "           1       0.67      0.54      0.60      1585\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.73      0.74      6513\n",
      "weighted avg       0.81      0.82      0.82      6513\n",
      "\n",
      "confusion matrix is [[4499  429]\n",
      " [ 731  854]]\n",
      "accuracy score correspond to random state 87 is: 0.8218946721940734\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4936\n",
      "           1       0.66      0.55      0.60      1577\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.73      0.74      6513\n",
      "weighted avg       0.82      0.82      0.82      6513\n",
      "\n",
      "confusion matrix is [[4498  438]\n",
      " [ 708  869]]\n",
      "accuracy score correspond to random state 88 is: 0.8240442192538001\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4915\n",
      "           1       0.67      0.53      0.59      1598\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4493  422]\n",
      " [ 744  854]]\n",
      "accuracy score correspond to random state 89 is: 0.8209734377399048\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4918\n",
      "           1       0.70      0.56      0.62      1595\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4534  384]\n",
      " [ 708  887]]\n",
      "accuracy score correspond to random state 90 is: 0.8323353293413174\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4896\n",
      "           1       0.69      0.55      0.61      1617\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4488  408]\n",
      " [ 724  893]]\n",
      "accuracy score correspond to random state 91 is: 0.8261937663135268\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89      4892\n",
      "           1       0.69      0.53      0.60      1621\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.77      0.72      0.74      6513\n",
      "weighted avg       0.81      0.82      0.82      6513\n",
      "\n",
      "confusion matrix is [[4509  383]\n",
      " [ 765  856]]\n",
      "accuracy score correspond to random state 92 is: 0.8237371411024106\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      4908\n",
      "           1       0.67      0.54      0.60      1605\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.76      0.73      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4476  432]\n",
      " [ 736  869]]\n",
      "accuracy score correspond to random state 93 is: 0.8206663595885153\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89      4924\n",
      "           1       0.69      0.54      0.61      1589\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4543  381]\n",
      " [ 729  860]]\n",
      "accuracy score correspond to random state 94 is: 0.8295716259788116\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      4937\n",
      "           1       0.67      0.55      0.60      1576\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4517  420]\n",
      " [ 711  865]]\n",
      "accuracy score correspond to random state 95 is: 0.8263473053892215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89      4880\n",
      "           1       0.69      0.53      0.60      1633\n",
      "\n",
      "    accuracy                           0.82      6513\n",
      "   macro avg       0.77      0.73      0.74      6513\n",
      "weighted avg       0.81      0.82      0.81      6513\n",
      "\n",
      "confusion matrix is [[4489  391]\n",
      " [ 764  869]]\n",
      "accuracy score correspond to random state 96 is: 0.8226623675725472\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4995\n",
      "           1       0.67      0.57      0.61      1518\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.74      0.75      6513\n",
      "weighted avg       0.83      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4571  424]\n",
      " [ 659  859]]\n",
      "accuracy score correspond to random state 97 is: 0.8337171810225702\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89      4871\n",
      "           1       0.72      0.56      0.63      1642\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.79      0.74      0.76      6513\n",
      "weighted avg       0.83      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4506  365]\n",
      " [ 715  927]]\n",
      "accuracy score correspond to random state 98 is: 0.8341777982496545\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4960\n",
      "           1       0.68      0.54      0.61      1553\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.77      0.73      0.75      6513\n",
      "weighted avg       0.82      0.83      0.82      6513\n",
      "\n",
      "confusion matrix is [[4567  393]\n",
      " [ 707  846]]\n",
      "accuracy score correspond to random state 99 is: 0.8311070167357593\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      4908\n",
      "           1       0.70      0.56      0.62      1605\n",
      "\n",
      "    accuracy                           0.83      6513\n",
      "   macro avg       0.78      0.74      0.76      6513\n",
      "weighted avg       0.82      0.83      0.83      6513\n",
      "\n",
      "confusion matrix is [[4518  390]\n",
      " [ 699  906]]\n",
      "accuracy score correspond to random state 100 is: 0.8327959465684016\n",
      "max Accuracyscore corresponsds to  70 is: 0.8384768923691079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kregr=KNeighborsClassifier(n_neighbors=20)\n",
    "maxraccuracy_score(Kregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 333, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'ginni'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "parameters={\"criterion\":[\"ginni\",\"entropy\"]}\n",
    "gscv=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=parameters)\n",
    "gscv.fit(x_train,y_train)\n",
    "print(gscv.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4942\n",
      "           1       0.54      0.54      0.54      1571\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4219  723]\n",
      " [ 727  844]]\n",
      "accuracy score correspond to random state 42 is: 0.7773683402425917\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4963\n",
      "           1       0.55      0.54      0.55      1550\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.78      6513\n",
      "\n",
      "confusion matrix is [[4275  688]\n",
      " [ 711  839]]\n",
      "accuracy score correspond to random state 43 is: 0.7851988331030247\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4940\n",
      "           1       0.55      0.54      0.54      1573\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4247  693]\n",
      " [ 729  844]]\n",
      "accuracy score correspond to random state 44 is: 0.7816674343620451\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4927\n",
      "           1       0.56      0.52      0.54      1586\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.78      6513\n",
      "\n",
      "confusion matrix is [[4286  641]\n",
      " [ 755  831]]\n",
      "accuracy score correspond to random state 45 is: 0.785659450330109\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4952\n",
      "           1       0.54      0.51      0.52      1561\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.69      0.69      6513\n",
      "weighted avg       0.77      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4266  686]\n",
      " [ 766  795]]\n",
      "accuracy score correspond to random state 46 is: 0.7770612620912022\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4946\n",
      "           1       0.56      0.53      0.55      1567\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.78      6513\n",
      "\n",
      "confusion matrix is [[4289  657]\n",
      " [ 732  835]]\n",
      "accuracy score correspond to random state 47 is: 0.7867342238599724\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4940\n",
      "           1       0.56      0.54      0.55      1573\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.78      6513\n",
      "\n",
      "confusion matrix is [[4278  662]\n",
      " [ 731  842]]\n",
      "accuracy score correspond to random state 48 is: 0.7861200675571933\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4883\n",
      "           1       0.57      0.54      0.56      1630\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.71      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4212  671]\n",
      " [ 744  886]]\n",
      "accuracy score correspond to random state 49 is: 0.7827422078919085\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4968\n",
      "           1       0.55      0.55      0.55      1545\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.71      0.71      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4286  682]\n",
      " [ 699  846]]\n",
      "accuracy score correspond to random state 50 is: 0.7879625364655305\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4888\n",
      "           1       0.56      0.54      0.55      1625\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4201  687]\n",
      " [ 742  883]]\n",
      "accuracy score correspond to random state 51 is: 0.7805926608321818\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4929\n",
      "           1       0.55      0.54      0.54      1584\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4218  711]\n",
      " [ 727  857]]\n",
      "accuracy score correspond to random state 52 is: 0.7792108091509289\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4899\n",
      "           1       0.56      0.55      0.56      1614\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.71      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4215  684]\n",
      " [ 731  883]]\n",
      "accuracy score correspond to random state 53 is: 0.7827422078919085\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4937\n",
      "           1       0.55      0.53      0.54      1576\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4266  671]\n",
      " [ 741  835]]\n",
      "accuracy score correspond to random state 54 is: 0.7832028251189928\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4929\n",
      "           1       0.55      0.53      0.54      1584\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4258  671]\n",
      " [ 748  836]]\n",
      "accuracy score correspond to random state 55 is: 0.7821280515891295\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4965\n",
      "           1       0.54      0.54      0.54      1548\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4246  719]\n",
      " [ 710  838]]\n",
      "accuracy score correspond to random state 56 is: 0.7805926608321818\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4952\n",
      "           1       0.53      0.53      0.53      1561\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.69      0.69      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4226  726]\n",
      " [ 730  831]]\n",
      "accuracy score correspond to random state 57 is: 0.7764471057884231\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4921\n",
      "           1       0.56      0.51      0.53      1592\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4265  656]\n",
      " [ 773  819]]\n",
      "accuracy score correspond to random state 58 is: 0.7805926608321818\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4956\n",
      "           1       0.55      0.52      0.53      1557\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.79      0.78      6513\n",
      "\n",
      "confusion matrix is [[4311  645]\n",
      " [ 753  804]]\n",
      "accuracy score correspond to random state 59 is: 0.7853523721787194\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4945\n",
      "           1       0.55      0.54      0.55      1568\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4250  695]\n",
      " [ 720  848]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score correspond to random state 60 is: 0.7827422078919085\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4895\n",
      "           1       0.56      0.52      0.54      1618\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4233  662]\n",
      " [ 769  849]]\n",
      "accuracy score correspond to random state 61 is: 0.7802855826807923\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4996\n",
      "           1       0.53      0.51      0.52      1517\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.69      0.69      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4309  687]\n",
      " [ 741  776]]\n",
      "accuracy score correspond to random state 62 is: 0.7807461999078765\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4980\n",
      "           1       0.55      0.55      0.55      1533\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4281  699]\n",
      " [ 690  843]]\n",
      "accuracy score correspond to random state 63 is: 0.7867342238599724\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4948\n",
      "           1       0.53      0.52      0.53      1565\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.69      0.69      6513\n",
      "weighted avg       0.77      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4231  717]\n",
      " [ 744  821]]\n",
      "accuracy score correspond to random state 64 is: 0.7756794104099494\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4921\n",
      "           1       0.56      0.54      0.55      1592\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4243  678]\n",
      " [ 738  854]]\n",
      "accuracy score correspond to random state 65 is: 0.7825886688162137\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4957\n",
      "           1       0.55      0.53      0.54      1556\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4266  691]\n",
      " [ 725  831]]\n",
      "accuracy score correspond to random state 66 is: 0.7825886688162137\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      5007\n",
      "           1       0.53      0.54      0.53      1506\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4284  723]\n",
      " [ 693  813]]\n",
      "accuracy score correspond to random state 67 is: 0.7825886688162137\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      4934\n",
      "           1       0.54      0.54      0.54      1579\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4215  719]\n",
      " [ 734  845]]\n",
      "accuracy score correspond to random state 68 is: 0.7769077230155075\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      4951\n",
      "           1       0.54      0.54      0.54      1562\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4231  720]\n",
      " [ 712  850]]\n",
      "accuracy score correspond to random state 69 is: 0.7801320436050975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4972\n",
      "           1       0.55      0.53      0.54      1541\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4317  655]\n",
      " [ 727  814]]\n",
      "accuracy score correspond to random state 70 is: 0.7878089973898357\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      4888\n",
      "           1       0.56      0.52      0.54      1625\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.77      0.78      0.77      6513\n",
      "\n",
      "confusion matrix is [[4215  673]\n",
      " [ 778  847]]\n",
      "accuracy score correspond to random state 71 is: 0.777214801166897\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4904\n",
      "           1       0.55      0.53      0.54      1609\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.77      0.78      0.77      6513\n",
      "\n",
      "confusion matrix is [[4197  707]\n",
      " [ 752  857]]\n",
      "accuracy score correspond to random state 72 is: 0.7759864885613389\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4906\n",
      "           1       0.55      0.54      0.55      1607\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4197  709]\n",
      " [ 735  872]]\n",
      "accuracy score correspond to random state 73 is: 0.7782895746967603\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4983\n",
      "           1       0.54      0.54      0.54      1530\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4277  706]\n",
      " [ 702  828]]\n",
      "accuracy score correspond to random state 74 is: 0.7838169814217718\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      4909\n",
      "           1       0.59      0.54      0.56      1604\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.72      0.71      0.71      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4301  608]\n",
      " [ 737  867]]\n",
      "accuracy score correspond to random state 75 is: 0.793489943190542\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4994\n",
      "           1       0.54      0.53      0.54      1519\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4293  701]\n",
      " [ 707  812]]\n",
      "accuracy score correspond to random state 76 is: 0.7838169814217718\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4972\n",
      "           1       0.55      0.53      0.54      1541\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4312  660]\n",
      " [ 720  821]]\n",
      "accuracy score correspond to random state 77 is: 0.7881160755412252\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4979\n",
      "           1       0.54      0.54      0.54      1534\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4285  694]\n",
      " [ 704  830]]\n",
      "accuracy score correspond to random state 78 is: 0.7853523721787194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4922\n",
      "           1       0.56      0.51      0.53      1591\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4278  644]\n",
      " [ 775  816]]\n",
      "accuracy score correspond to random state 79 is: 0.7821280515891295\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      4952\n",
      "           1       0.53      0.49      0.51      1561\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.68      0.68      6513\n",
      "weighted avg       0.77      0.78      0.77      6513\n",
      "\n",
      "confusion matrix is [[4283  669]\n",
      " [ 792  769]]\n",
      "accuracy score correspond to random state 80 is: 0.7756794104099494\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4944\n",
      "           1       0.57      0.53      0.55      1569\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.71      6513\n",
      "weighted avg       0.78      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4301  643]\n",
      " [ 732  837]]\n",
      "accuracy score correspond to random state 81 is: 0.7888837709196991\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4967\n",
      "           1       0.55      0.56      0.56      1546\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.71      0.71      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4253  714]\n",
      " [ 676  870]]\n",
      "accuracy score correspond to random state 82 is: 0.7865806847842776\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4963\n",
      "           1       0.56      0.54      0.55      1550\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.71      0.70      0.71      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4297  666]\n",
      " [ 709  841]]\n",
      "accuracy score correspond to random state 83 is: 0.7888837709196991\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4945\n",
      "           1       0.55      0.54      0.55      1568\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4251  694]\n",
      " [ 717  851]]\n",
      "accuracy score correspond to random state 84 is: 0.7833563641946876\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4939\n",
      "           1       0.55      0.52      0.53      1574\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4261  678]\n",
      " [ 753  821]]\n",
      "accuracy score correspond to random state 85 is: 0.7802855826807923\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4962\n",
      "           1       0.53      0.52      0.53      1551\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.69      0.69      0.69      6513\n",
      "weighted avg       0.77      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4249  713]\n",
      " [ 743  808]]\n",
      "accuracy score correspond to random state 86 is: 0.7764471057884231\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4928\n",
      "           1       0.55      0.53      0.54      1585\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4253  675]\n",
      " [ 744  841]]\n",
      "accuracy score correspond to random state 87 is: 0.7821280515891295\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      4936\n",
      "           1       0.55      0.55      0.55      1577\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4240  696]\n",
      " [ 712  865]]\n",
      "accuracy score correspond to random state 88 is: 0.7838169814217718\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4915\n",
      "           1       0.56      0.53      0.55      1598\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4257  658]\n",
      " [ 751  847]]\n",
      "accuracy score correspond to random state 89 is: 0.7836634423460771\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86      4918\n",
      "           1       0.58      0.55      0.56      1595\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.72      0.71      0.71      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4271  647]\n",
      " [ 716  879]]\n",
      "accuracy score correspond to random state 90 is: 0.7907262398280362\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4896\n",
      "           1       0.56      0.52      0.54      1617\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4237  659]\n",
      " [ 773  844]]\n",
      "accuracy score correspond to random state 91 is: 0.7801320436050975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86      4892\n",
      "           1       0.59      0.53      0.55      1621\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.78      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4293  599]\n",
      " [ 769  852]]\n",
      "accuracy score correspond to random state 92 is: 0.7899585444495624\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      4908\n",
      "           1       0.55      0.52      0.53      1605\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.69      6513\n",
      "weighted avg       0.77      0.78      0.77      6513\n",
      "\n",
      "confusion matrix is [[4231  677]\n",
      " [ 778  827]]\n",
      "accuracy score correspond to random state 93 is: 0.776600644864118\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4924\n",
      "           1       0.55      0.53      0.54      1589\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.70      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4252  672]\n",
      " [ 751  838]]\n",
      "accuracy score correspond to random state 94 is: 0.7815138952863504\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4937\n",
      "           1       0.55      0.53      0.54      1576\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4248  689]\n",
      " [ 747  829]]\n",
      "accuracy score correspond to random state 95 is: 0.7795178873023184\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      4880\n",
      "           1       0.56      0.52      0.54      1633\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.77      0.78      0.77      6513\n",
      "\n",
      "confusion matrix is [[4208  672]\n",
      " [ 782  851]]\n",
      "accuracy score correspond to random state 96 is: 0.7767541839398127\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85      4995\n",
      "           1       0.52      0.49      0.51      1518\n",
      "\n",
      "    accuracy                           0.77      6513\n",
      "   macro avg       0.68      0.68      0.68      6513\n",
      "weighted avg       0.77      0.77      0.77      6513\n",
      "\n",
      "confusion matrix is [[4293  702]\n",
      " [ 767  751]]\n",
      "accuracy score correspond to random state 97 is: 0.7744510978043913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      4871\n",
      "           1       0.58      0.54      0.56      1642\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.70      0.71      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4218  653]\n",
      " [ 750  892]]\n",
      "accuracy score correspond to random state 98 is: 0.7845846768002457\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4960\n",
      "           1       0.54      0.52      0.53      1553\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.70      0.69      0.70      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4273  687]\n",
      " [ 739  814]]\n",
      "accuracy score correspond to random state 99 is: 0.781053278059266\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      4908\n",
      "           1       0.56      0.55      0.56      1605\n",
      "\n",
      "    accuracy                           0.78      6513\n",
      "   macro avg       0.71      0.71      0.71      6513\n",
      "weighted avg       0.78      0.78      0.78      6513\n",
      "\n",
      "confusion matrix is [[4218  690]\n",
      " [ 717  888]]\n",
      "accuracy score correspond to random state 100 is: 0.7839705204974666\n",
      "max Accuracyscore corresponsds to  75 is: 0.793489943190542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dregr=DecisionTreeClassifier(criterion=\"entropy\")\n",
    "maxraccuracy_score(dregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4942\n",
      "           1       0.63      0.39      0.48      1571\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4591  351]\n",
      " [ 965  606]]\n",
      "accuracy score correspond to random state 42 is: 0.7979425763856901\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4963\n",
      "           1       0.65      0.38      0.48      1550\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4645  318]\n",
      " [ 963  587]]\n",
      "accuracy score correspond to random state 43 is: 0.8033164440350069\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4940\n",
      "           1       0.63      0.39      0.48      1573\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4579  361]\n",
      " [ 954  619]]\n",
      "accuracy score correspond to random state 44 is: 0.7980961154613849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.88      4927\n",
      "           1       0.65      0.38      0.48      1586\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4601  326]\n",
      " [ 985  601]]\n",
      "accuracy score correspond to random state 45 is: 0.798710271764164\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4952\n",
      "           1       0.65      0.39      0.49      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4622  330]\n",
      " [ 945  616]]\n",
      "accuracy score correspond to random state 46 is: 0.8042376784891755\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4946\n",
      "           1       0.63      0.39      0.48      1567\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4597  349]\n",
      " [ 963  604]]\n",
      "accuracy score correspond to random state 47 is: 0.7985567326884692\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4940\n",
      "           1       0.68      0.39      0.50      1573\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4645  295]\n",
      " [ 956  617]]\n",
      "accuracy score correspond to random state 48 is: 0.8079226163058498\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      4883\n",
      "           1       0.67      0.38      0.49      1630\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4578  305]\n",
      " [1009  621]]\n",
      "accuracy score correspond to random state 49 is: 0.7982496545370796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88      4968\n",
      "           1       0.66      0.41      0.51      1545\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.70      6513\n",
      "weighted avg       0.80      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4647  321]\n",
      " [ 911  634]]\n",
      "accuracy score correspond to random state 50 is: 0.8108398587440504\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87      4888\n",
      "           1       0.66      0.37      0.47      1625\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.74      0.65      0.67      6513\n",
      "weighted avg       0.78      0.79      0.77      6513\n",
      "\n",
      "confusion matrix is [[4576  312]\n",
      " [1024  601]]\n",
      "accuracy score correspond to random state 51 is: 0.7948717948717948\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4929\n",
      "           1       0.64      0.37      0.46      1584\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.65      0.67      6513\n",
      "weighted avg       0.78      0.80      0.77      6513\n",
      "\n",
      "confusion matrix is [[4598  331]\n",
      " [1004  580]]\n",
      "accuracy score correspond to random state 52 is: 0.7950253339474896\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4899\n",
      "           1       0.63      0.37      0.47      1614\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.72      0.65      0.67      6513\n",
      "weighted avg       0.77      0.79      0.77      6513\n",
      "\n",
      "confusion matrix is [[4553  346]\n",
      " [1019  595]]\n",
      "accuracy score correspond to random state 53 is: 0.7904191616766467\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4937\n",
      "           1       0.66      0.39      0.49      1576\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4615  322]\n",
      " [ 963  613]]\n",
      "accuracy score correspond to random state 54 is: 0.8027022877322278\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4929\n",
      "           1       0.66      0.40      0.50      1584\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4608  321]\n",
      " [ 956  628]]\n",
      "accuracy score correspond to random state 55 is: 0.803930600337786\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4965\n",
      "           1       0.64      0.38      0.48      1548\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4627  338]\n",
      " [ 956  592]]\n",
      "accuracy score correspond to random state 56 is: 0.801320436050975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4952\n",
      "           1       0.62      0.37      0.46      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.65      0.67      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4604  348]\n",
      " [ 986  575]]\n",
      "accuracy score correspond to random state 57 is: 0.7951788730231844\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4921\n",
      "           1       0.65      0.38      0.48      1592\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4588  333]\n",
      " [ 981  611]]\n",
      "accuracy score correspond to random state 58 is: 0.7982496545370796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4956\n",
      "           1       0.66      0.40      0.50      1557\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4636  320]\n",
      " [ 939  618]]\n",
      "accuracy score correspond to random state 59 is: 0.8066943037002917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4945\n",
      "           1       0.64      0.38      0.48      1568\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4607  338]\n",
      " [ 971  597]]\n",
      "accuracy score correspond to random state 60 is: 0.7990173499155535\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4895\n",
      "           1       0.69      0.38      0.49      1618\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.69      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4611  284]\n",
      " [ 996  622]]\n",
      "accuracy score correspond to random state 61 is: 0.8034699831107017\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4996\n",
      "           1       0.62      0.39      0.48      1517\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4637  359]\n",
      " [ 925  592]]\n",
      "accuracy score correspond to random state 62 is: 0.8028558268079227\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4980\n",
      "           1       0.63      0.39      0.48      1533\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4624  356]\n",
      " [ 932  601]]\n",
      "accuracy score correspond to random state 63 is: 0.8022416705051436\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4948\n",
      "           1       0.64      0.38      0.48      1565\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4610  338]\n",
      " [ 965  600]]\n",
      "accuracy score correspond to random state 64 is: 0.7999385843697221\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4921\n",
      "           1       0.64      0.38      0.48      1592\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4577  344]\n",
      " [ 981  611]]\n",
      "accuracy score correspond to random state 65 is: 0.7965607247044373\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4957\n",
      "           1       0.63      0.39      0.48      1556\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4598  359]\n",
      " [ 945  611]]\n",
      "accuracy score correspond to random state 66 is: 0.7997850452940273\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      5007\n",
      "           1       0.63      0.41      0.50      1506\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4649  358]\n",
      " [ 886  620]]\n",
      "accuracy score correspond to random state 67 is: 0.8089973898357132\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4934\n",
      "           1       0.63      0.38      0.47      1579\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.65      0.67      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4587  347]\n",
      " [ 980  599]]\n",
      "accuracy score correspond to random state 68 is: 0.7962536465530478\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4951\n",
      "           1       0.66      0.41      0.50      1562\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4623  328]\n",
      " [ 926  636]]\n",
      "accuracy score correspond to random state 69 is: 0.8074619990787656\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4972\n",
      "           1       0.63      0.40      0.49      1541\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4615  357]\n",
      " [ 927  614]]\n",
      "accuracy score correspond to random state 70 is: 0.8028558268079227\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4888\n",
      "           1       0.65      0.38      0.48      1625\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.77      6513\n",
      "\n",
      "confusion matrix is [[4565  323]\n",
      " [1012  613]]\n",
      "accuracy score correspond to random state 71 is: 0.7950253339474896\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4904\n",
      "           1       0.65      0.38      0.48      1609\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4575  329]\n",
      " [ 991  618]]\n",
      "accuracy score correspond to random state 72 is: 0.797328420082911\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4906\n",
      "           1       0.65      0.40      0.49      1607\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4563  343]\n",
      " [ 971  636]]\n",
      "accuracy score correspond to random state 73 is: 0.7982496545370796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4983\n",
      "           1       0.63      0.40      0.49      1530\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4626  357]\n",
      " [ 922  608]]\n",
      "accuracy score correspond to random state 74 is: 0.8036235221863964\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4909\n",
      "           1       0.66      0.38      0.49      1604\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4598  311]\n",
      " [ 987  617]]\n",
      "accuracy score correspond to random state 75 is: 0.800706279748196\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4994\n",
      "           1       0.63      0.40      0.49      1519\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4637  357]\n",
      " [ 905  614]]\n",
      "accuracy score correspond to random state 76 is: 0.8062336864732075\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4972\n",
      "           1       0.62      0.38      0.47      1541\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4618  354]\n",
      " [ 952  589]]\n",
      "accuracy score correspond to random state 77 is: 0.7994779671426377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4979\n",
      "           1       0.65      0.39      0.49      1534\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4656  323]\n",
      " [ 938  596]]\n",
      "accuracy score correspond to random state 78 is: 0.8063872255489022\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4922\n",
      "           1       0.64      0.40      0.49      1591\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4573  349]\n",
      " [ 961  630]]\n",
      "accuracy score correspond to random state 79 is: 0.7988638108398587\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4952\n",
      "           1       0.63      0.39      0.48      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4593  359]\n",
      " [ 955  606]]\n",
      "accuracy score correspond to random state 80 is: 0.7982496545370796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4944\n",
      "           1       0.63      0.38      0.48      1569\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.67      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4587  357]\n",
      " [ 968  601]]\n",
      "accuracy score correspond to random state 81 is: 0.7965607247044373\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4967\n",
      "           1       0.65      0.40      0.50      1546\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4631  336]\n",
      " [ 921  625]]\n",
      "accuracy score correspond to random state 82 is: 0.8070013818516812\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4963\n",
      "           1       0.63      0.39      0.48      1550\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4597  366]\n",
      " [ 938  612]]\n",
      "accuracy score correspond to random state 83 is: 0.7997850452940273\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4945\n",
      "           1       0.65      0.39      0.49      1568\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4620  325]\n",
      " [ 959  609]]\n",
      "accuracy score correspond to random state 84 is: 0.8028558268079227\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4939\n",
      "           1       0.65      0.39      0.49      1574\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4609  330]\n",
      " [ 954  620]]\n",
      "accuracy score correspond to random state 85 is: 0.8028558268079227\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.87      4962\n",
      "           1       0.62      0.37      0.47      1551\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.65      0.67      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4610  352]\n",
      " [ 970  581]]\n",
      "accuracy score correspond to random state 86 is: 0.7970213419315215\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4928\n",
      "           1       0.64      0.38      0.47      1585\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.65      0.67      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4591  337]\n",
      " [ 989  596]]\n",
      "accuracy score correspond to random state 87 is: 0.7964071856287425\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4936\n",
      "           1       0.65      0.39      0.49      1577\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4602  334]\n",
      " [ 955  622]]\n",
      "accuracy score correspond to random state 88 is: 0.8020881314294488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4915\n",
      "           1       0.64      0.38      0.48      1598\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4569  346]\n",
      " [ 987  611]]\n",
      "accuracy score correspond to random state 89 is: 0.7953324120988792\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      4918\n",
      "           1       0.68      0.40      0.50      1595\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4620  298]\n",
      " [ 964  631]]\n",
      "accuracy score correspond to random state 90 is: 0.8062336864732075\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4896\n",
      "           1       0.66      0.38      0.48      1617\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4573  323]\n",
      " [ 998  619]]\n",
      "accuracy score correspond to random state 91 is: 0.7971748810072163\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4892\n",
      "           1       0.65      0.38      0.48      1621\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.77      6513\n",
      "\n",
      "confusion matrix is [[4565  327]\n",
      " [1008  613]]\n",
      "accuracy score correspond to random state 92 is: 0.7950253339474896\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87      4908\n",
      "           1       0.64      0.38      0.47      1605\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.73      0.65      0.67      6513\n",
      "weighted avg       0.78      0.79      0.77      6513\n",
      "\n",
      "confusion matrix is [[4566  342]\n",
      " [1000  605]]\n",
      "accuracy score correspond to random state 93 is: 0.7939505604176262\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4924\n",
      "           1       0.66      0.39      0.49      1589\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4601  323]\n",
      " [ 970  619]]\n",
      "accuracy score correspond to random state 94 is: 0.8014739751266697\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4937\n",
      "           1       0.64      0.40      0.49      1576\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4586  351]\n",
      " [ 945  631]]\n",
      "accuracy score correspond to random state 95 is: 0.8010133578995855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87      4880\n",
      "           1       0.65      0.37      0.47      1633\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.73      0.65      0.67      6513\n",
      "weighted avg       0.77      0.79      0.77      6513\n",
      "\n",
      "confusion matrix is [[4561  319]\n",
      " [1036  597]]\n",
      "accuracy score correspond to random state 96 is: 0.7919545524335944\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      4995\n",
      "           1       0.63      0.42      0.50      1518\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.67      0.69      6513\n",
      "weighted avg       0.79      0.81      0.79      6513\n",
      "\n",
      "confusion matrix is [[4625  370]\n",
      " [ 885  633]]\n",
      "accuracy score correspond to random state 97 is: 0.8073084600030708\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4871\n",
      "           1       0.68      0.38      0.49      1642\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.75      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4580  291]\n",
      " [1014  628]]\n",
      "accuracy score correspond to random state 98 is: 0.7996315062183326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      4960\n",
      "           1       0.64      0.40      0.49      1553\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.66      0.68      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4610  350]\n",
      " [ 935  618]]\n",
      "accuracy score correspond to random state 99 is: 0.8027022877322278\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88      4908\n",
      "           1       0.66      0.38      0.48      1605\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.66      0.68      6513\n",
      "weighted avg       0.78      0.80      0.78      6513\n",
      "\n",
      "confusion matrix is [[4603  305]\n",
      " [1000  605]]\n",
      "accuracy score correspond to random state 100 is: 0.7996315062183326\n",
      "max Accuracyscore corresponsds to  50 is: 0.8108398587440504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adregr=AdaBoostClassifier(n_estimators=50,base_estimator=lregr)\n",
    "maxraccuracy_score(adregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      4942\n",
      "           1       0.61      0.56      0.58      1571\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4393  549]\n",
      " [ 697  874]]\n",
      "accuracy score correspond to random state 42 is: 0.8086903116843237\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4963\n",
      "           1       0.59      0.52      0.55      1550\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4396  567]\n",
      " [ 738  812]]\n",
      "accuracy score correspond to random state 43 is: 0.7996315062183326\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4940\n",
      "           1       0.59      0.55      0.57      1573\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4340  600]\n",
      " [ 700  873]]\n",
      "accuracy score correspond to random state 44 is: 0.8003992015968064\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4927\n",
      "           1       0.61      0.54      0.57      1586\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4383  544]\n",
      " [ 727  859]]\n",
      "accuracy score correspond to random state 45 is: 0.8048518347919545\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4952\n",
      "           1       0.59      0.52      0.55      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4388  564]\n",
      " [ 751  810]]\n",
      "accuracy score correspond to random state 46 is: 0.7980961154613849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4946\n",
      "           1       0.60      0.54      0.57      1567\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4388  558]\n",
      " [ 717  850]]\n",
      "accuracy score correspond to random state 47 is: 0.8042376784891755\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      4940\n",
      "           1       0.62      0.54      0.58      1573\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4407  533]\n",
      " [ 716  857]]\n",
      "accuracy score correspond to random state 48 is: 0.8082296944572394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4883\n",
      "           1       0.62      0.56      0.59      1630\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4319  564]\n",
      " [ 717  913]]\n",
      "accuracy score correspond to random state 49 is: 0.8033164440350069\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4968\n",
      "           1       0.61      0.58      0.59      1545\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.73      0.74      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4393  575]\n",
      " [ 648  897]]\n",
      "accuracy score correspond to random state 50 is: 0.8122217104253032\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4888\n",
      "           1       0.62      0.53      0.57      1625\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4374  514]\n",
      " [ 771  854]]\n",
      "accuracy score correspond to random state 51 is: 0.8027022877322278\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4929\n",
      "           1       0.60      0.54      0.57      1584\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4356  573]\n",
      " [ 726  858]]\n",
      "accuracy score correspond to random state 52 is: 0.8005527406725012\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4899\n",
      "           1       0.60      0.56      0.58      1614\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4288  611]\n",
      " [ 713  901]]\n",
      "accuracy score correspond to random state 53 is: 0.796714263780132\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4937\n",
      "           1       0.61      0.56      0.58      1576\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4367  570]\n",
      " [ 700  876]]\n",
      "accuracy score correspond to random state 54 is: 0.8050053738676494\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4929\n",
      "           1       0.59      0.55      0.57      1584\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4320  609]\n",
      " [ 715  869]]\n",
      "accuracy score correspond to random state 55 is: 0.796714263780132\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4965\n",
      "           1       0.59      0.55      0.57      1548\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4367  598]\n",
      " [ 698  850]]\n",
      "accuracy score correspond to random state 56 is: 0.8010133578995855\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4952\n",
      "           1       0.58      0.53      0.55      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4352  600]\n",
      " [ 733  828]]\n",
      "accuracy score correspond to random state 57 is: 0.7953324120988792\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4921\n",
      "           1       0.61      0.55      0.58      1592\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4355  566]\n",
      " [ 720  872]]\n",
      "accuracy score correspond to random state 58 is: 0.8025487486565331\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4956\n",
      "           1       0.59      0.54      0.56      1557\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.71      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4366  590]\n",
      " [ 721  836]]\n",
      "accuracy score correspond to random state 59 is: 0.798710271764164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      4945\n",
      "           1       0.56      0.59      0.58      1568\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.72      0.72      0.72      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4225  720]\n",
      " [ 641  927]]\n",
      "accuracy score correspond to random state 60 is: 0.7910333179794258\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4895\n",
      "           1       0.62      0.54      0.58      1618\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4365  530]\n",
      " [ 742  876]]\n",
      "accuracy score correspond to random state 61 is: 0.8046982957162598\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4996\n",
      "           1       0.58      0.56      0.57      1517\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4389  607]\n",
      " [ 667  850]]\n",
      "accuracy score correspond to random state 62 is: 0.8043912175648703\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4980\n",
      "           1       0.59      0.54      0.56      1533\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4397  583]\n",
      " [ 711  822]]\n",
      "accuracy score correspond to random state 63 is: 0.801320436050975\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4948\n",
      "           1       0.61      0.54      0.57      1565\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4403  545]\n",
      " [ 716  849]]\n",
      "accuracy score correspond to random state 64 is: 0.8063872255489022\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4921\n",
      "           1       0.62      0.55      0.58      1592\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4371  550]\n",
      " [ 711  881]]\n",
      "accuracy score correspond to random state 65 is: 0.8063872255489022\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4957\n",
      "           1       0.61      0.56      0.58      1556\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4397  560]\n",
      " [ 683  873]]\n",
      "accuracy score correspond to random state 66 is: 0.8091509289114079\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      5007\n",
      "           1       0.59      0.54      0.56      1506\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4429  578]\n",
      " [ 691  815]]\n",
      "accuracy score correspond to random state 67 is: 0.8051589129433441\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4934\n",
      "           1       0.60      0.55      0.57      1579\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4353  581]\n",
      " [ 715  864]]\n",
      "accuracy score correspond to random state 68 is: 0.8010133578995855\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4951\n",
      "           1       0.60      0.57      0.58      1562\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.73      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4348  603]\n",
      " [ 671  891]]\n",
      "accuracy score correspond to random state 69 is: 0.8043912175648703\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4972\n",
      "           1       0.59      0.55      0.57      1541\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4396  576]\n",
      " [ 701  840]]\n",
      "accuracy score correspond to random state 70 is: 0.803930600337786\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      4888\n",
      "           1       0.61      0.55      0.57      1625\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4311  577]\n",
      " [ 737  888]]\n",
      "accuracy score correspond to random state 71 is: 0.7982496545370796\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4904\n",
      "           1       0.62      0.56      0.59      1609\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4355  549]\n",
      " [ 709  900]]\n",
      "accuracy score correspond to random state 72 is: 0.8068478427759865\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4906\n",
      "           1       0.61      0.57      0.59      1607\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4318  588]\n",
      " [ 693  914]]\n",
      "accuracy score correspond to random state 73 is: 0.8033164440350069\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      4983\n",
      "           1       0.60      0.57      0.58      1530\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.72      0.73      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4397  586]\n",
      " [ 663  867]]\n",
      "accuracy score correspond to random state 74 is: 0.8082296944572394\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4909\n",
      "           1       0.61      0.55      0.58      1604\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4348  561]\n",
      " [ 716  888]]\n",
      "accuracy score correspond to random state 75 is: 0.803930600337786\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      4994\n",
      "           1       0.61      0.55      0.58      1519\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4458  536]\n",
      " [ 679  840]]\n",
      "accuracy score correspond to random state 76 is: 0.8134500230308613\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      4972\n",
      "           1       0.60      0.55      0.58      1541\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4406  566]\n",
      " [ 690  851]]\n",
      "accuracy score correspond to random state 77 is: 0.8071549209273761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4979\n",
      "           1       0.58      0.54      0.56      1534\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4388  591]\n",
      " [ 705  829]]\n",
      "accuracy score correspond to random state 78 is: 0.8010133578995855\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4922\n",
      "           1       0.61      0.52      0.56      1591\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4400  522]\n",
      " [ 765  826]]\n",
      "accuracy score correspond to random state 79 is: 0.8023952095808383\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4952\n",
      "           1       0.59      0.51      0.55      1561\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4395  557]\n",
      " [ 761  800]]\n",
      "accuracy score correspond to random state 80 is: 0.7976354982343006\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4944\n",
      "           1       0.61      0.54      0.57      1569\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4396  548]\n",
      " [ 716  853]]\n",
      "accuracy score correspond to random state 81 is: 0.805926608321818\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      4967\n",
      "           1       0.60      0.58      0.59      1546\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.73      0.73      0.73      6513\n",
      "weighted avg       0.80      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4363  604]\n",
      " [ 656  890]]\n",
      "accuracy score correspond to random state 82 is: 0.806540764624597\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4963\n",
      "           1       0.60      0.55      0.57      1550\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4388  575]\n",
      " [ 703  847]]\n",
      "accuracy score correspond to random state 83 is: 0.8037770612620913\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4945\n",
      "           1       0.60      0.55      0.57      1568\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4362  583]\n",
      " [ 705  863]]\n",
      "accuracy score correspond to random state 84 is: 0.8022416705051436\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4939\n",
      "           1       0.60      0.54      0.57      1574\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4382  557]\n",
      " [ 731  843]]\n",
      "accuracy score correspond to random state 85 is: 0.8022416705051436\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4962\n",
      "           1       0.59      0.53      0.56      1551\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.71      0.71      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4395  567]\n",
      " [ 731  820]]\n",
      "accuracy score correspond to random state 86 is: 0.800706279748196\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4928\n",
      "           1       0.61      0.52      0.56      1585\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4398  530]\n",
      " [ 763  822]]\n",
      "accuracy score correspond to random state 87 is: 0.8014739751266697\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4936\n",
      "           1       0.60      0.56      0.58      1577\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.72      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4346  590]\n",
      " [ 701  876]]\n",
      "accuracy score correspond to random state 88 is: 0.8017810532780593\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4915\n",
      "           1       0.61      0.53      0.57      1598\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4376  539]\n",
      " [ 750  848]]\n",
      "accuracy score correspond to random state 89 is: 0.8020881314294488\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      4918\n",
      "           1       0.63      0.56      0.59      1595\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.73      0.73      6513\n",
      "weighted avg       0.80      0.81      0.81      6513\n",
      "\n",
      "confusion matrix is [[4391  527]\n",
      " [ 706  889]]\n",
      "accuracy score correspond to random state 90 is: 0.8106863196683556\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      4896\n",
      "           1       0.61      0.54      0.57      1617\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4325  571]\n",
      " [ 738  879]]\n",
      "accuracy score correspond to random state 91 is: 0.7990173499155535\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      4892\n",
      "           1       0.63      0.52      0.57      1621\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4389  503]\n",
      " [ 772  849]]\n",
      "accuracy score correspond to random state 92 is: 0.8042376784891755\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      4908\n",
      "           1       0.61      0.52      0.56      1605\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.80      0.79      6513\n",
      "\n",
      "confusion matrix is [[4367  541]\n",
      " [ 767  838]]\n",
      "accuracy score correspond to random state 93 is: 0.7991708889912482\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4924\n",
      "           1       0.61      0.55      0.58      1589\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4369  555]\n",
      " [ 708  881]]\n",
      "accuracy score correspond to random state 94 is: 0.8060801473975127\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4937\n",
      "           1       0.61      0.53      0.57      1576\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4398  539]\n",
      " [ 743  833]]\n",
      "accuracy score correspond to random state 95 is: 0.8031629049593122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      4880\n",
      "           1       0.60      0.53      0.56      1633\n",
      "\n",
      "    accuracy                           0.79      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.79      0.79      0.79      6513\n",
      "\n",
      "confusion matrix is [[4310  570]\n",
      " [ 767  866]]\n",
      "accuracy score correspond to random state 96 is: 0.7947182557961001\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87      4995\n",
      "           1       0.57      0.53      0.55      1518\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.72      0.70      0.71      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4398  597]\n",
      " [ 718  800]]\n",
      "accuracy score correspond to random state 97 is: 0.7980961154613849\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      4871\n",
      "           1       0.62      0.55      0.58      1642\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.79      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4309  562]\n",
      " [ 735  907]]\n",
      "accuracy score correspond to random state 98 is: 0.8008598188238907\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4960\n",
      "           1       0.60      0.54      0.57      1553\n",
      "\n",
      "    accuracy                           0.80      6513\n",
      "   macro avg       0.73      0.71      0.72      6513\n",
      "weighted avg       0.80      0.80      0.80      6513\n",
      "\n",
      "confusion matrix is [[4390  570]\n",
      " [ 711  842]]\n",
      "accuracy score correspond to random state 99 is: 0.8033164440350069\n",
      "classification report is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      4908\n",
      "           1       0.62      0.56      0.59      1605\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.74      0.72      0.73      6513\n",
      "weighted avg       0.80      0.81      0.80      6513\n",
      "\n",
      "confusion matrix is [[4350  558]\n",
      " [ 704  901]]\n",
      "accuracy score correspond to random state 100 is: 0.8062336864732075\n",
      "max Accuracyscore corresponsds to  76 is: 0.8134500230308613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adregr=AdaBoostClassifier(n_estimators=50,base_estimator=dregr)\n",
    "maxraccuracy_score(adregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-b3158bc5dd81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgdregr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlregr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmaxraccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdregr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "gdregr=GradientBoostingClassifier(n_estimators=100,base_estimator=lregr)\n",
    "maxraccuracy_score(gdregr,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anubhav Agarwal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80239521, 0.80436118, 0.80681818, 0.80482187, 0.80743243])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lregr, x, y, cv=5)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3 , 0.25, 0.4 , ..., 0.35, 0.35, 0.25])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auc_Roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_prob=Kregr.predict_proba(x_test)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 4.04694456e-04, 1.01173614e-03, 1.82112505e-03,\n",
       "       3.23755565e-03, 9.51031971e-03, 3.48037232e-02, 1.06839336e-01,\n",
       "       3.54917038e-01, 6.86361797e-01, 8.51679482e-01, 9.57709429e-01,\n",
       "       9.89680291e-01, 9.99392958e-01, 1.00000000e+00])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_prob)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00445576, 0.01718651, 0.12221515, 0.51177594, 0.8255888 ,\n",
       "       0.94334819, 0.99554424, 0.99936346, 1.        , 1.        ])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title(\"KNeighborsClassifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542177354060766"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score=roc_auc_score(y_test,y_pred_prob)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=70,test_size=0.20)\n",
    "\n",
    "# From the analysis it is clear that KNeighborsClassifier is the best classifier at random state 65 with a accuracy score of 93\n",
    "# saving a file\n",
    "import pickle\n",
    "filename=\"picklelregr.pkl\"\n",
    "pickle.dump(KNeighborsClassifier,open(filename,\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
